{"body": [{"indent": 0, "text": ["Mantra"], "type": "title", "level": 0}, {"indent": 0, "type": "summary", "text": ["Renders the scene using Houdini\u2019s standard mantra renderer and generates IFD files."]}, {"body": [{"indent": 0, "type": "para", "text": ["The mantra output driver node uses mantra (Houdini\u2019s built-in renderer) to render your scene. You can create a new mantra node by choosing ", {"text": ["Render \u25b8 Create render node \u25b8 Mantra"], "type": "ui"}, " from the main menus. You can edit an existing render node with ", {"text": ["Render \u25b8 Edit render node \u25b8 ", {"text": ["node name"], "type": "var"}], "type": "ui"}, ". To see the actual network of render driver nodes, click the path at the top of a network editor pane and choose ", {"text": ["Other networks \u25b8 out"], "type": "ui"}, "."]}, {"indent": 0, "type": "para", "text": ["You can add and remove ", {"text": ["properties"], "fullpath": "/props", "scheme": null, "type": "link", "value": "/props"}, " from the output driver just like you can for objects. If you add object properties to the render driver, they define defaults for all objects in the scene. Select a render node, and in the parameter editor click the ", {"text": "", "fullpath": "/nodes/out/BUTTONS/gear", "scheme": "Icon", "type": "link", "value": "BUTTONS/gear"}, " Gear menu and choose ", {"text": ["Edit rendering parameters"], "type": "ui"}, " to edit the properties on the node. For more information on properties, see ", {"text": ["properties"], "fullpath": "/props", "scheme": null, "type": "link", "value": "/props"}, ". For more information on adding properties to a node see the ", {"text": ["Edit Parameter Interface"], "fullpath": "/ref/windows/edit_parameter_interface", "scheme": null, "type": "link", "value": "/ref/windows/edit_parameter_interface"}, "."]}, {"indent": 0, "type": "para", "text": ["For complex scenes involving multiple render passes, separate lighting and shadow passes, and so on, you can set up dependency relationships between render drivers by connecting driver nodes together. See ", {"text": ["render dependencies"], "fullpath": "/render/batch", "scheme": null, "type": "link", "value": "/render/batch"}, "."]}], "indent": 0, "level": 2, "text": ["Overview"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["Sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["Noise reduction"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["Motion blur"], "fullpath": "/render/blur", "scheme": null, "type": "link", "value": "/render/blur"}]}], "container": true, "type": "bullet_group"}], "indent": 0, "level": 2, "text": ["User guide"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["The following ", {"text": ["attributes"], "fullpath": "/model/attributes", "scheme": null, "type": "link", "value": "/model/attributes"}, " on geometry control how mantra renders the geometry."]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["Orientation of curve/point primitives. Curves and points will be\n    oriented so that their normals point in the direction of the\n    orient vector attribute."]}], "indent": 0, "type": "dt", "text": [{"text": ["orient"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["(velocity) Used for velocity motion blur computations."]}], "indent": 0, "type": "dt", "text": [{"text": ["v"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Default attribute for the ", {"text": ["-u"], "type": "code"}, " command-line option."]}], "indent": 0, "type": "dt", "text": [{"text": ["uv"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Shader overrides (per primitive)."]}], "indent": 0, "type": "dt", "text": [{"text": ["vm_photon"], "type": "code"}, ", ", {"text": ["vm_surface"], "type": "code"}, ", ", {"text": ["vm_displace"], "type": "code"}, ", ", {"text": ["shop_vm_photon"], "type": "code"}, "\n", {"text": ["shop_vm_surface"], "type": "code"}, ", ", {"text": ["shop_vm_displace"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Controls width of curve/point primitives (see below)."]}], "indent": 0, "type": "dt", "text": [{"text": ["width"], "type": "code"}, ", ", {"text": ["pscale"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Not used by mantra."]}], "indent": 0, "type": "dt", "text": [{"text": ["scale"], "type": "code"}]}], "container": true, "type": "dt_group"}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["When mantra decides the size of point primitives, it looks for the\n    following attributes in order:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "ord", "text": ["Point attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Point attribute ", {"text": ["pscale"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Detail attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Detail attribute ", {"text": ["pscale"], "type": "code"}]}], "container": true, "type": "ord_group"}, {"indent": 4, "type": "para", "text": ["To decide the width of curve primitives, mantra looks for the\n    following attributes in order:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "ord", "text": ["Vertex attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Point attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Primitive attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Detail attribute ", {"text": ["width"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Point attribute ", {"text": ["pscale"], "type": "code"}]}], "container": true, "type": "ord_group"}], "indent": 0, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}, {"indent": 0, "type": "para", "text": ["The first attribute mantra finds controls the size/width of the\npoint/curve."]}], "indent": 0, "level": 2, "text": ["Mantra Attributes"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Renders with the last render control settings, using the path specified in ", {"text": ["Output Picture"], "type": "ui"}, "."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Render to File"]}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["If enabled, deep images and cryptomatte images will still be written out to their specified output path."]}], "indent": 4, "type": "dt", "text": ["Renders with the last render control settings, redirecting rendered frames to ", {"text": ["MPlay"], "fullpath": "/mplay", "scheme": null, "type": "link", "value": "/mplay"}, ", instead of the specified path. \n    NOTE"]}], "container": true, "type": "dt_group"}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Render to MPlay"]}, {"body": [{"indent": 4, "type": "para", "text": ["Opens the render control dialog to allow adjustments of the render parameters before rendering."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Render Control"]}, {"body": [{"indent": 4, "type": "para", "text": ["Controls whether this render node outputs the current frame (", {"text": ["Render any frame"], "type": "ui"}, ") or the image sequence specified in the ", {"text": ["Start/End/Inc"], "type": "ui"}, " parameters (", {"text": ["Render Frame Range"], "type": "ui"}, ")."]}, {"indent": 4, "type": "para", "text": [{"text": ["Render Frame Range (strict)"], "type": "ui"}, " will render frames START to END when it is rendered, but will not allow frames outside this range to be rendered at all. ", {"text": ["Render Frame Range"], "type": "ui"}, " will allow outside frames to be rendered. This is used in conjunction with render dependencies. It also affects the behavior of the 'Override Frame Range' in the Render Control dialog."]}, {"indent": 4, "type": "para", "text": ["Two possible cases where you'd want the strict behavior:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": ["A 60 frame walk cycle written out to a geo, but part of a larger ROP net to render out a larger frame range."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["A texture loop from 1-20."]}], "container": true, "type": "bullet_group"}, {"indent": 4, "type": "para", "text": ["Otherwise, you will usually set this to non-strict."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Renders a single frame, based on the value in the playbar or the frame that is requested by a connected output render node."]}], "indent": 4, "type": "dt", "text": ["Render Current Frame"]}, {"body": [{"indent": 8, "type": "para", "text": ["Renders a sequence of frames. If an output render node is connected, this range is generally ignored in favor of frames requested by the output render node."]}], "indent": 4, "type": "dt", "text": ["Render Frame Range"]}, {"body": [{"indent": 8, "type": "para", "text": ["Renders a sequence of frames. If an output render node is connected, this range restricts its requested frames to this frame range."]}], "indent": 4, "type": "dt", "text": ["Render Frame Range (Strict)"]}], "container": true, "type": "dt_group"}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Valid Frame Range"]}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the range of frames to render (start frame, end frame, and increment). All values may be floating point values. The range is inclusive. "]}, {"body": [{"body": [{"body": [{"indent": 12, "type": "para", "text": ["The number of frames to be rendered by the output driver."]}], "indent": 8, "type": "dt", "text": [{"text": ["$NRENDER"], "type": "code"}]}, {"body": [{"indent": 12, "type": "para", "text": ["The current frame being rendered (starting at 1 and going to ", {"text": ["$NRENDER"], "type": "code"}, ")."]}], "indent": 8, "type": "dt", "text": [{"text": ["$N"], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 4, "type": "para", "text": ["These parameters determine the values of the local variables for the output driver."]}, {"indent": 4, "type": "para", "text": ["For example, if the parameters are set to:"]}, {"body": [{"body": [{"indent": 4, "role": "td", "type": "cell", "text": ["10.5 "]}, {"indent": 8, "role": "td", "type": "cell", "text": ["12 "]}, {"body": [{"indent": 12, "type": "para", "text": ["0.5 |"]}], "role": "td", "type": "cell"}], "type": "row"}], "type": "table", "thead": [{"body": [{"indent": 4, "role": "th", "type": "cell", "text": ["Start "]}, {"indent": 8, "role": "th", "type": "cell", "text": ["End "]}, {"indent": 12, "role": "th", "type": "cell", "text": ["Inc "]}], "type": "row"}]}, {"indent": 4, "type": "para", "text": ["\u2026there will be 4 frames rendered (10.5, 11, 11.5, and 12), so ", {"text": ["$NRENDER"], "type": "code"}, " will have a value of 4. ", {"text": ["$N"], "type": "code"}, " will have the following values at each frame:"]}, {"body": [{"body": [{"indent": 4, "role": "td", "type": "cell", "text": ["10.5 "]}, {"body": [{"indent": 8, "type": "para", "text": ["1"]}], "role": "td", "type": "cell"}], "type": "row"}, {"body": [{"indent": 4, "role": "td", "type": "cell", "text": ["11 "]}, {"body": [{"indent": 8, "type": "para", "text": ["2"]}], "role": "td", "type": "cell"}], "type": "row"}, {"body": [{"indent": 4, "role": "td", "type": "cell", "text": ["11.5 "]}, {"body": [{"indent": 8, "type": "para", "text": ["3"]}], "role": "td", "type": "cell"}], "type": "row"}, {"body": [{"indent": 4, "role": "td", "type": "cell", "text": ["12 "]}, {"body": [{"indent": 8, "type": "para", "text": ["4"]}], "role": "td", "type": "cell"}], "type": "row"}], "type": "table", "thead": [{"body": [{"indent": 4, "role": "th", "type": "cell", "text": ["Frame "]}, {"indent": 8, "role": "th", "type": "cell", "text": [{"text": ["$N"], "type": "code"}, " "]}], "type": "row"}]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Start/End/Inc"]}, {"body": [{"indent": 4, "type": "para", "text": ["The output driver will switch to this take before rendering and then restore the current take when rendering is done."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["use ", {"text": ["chs(\"take\")"], "type": "code"}, " to use this value in other parameters. See the ", {"text": "", "value": "/expressions/chs", "fallback_text": "chs()", "fullpath": "/expressions/chs", "scheme": "Exp", "type": "link"}, " expression function for more information."]}], "indent": 4, "role": "item", "type": "tip"}], "container": true, "role": "item_group", "type": "tip_group"}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Render With Take"]}, {"body": [{"indent": 4, "type": "para", "text": ["The path the to camera object to use to render the scene, for example ", {"text": ["/obj/cam1"], "type": "code"}, "."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Camera"]}, {"body": [{"indent": 4, "type": "para", "text": ["Normally the image resolution is set on the camera object. Turn this on to enable controls that modify or override the camera\u2019s settings."]}], "indent": 0, "text": ["Override camera resolution"], "role": "item", "attrs": {"hprop": "override_camerares"}, "type": "parameters_item", "id": "override_camerares"}, {"body": [{"type": "para", "indent": 4, "text": ["When ", {"text": ["Override camera resolution"], "type": "ui"}, " is on, allows you to scale whatever resolution is set on the camera. To completely override the camera\u2019s resolution, choose \"User specified resolution\"."]}], "indent": 0, "text": ["Resolution scale"], "role": "item", "attrs": {"hprop": "res_fraction"}, "type": "parameters_item", "id": "res_fraction"}, {"body": [{"type": "para", "indent": 4, "text": ["When ", {"text": ["Override camera resolution"], "type": "ui"}, " is on and ", {"text": ["Resolution scale"], "type": "ui"}, " is \"User specified resolution\", lets you set the resolution of the output image, overriding the settings on the camera."]}], "indent": 0, "text": ["Resolution override"], "role": "item", "attrs": {"hprop": "res_override"}, "type": "parameters_item", "id": "res_override"}, {"body": [{"type": "para", "indent": 4, "text": ["The pixel aspect ratio represents the width of a pixel divided by the height of a pixel. It is not the aspect ratio of the image (which is determined by the resolution of the image). This parameter does not affect rendering, it is only used to change how images are displayed, by stretching the pixels by this factor."]}], "indent": 0, "text": ["Pixel Aspect Ratio"], "role": "item", "attrs": {"hprop": "aspect_override"}, "type": "parameters_item", "id": "aspect_override"}], "container": true, "role": "item_group", "type": "parameters_item_group"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["The image or device where the resulting image will be rendered. You can set this value to ", {"text": ["ip"], "type": "code"}, " which renders the image in MPlay, or you can save it to an image. The following image types are supported: ", {"text": [".pic"], "type": "code"}, ", ", {"text": [".tif"], "type": "code"}, ", ", {"text": [".sgi"], "type": "code"}, ", ", {"text": [".pic.gz"], "type": "code"}, ", ", {"text": [".rat"], "type": "code"}, ", ", {"text": [".jpg"], "type": "code"}, ", ", {"text": [".cin"], "type": "code"}, ", ", {"text": [".rta"], "type": "code"}, ", ", {"text": [".bmp"], "type": "code"}, ", ", {"text": [".tga"], "type": "code"}, ", ", {"text": [".rad"], "type": "code"}, ", ", {"text": [".exr"], "type": "code"}, ", and ", {"text": [".png"], "type": "code"}, "."]}, {"type": "para", "indent": 4, "text": ["Include ", {"text": ["$F"], "type": "code"}, " in the file name to insert the frame number. This is necessary when rendering animation. See ", {"text": ["expressions in file names"], "fullpath": "/render/expressions", "scheme": null, "type": "link", "value": "/render/expressions"}, " for more information."]}], "indent": 0, "text": ["Output picture"], "role": "item", "attrs": {"ifdprop": "image:filename", "hprop": "vm_picture"}, "type": "parameters_item", "id": "vm_picture"}, {"body": [{"type": "para", "indent": 4, "text": ["The image format or device for the output image.  If you leave this at the default value of ", {"text": ["Infer from filename"], "type": "ui"}, ", the image format will be selected based on the file extension (eg. .pic will automatically generate a Houdini format image.)"]}], "indent": 0, "text": ["Output device"], "role": "item", "attrs": {"ifdprop": "image:device", "hprop": "vm_device"}, "type": "parameters_item", "id": "vm_device"}, {"body": [{"indent": 4, "type": "para", "text": ["Create intermediate parent directories for output files as needed. This currently only applies to generated scripts, images, and shadow maps."]}], "indent": 0, "text": ["Create Intermediate Directories"], "role": "item", "attrs": {"id": "soho_mkpath"}, "type": "parameters_item"}, {"body": [{"type": "para", "indent": 4, "text": ["Skip rendering of existing frames.  There are three values for this\n    parameter."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["This option will render every frame, regardless whether there\u2019s a\n        file on disk or not."]}], "type": "dt", "indent": 4, "text": ["Overwrite existing frames"]}, {"body": [{"type": "para", "indent": 8, "text": ["If there\u2019s a disk file that matches the ", {"text": ["vm_picture"], "type": "code"}, " parameter, no\n        render will be performed."]}], "type": "dt", "indent": 4, "text": ["Skip frames that exist"]}, {"body": [{"type": "para", "indent": 8, "text": ["If a disk file exists, the integrity of the image is checked before\n        rendering is performed.  This option incurs the cost of reading the\n        image, but will re-render images that weren\u2019t fully rendered."]}], "type": "dt", "indent": 4, "text": ["Skip frames that are valid images"]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["Skip Existing Frames"], "role": "item", "attrs": {"id": "soho_skip_path"}, "type": "parameters_item"}], "container": true, "role": "item_group", "type": "parameters_item_group"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["Specifies the pixel filter used to combine sub-pixel samples to generate the value for the single pixel.  The filter is normally specified as a filter type (eg. ", {"text": ["gauss"], "type": "code"}, ") followed by an x and y filter width in pixels.  To blur the image, increase the filter width."]}, {"type": "para", "indent": 4, "text": ["There are several different pixel filters available."]}, {"body": [{"body": [{"type": "para", "indent": 0, "text": ["The style may be one of:"]}, {"body": [{"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["min"], "type": "code"}, " \u2013 Choose the value of the sample with the smallest z value (closest to camera)."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["max"], "type": "code"}, " \u2013 Choose the value of the sample with the maximum z value (farthest from camera)."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["median"], "type": "code"}, " \u2013 Choose the value of the sample that has the median z value of all samples."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["edge"], "type": "code"}, " \u2013 Filter using a unit box but only averages samples with object coverage.  This filter will have the effect of disabling external edge antialiasing."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["ocover"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then take the average value from the sub-pixels of that object only.  This filter is similar to ", {"text": ["edge"], "type": "code"}, " but it also disables internal edge antialiasing between object boundaries."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["idcover"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then select a single sample from that object for the pixel value.  This filter is similar to ", {"text": ["ocover"], "type": "code"}, " but it will not average any samples.  Use this filter mode for planes that will be interpreted as integers, such as object or primitive identifiers.  The sample chosen will be unordered."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["omin"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the smallest z value (closest to camera)."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["omax"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the maximum z value (farthest)."]}, {"type": "bullet", "blevel": 2, "indent": 0, "text": [{"text": ["omedian"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the median z value."]}], "type": "bullet_group", "container": true}], "type": "dt", "indent": 4, "text": [{"text": ["minmax ", {"text": ["style"], "type": "var"}], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Choose the sub-pixel closest to the center of the pixel."]}], "type": "dt", "indent": 4, "text": [{"text": ["point"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a box filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["box [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Gaussian filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["gaussian [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Bartlett (cone)  filter to combine the sub-pixels with a size width given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["bartlett [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Blackman filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["blackman [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Catmull-Rom filter to combine the sub-pixels with a size width given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["catrom [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Hanning filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["hanning [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Mitchell filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["mitchell [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a sinc filter to combine the sub-pixels with a filter size given by width/height."]}], "type": "dt", "indent": 4, "text": [{"text": ["sinc [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use an edge detection filter to find edges based on z-depth, object boundaries, and color gradients."]}], "type": "dt", "indent": 4, "text": [{"text": ["edgedetect"], "type": "code"}]}, {"body": [{"type": "para", "indent": 8, "text": ["Use a Ray Histogram Fusion-based filter to combine the sub-pixels with the given similarity tolerance."]}, {"body": [{"body": [{"type": "para", "indent": 12, "text": ["This option is very slow and may eliminate some noise in an image, even if the noise is supposed to be there (ie, not just noise due to undersampling), resulting in loss of detail. "]}], "role": "item", "indent": 8, "type": "note"}], "role": "item_group", "container": true, "type": "note_group"}], "type": "dt", "indent": 4, "text": [{"text": ["combine -t ", {"text": ["tolerance"], "type": "var"}], "type": "code"}]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["Pixel filter"], "role": "item", "attrs": {"ifdprop": "plane:pfilter", "hprop": "vm_pfilter"}, "type": "parameters_item", "id": "vm_pfilter"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls how transparent samples are combined to produce the color values for individual pixel samples. The sample filter is used to composite transparent surfaces before the pixel filter produces final pixel colors."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["Uses the opacity (Of) values for transparent samples for compositing. This option should be used whenever correct transparent compositing is required. For example, when rendering volumes, sprites, or transparency."]}], "type": "dt", "indent": 4, "text": ["Opacity Filtering (", {"text": ["alpha"], "type": "code"}, ")"]}], "type": "dt_group", "container": true}, {"type": "para", "indent": 4, "text": ["Full Opacity Filtering (", {"text": ["fullopacity"], "type": "code"}, "):\n    When stochastic transparency is enabled, this option causes a channel to be evaluated and composited with every opacity evaluation - as opposed to only being composited with the samples that are selected for full shading.  It can be used to produce smoother results for channels that are fast to evaluate such as ", {"text": ["Ce"], "type": "code"}, " or ", {"text": ["direct_emission"], "type": "code"}, ".  When stochastic transparency is disabled, this option behaves the same way as ", {"text": ["Opacity Filtering"], "type": "ui"}, "."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["Ignores the opacity values and just copies the color for the closest transparent sample into the image. This option disables transparency for a given deep raster plane and will only produce the closest sample results."]}], "type": "dt", "indent": 4, "text": ["Closest Surface (", {"text": ["closest"], "type": "code"}, ")"]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["Sample filter"], "role": "item", "attrs": {"ifdprop": "plane:sfilter", "hprop": "vm_sfilter"}, "type": "parameters_item", "id": "vm_sfilter"}, {"body": [{"type": "para", "indent": 4, "text": ["The storage type for the main image.  The type of quantization used will affect image quality and size.  If you need to adjust the image\u2019s dynamic range in compositing, you should normally leave this value at the default of 16-bit floating point."]}, {"type": "para", "indent": 4, "text": ["The default is ", {"text": ["\"float16\""], "type": "code"}, " for the first plane, and ", {"text": ["\"float\""], "type": "code"}, " for secondary planes. You can override the first plane\u2019s value with the ", {"text": ["-b"], "type": "code"}, " command line argument to mantra."]}], "indent": 0, "text": ["Quantization"], "role": "item", "attrs": {"hprop": "vm_quantize"}, "type": "parameters_item", "id": "vm_quantize"}, {"body": [], "indent": 0, "text": ["Gamma"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_gamma"}, "type": "parameters_item", "id": "vm_gamma"}, {"body": [{"type": "para", "indent": 4, "text": ["Normally, sub-pixel samples are filtered using the pixel filter defined on an image plane. When this is turned on, each sub-pixel is output without any pixel filtering performed. "]}, {"type": "para", "indent": 4, "text": ["The ", {"text": ["image:resolution"], "type": "code"}, " property will be scaled by the ", {"text": ["image:samples"], "type": "code"}, " property to determine the actual output image resolution. For example, if ", {"text": ["image:resolution"], "type": "code"}, " was ", {"text": ["(1024,512)"], "type": "code"}, " and ", {"text": ["image:samples"], "type": "code"}, " was ", {"text": ["(4,6)"], "type": "code"}, ", the image rendered would have a resolution of 4096 by 3072. Each pixel would represent a single unfiltered sub-pixel sample."]}], "indent": 0, "text": ["Sub-pixel output"], "role": "item", "attrs": {"ifdprop": "image:subpixel", "hprop": "vm_subpixel"}, "type": "parameters_item", "id": "vm_subpixel"}, {"body": [{"type": "para", "indent": 4, "text": ["When you render a target node with this option on using HQueue, the server will split frames to render into separate tiles and render each tile as a separate job. When you render locally with this option on, Mantra will render a single tile instead of the entire frame."]}, {"type": "para", "indent": 4, "text": ["Tiled render can also be enabled using ", {"text": ["-t"], "type": "code"}, " command line option to mantra, which can be used to render a tile locally without having to generate an IFD for each tile with ", {"text": ["Tiled render"], "type": "ui"}, " enabled."]}], "indent": 0, "text": ["Tiled render"], "role": "item", "attrs": {"hprop": "vm_tile_render"}, "type": "parameters_item", "id": "vm_tile_render"}, {"body": [{"type": "para", "indent": 4, "text": ["Split the frame into this number of tiles horizontally, when ", {"text": ["Tile render"], "type": "ui"}, " is on."]}], "indent": 0, "text": ["Horizontal tiles"], "role": "item", "attrs": {"ifdprop": "image:tiledrendercount", "hprop": "vm_tile_count_x"}, "type": "parameters_item", "id": "vm_tile_count_x"}, {"body": [{"type": "para", "indent": 4, "text": ["Split the frame into this number of tiles vertically, when ", {"text": ["Tile render"], "type": "ui"}, " is on."]}], "indent": 0, "text": ["Vertical tiles"], "role": "item", "attrs": {"ifdprop": "image:tiledrendercount", "hprop": "vm_tile_count_y"}, "type": "parameters_item", "id": "vm_tile_count_y"}, {"body": [{"type": "para", "indent": 4, "text": ["Which tile to render, when rendering locally with ", {"text": ["Tile render"], "type": "ui"}, " on. Tile numbers start at 0 in the top left and increase left to right, top to bottom."]}], "indent": 0, "text": ["Tile index"], "role": "item", "attrs": {"ifdprop": "image:tiledrenderindex", "hprop": "vm_tile_index"}, "type": "parameters_item", "id": "vm_tile_index"}, {"body": [{"type": "para", "indent": 4, "text": ["Renders an image from the viewing camera. Sometimes, it is useful to skip this render, for example, when rendering shadow maps."]}], "indent": 0, "text": ["Create image from viewing camera"], "role": "item", "attrs": {"hprop": "render_viewcamera"}, "type": "parameters_item", "id": "render_viewcamera"}, {"body": [{"type": "para", "indent": 4, "text": ["Enable or disable shadow map generation. Each light also has its own controls to determine whether shadow maps will be generated."]}], "indent": 0, "text": ["Auto-generate shadow maps"], "role": "item", "attrs": {"hprop": "render_any_shadowmap"}, "type": "parameters_item", "id": "render_any_shadowmap"}, {"body": [{"type": "para", "indent": 4, "text": ["Enable or disable environment map generation. Each object can be set up to generate an environment map of all the other objects in the scene."]}], "indent": 0, "text": ["Auto-generate environment maps"], "role": "item", "attrs": {"hprop": "render_any_envmap"}, "type": "parameters_item", "id": "render_any_envmap"}, {"body": [{"type": "para", "indent": 4, "text": ["Enable or disable photon map generation."]}], "indent": 0, "text": ["Auto-generate photon maps"], "role": "item", "attrs": {"hprop": "render_any_photonmap"}, "type": "parameters_item", "id": "render_any_photonmap"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Output"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["A whitespace-separated list of shading component names that will be computed for export. If you have defined new component labels in your materials, these can be added to the list so that they are exported for per-component export planes. If you are not using some components, remove them from the list to improve render efficiency."]}, {"type": "para", "indent": 4, "text": ["PBR light exports assume that this list is complete - that is, all components created by shaders are listed. If there are unlisted components, light exports may be missing illumination from these components."]}], "indent": 0, "text": ["Export components"], "role": "item", "attrs": {"ifdprop": "renderer:exportcomponents", "hprop": "vm_exportcomponents"}, "type": "parameters_item", "id": "vm_exportcomponents"}, {"body": [], "indent": 0, "text": ["Shading position (P)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_P"}, "type": "parameters_item", "id": "vm_quickplane_P"}, {"body": [], "indent": 0, "text": ["Shading depth (Pz)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Pz"}, "type": "parameters_item", "id": "vm_quickplane_Pz"}, {"body": [], "indent": 0, "text": ["Shading normal (N)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_N"}, "type": "parameters_item", "id": "vm_quickplane_N"}, {"body": [{"type": "para", "indent": 4, "text": ["Add an extra image plane for the combined lighting (all components) using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Combined lighting (per-component)"], "role": "item", "attrs": {"hprop": "vm_quickplane_all_comp"}, "type": "parameters_item", "id": "vm_quickplane_all_comp"}, {"body": [], "indent": 0, "text": ["Direct lighting (per-component)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_comp"}, "type": "parameters_item", "id": "vm_quickplane_direct_comp"}, {"body": [], "indent": 0, "text": ["Indirect lighting (per-component)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_indirect_comp"}, "type": "parameters_item", "id": "vm_quickplane_indirect_comp"}, {"body": [], "indent": 0, "text": ["Combined emission"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_all_emission"}, "type": "parameters_item", "id": "vm_quickplane_all_emission"}, {"body": [], "indent": 0, "text": ["Direct unshadowed"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_noshadow"}, "type": "parameters_item", "id": "vm_quickplane_direct_noshadow"}, {"body": [], "indent": 0, "text": ["Direct ray samples"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_samples"}, "type": "parameters_item", "id": "vm_quickplane_direct_samples"}, {"body": [], "indent": 0, "text": ["Indirect ray samples"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_indirect_samples"}, "type": "parameters_item", "id": "vm_quickplane_indirect_samples"}, {"body": [], "indent": 0, "text": ["SSS single/multi"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_sss"}, "type": "parameters_item", "id": "vm_quickplane_sss"}, {"body": [], "indent": 0, "text": ["Surface Unlit Base Color (basecolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_basecolor"}, "type": "parameters_item", "id": "vm_quickplane_basecolor"}, {"body": [], "indent": 0, "text": ["Surface Unlit Diffuse Color (diffcolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_diffcolor"}, "type": "parameters_item", "id": "vm_quickplane_diffcolor"}, {"body": [], "indent": 0, "text": ["Surface Unlit Specular Color (speccolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_speccolor"}, "type": "parameters_item", "id": "vm_quickplane_speccolor"}, {"body": [], "indent": 0, "text": ["Surface Emission Color (emitcolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_emitcolor"}, "type": "parameters_item", "id": "vm_quickplane_emitcolor"}, {"body": [], "indent": 0, "text": ["Surface SSS color (ssscolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_ssscolor"}, "type": "parameters_item", "id": "vm_quickplane_ssscolor"}, {"body": [], "indent": 0, "text": ["Surface Metallic (metallic)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_metallic"}, "type": "parameters_item", "id": "vm_quickplane_metallic"}, {"body": [], "indent": 0, "text": ["Surface Roughness (specrough)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_specrough"}, "type": "parameters_item", "id": "vm_quickplane_specrough"}, {"body": [{"type": "para", "indent": 4, "text": ["These controls let you output VEX variables as auxiliary image planes, either as extra planes in the output file or extra files."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["As of Houdini 9.1, each channel can now be written out to a different file. This lets you work with OpenEXR programs that don\u2019t support multiple channels in a single ", {"text": [".exr"], "type": "code"}, " image."]}, {"type": "para", "indent": 8, "text": ["You can also do fancy stuff like send one channel to the ", {"text": ["md"], "type": "code"}, " device (a non-interactive MPlay window), or split your image into multiple ", {"text": [".pic"], "type": "code"}, " files with a handful of ", {"text": [".tif"], "type": "code"}, " files thrown in. But if the primary image is ", {"text": ["ip"], "type": "code"}, ", all planes go to ", {"text": ["ip"], "type": "code"}, "."]}], "role": "item", "indent": 4, "type": "tip"}], "role": "item_group", "container": true, "type": "tip_group"}, {"type": "para", "indent": 4, "text": ["The Channel Name parameter lets you give the channel in the output file a different name than the default (the name of the VEX variable). For example, you want to send out the Of variable. If the Channel Name is left blank, the plane name in the ", {"text": [".pic"], "type": "code"}, " file will be ", {"text": ["Of"], "type": "code"}, ". If you set Channel Name to ", {"text": ["Opacity"], "type": "code"}, ", the plane in the ", {"text": [".pic"], "type": "code"}, " file will be called ", {"text": ["Opacity"], "type": "code"}, "."]}], "indent": 0, "text": ["Extra image planes"], "role": "item", "attrs": {"hprop": "vm_numaux"}, "type": "parameters_item", "id": "vm_numaux"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Extra image planes"], "container": true, "type": "h", "id": "extra_image_planes_tab"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["When generating an image, mantra runs the sample filter to composite samples to a single color. Mantra then runs the pixel filter to produce the final color for a pixel. A deep resolver is used to store information about each sample prior to sample filtering. This allows the image resolver to store information about each individual sample before compositing. "]}, {"type": "para", "indent": 4, "text": [{"text": ["No Deep Resolver"], "type": "code"}, ": \n    Deep image will not be output\n    ", {"text": ["Deep Shadow Map"], "type": "code"}, ":\n    Only the opacity (", {"text": ["Of"], "type": "code"}, ") and depth (", {"text": ["Pz"], "type": "code"}, ") image planes will be written out.\n    ", {"text": ["Deep Camera Map"], "type": "code"}, ":\n    All planes selected for deep images will be written out. Use the ", {"text": ["Exclude from DCM"], "type": "code"}, " toggle to leave a specific image plane from the deep image output."]}], "indent": 0, "text": ["Deep Resolver"], "role": "item", "attrs": {"ifdprop": "image:deepresolver", "hprop": "vm_deepresolver"}, "type": "parameters_item", "id": "vm_deepresolver"}, {"body": [{"type": "para", "indent": 4, "text": ["The file to generate when the Deep Camera Map resolver is used."]}], "indent": 0, "text": ["DCM Filename"], "role": "item", "attrs": {"hprop": "vm_dcmfilename"}, "type": "parameters_item", "id": "vm_dcmfilename"}, {"body": [{"type": "para", "indent": 4, "text": ["The samples stored in the deep file can be stored as either uncomposited, meaning that each sample is independent of any other sample for the same pixel; or it can be stored pre-composited, meaning that each sample stores the accumulated opacity of the sample behind it and the opacity of the sample itself."]}], "indent": 0, "text": ["DCM Pre-Composite Samples"], "role": "item", "attrs": {"hprop": "vm_dcmcompositing"}, "type": "parameters_item", "id": "vm_dcmcompositing"}, {"body": [{"type": "para", "indent": 4, "text": ["When rendering DCM, force regular/non-deep image planes to have the same pixel filtering as DCM\u2019s (i.e. Unit Box filter)."]}], "indent": 0, "text": ["Force DCM Pixel Filter on Image Planes"], "role": "item", "attrs": {"ifdprop": "image:matchdeeppixelfilter", "hprop": "vm_matchdeeppixelfilter"}, "type": "parameters_item", "id": "vm_matchdeeppixelfilter"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Deep output"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["The name of the image creator. By default uses the current user\u2019s log in name."]}, {"type": "para", "indent": 4, "text": ["Houdini, TIFF, PNG formats"]}], "indent": 0, "text": ["Artist"], "role": "item", "attrs": {"hprop": "vm_image_artist"}, "type": "parameters_item", "id": "vm_image_artist"}, {"body": [{"type": "para", "indent": 4, "text": ["A text comment to include in the output file."]}, {"type": "para", "indent": 4, "text": ["Houdini, OpenEXR, PNG formats"]}], "indent": 0, "text": ["Comment"], "role": "item", "attrs": {"hprop": "vm_image_comment"}, "type": "parameters_item", "id": "vm_image_comment"}, {"body": [{"type": "para", "indent": 4, "text": ["The name of the computer where this image was created."]}], "indent": 0, "text": ["Hostname"], "role": "item", "attrs": {"hprop": "vm_image_hostname"}, "type": "parameters_item", "id": "vm_image_hostname"}, {"body": [{"type": "para", "indent": 4, "text": ["The direction in which MPlay renders the image. Possible values are ", {"text": ["\"middle\""], "type": "code"}, " (middle out), ", {"text": ["\"top\""], "type": "code"}, " (top down), or ", {"text": ["\"bottom\""], "type": "code"}, " (bottom up)."]}], "indent": 0, "text": ["MPlay tile order"], "role": "item", "attrs": {"hprop": "vm_image_mplay_direction"}, "type": "parameters_item", "id": "vm_image_mplay_direction"}, {"body": [{"type": "para", "indent": 4, "text": ["When rendering to MPlay, all Houdini sessions will send the output to the same MPlay flipbook. This can be problematic when running multiple Houdini sessions. The MPlay Label lets you specify a label for the MPlay associated with the output driver. Only renders which match the given label will be sent to that MPlay."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["Uses the operating system process identifier so that the MPlay flipbook will only accept renders from that Houdini session."]}], "type": "dt", "indent": 4, "text": ["Houdini Process ID"]}, {"body": [{"type": "para", "indent": 8, "text": ["Uses the ", {"text": ["$HIPNAME"], "type": "code"}, " variable so the MPlay will only accept renders from the running ", {"text": ["$HIP"], "type": "code"}, " file."]}], "type": "dt", "indent": 4, "text": ["HIP Name"]}, {"body": [{"type": "para", "indent": 8, "text": ["The MPlay flipbook will only accept renders from the given output driver. For example, if you copy paste the output driver, each output driver will be sent to different MPlay flipbooks because the operators will have different names. "]}, {"type": "para", "indent": 8, "text": ["If there are multiple Houdini sessions, there may be output drivers in the other session which match the same operator name."]}, {"type": "para", "indent": 8, "text": ["For example, say you have two output drivers: \"High quality\" and \"Low Quality\". If you set the MPlay Label to different values for the two output drivers, each render will be sent to different MPlay sessions."]}], "type": "dt", "indent": 4, "text": ["Output Driver Name"]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["MPlay session label"], "role": "item", "attrs": {"hprop": "vm_image_mplay_label"}, "type": "parameters_item", "id": "vm_image_mplay_label"}, {"body": [{"type": "para", "indent": 4, "text": ["Display gamma for MPlay, from ", {"text": ["0.0"], "type": "code"}, " to ", {"text": ["4.0"], "type": "code"}, "."]}], "indent": 0, "text": ["MPlay gamma"], "role": "item", "attrs": {"hprop": "vm_image_mplay_gamma"}, "type": "parameters_item", "id": "vm_image_mplay_gamma"}, {"body": [{"type": "para", "indent": 4, "text": ["JPEG Quality, integer from ", {"text": ["10"], "type": "code"}, " to ", {"text": ["100"], "type": "code"}, "."]}], "indent": 0, "text": ["JPEG quality"], "role": "item", "attrs": {"hprop": "vm_image_jpeg_quality"}, "type": "parameters_item", "id": "vm_image_jpeg_quality"}, {"body": [{"type": "para", "indent": 4, "text": ["Type of image compression to use in TIFF files. Possible values are ", {"text": ["\"None\", \"LZW\", \"AdobeDeflate\", \"Deflate\", \"PackBits\", \"JPEG\", \"PixarLog\", \"SGILog\", \"SGILog24\""], "type": "code"}, "."]}], "indent": 0, "text": ["TIFF compression"], "role": "item", "attrs": {"hprop": "vm_image_tiff_compression"}, "type": "parameters_item", "id": "vm_image_tiff_compression"}, {"body": [{"type": "para", "indent": 4, "text": ["Compression type for EXR format images. Possible values are ", {"text": ["\"none\", \"rle\", \"zips\", \"zip\", \"piz\", \"pix\""], "type": "code"}, "."]}], "indent": 0, "text": ["EXR Compression"], "role": "item", "attrs": {"hprop": "vm_image_exr_compression"}, "type": "parameters_item", "id": "vm_image_exr_compression"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Meta data"], "container": true, "type": "h", "id": null}], "indent": 0, "level": 2, "text": ["Images"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["See ", {"text": ["understanding mantra rendering"], "fullpath": "/render/understanding", "scheme": null, "type": "link", "value": "/render/understanding"}, " for more information."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["Each primitive is diced up into micropolygons which are shaded and sampled independently."]}], "type": "dt", "indent": 4, "text": ["Micropolygon Rendering"]}, {"body": [{"type": "para", "indent": 8, "text": ["The scene is sampled by sending rays from the camera.  Each surface hit by a ray will trigger a surface shader execution."]}], "type": "dt", "indent": 4, "text": ["Ray Tracing"]}, {"body": [{"type": "para", "indent": 8, "text": ["Sampling is performed on micropolygons; however, all shading and illumination is performed using physically based rendering. "]}, {"type": "para", "indent": 8, "text": ["The number of rays used to compute shading is determined by the maximum ray-samples."]}], "type": "dt", "indent": 4, "text": ["Micropolygon Physically Based Rendering"]}, {"body": [{"type": "para", "indent": 8, "text": ["Sampling of the scene is performed using ray-tracing and shading is computed using physically based rendering."]}, {"type": "para", "indent": 8, "text": ["In this case, the pixel samples determine the shading quality of the PBR engine."]}], "type": "dt", "indent": 4, "text": ["Physically Based Rendering"]}, {"body": [{"type": "para", "indent": 8, "text": ["Rather than rendering an image, a photon map will be generated by sending photons from light sources into the scene.  The photon map file to be generated is specified on the PBR tab."]}], "type": "dt", "indent": 4, "text": ["Photon Map Generation"]}], "type": "dt_group", "container": true}, {"type": "para", "indent": 4, "text": ["Though this IFD token has an integer value, it\u2019s also possible to set the value through a string value."]}, {"body": [{"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["micropoly"], "type": "code"}, " \u2013 Micropolygon scanline rendering (default)."]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["raytrace"], "type": "code"}, " \u2013 All rendering will be performed using ray-tracing."]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["pbrmicropoly"], "type": "code"}, " \u2013 Physically Based Rendering using micro-polygon scanline rendering"]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["pbrraytrace"], "type": "code"}, " \u2013 Physically Based Rendering using ray-tracing only."]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["photon"], "type": "code"}, " \u2013 Photon map generation."]}], "type": "bullet_group", "container": true}], "indent": 0, "text": ["Render engine"], "role": "item", "attrs": {"ifdprop": "renderer:renderengine", "hprop": "vm_renderengine"}, "type": "parameters_item", "id": "vm_renderengine"}, {"body": [{"type": "para", "indent": 4, "text": ["Mantra will render with depth of field. The parameters controlling depth of field may be found on the camera object."]}], "indent": 0, "text": ["Enable depth of field"], "role": "item", "attrs": {"hprop": "vm_dof"}, "type": "parameters_item", "id": "vm_dof"}, {"body": [{"type": "para", "indent": 4, "text": ["Mantra will render the image using motion blur. The shutter parameter on the camera determines the duration of the shutter, specified as a fraction of the frame.  The ", {"text": ["Xform Time Samples"], "type": "ui"}, " and ", {"text": ["Geo Time Samples"], "type": "ui"}, " parameters should be used in motion blur renders to control how motion blur is computed.  By default, only transformation motion blur with 2 segments will be computed - meaning that animated SOPs will not produce blur in the render.  To enable motion blur for moving geometry, it\u2019s necessary to increase the ", {"text": ["Geo Time Samples"], "type": "ui"}, "."]}], "indent": 0, "text": ["Allow motion blur"], "role": "item", "attrs": {"hprop": "allowmotionblur"}, "type": "parameters_item", "id": "allowmotionblur"}, {"body": [{"type": "para", "indent": 4, "text": ["The number of transformation blur motion samples. Each object (unless the parameter exists on the object) will have this many transforms output over the shutter duration. Increasing this number will result in smoother sub-frame motion, at a small memory and compute expense. Any number of segments may be specified, though the default of 2 is often adequate unless significant nonlinear motion occurs within the shutter time for a frame."]}], "indent": 0, "text": ["Xform time samples"], "role": "item", "attrs": {"ifdprop": "object:xformsamples", "hprop": "xform_motionsamples"}, "type": "parameters_item", "id": "xform_motionsamples"}, {"body": [{"type": "para", "indent": 4, "text": ["The number of deformation blur motion samples. Each object (unless the parameter exists on the object) will have this many copies of the geometry included in the IFD. When an object is deforming it is necessary to increase this parameter to a value of 2 to see motion blurred geometry.  Any number of segments may be specified, though a value of 2 is often adequate unless significant nonlinear motion occurs within the shutter time for a frame."]}, {"type": "para", "indent": 4, "text": ["This option has no effect on objects which use velocity blur, since velocity blur is linear by nature."]}, {"type": "para", "indent": 4, "text": ["Any number of segments may be specified; however, duplicate geometry is sent down for each sample which may significantly impact the memory footprint of mantra. "]}], "indent": 0, "text": ["Geo time samples"], "role": "item", "attrs": {"ifdprop": "object:geosamples", "hprop": "geo_motionsamples"}, "type": "parameters_item", "id": "geo_motionsamples"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls where the blur occurs in the image relative to the position of the object at the current frame. A value of ", {"text": ["-1"], "type": "code"}, " blurs from the position at the previous frame to the position in the current frame. A value of ", {"text": ["0"], "type": "code"}, " blurs from halfway to the previous frame to halfway to the next frame. A value of ", {"text": ["1"], "type": "code"}, " blurs from the current position to the position at the next frame. You can use fractional frame values and values greater than ", {"text": ["-1"], "type": "code"}, " or ", {"text": ["1"], "type": "code"}, " to move the blur less or more."]}, {"type": "para", "indent": 4, "text": ["To change the ", {"text": ["size"], "type": "em"}, " of the blur, change the ", {"text": ["Shutter time"], "type": "ui"}, " (", {"text": ["shutter"], "type": "code"}, " property)."]}, {"type": "para", "indent": 4, "text": ["This parameter replaces the old ", {"text": ["Motion blur style"], "type": "ui"}, " (", {"text": ["motionstyle"], "type": "code"}, ") parameter, which only allows values of \"before\" (shutter offset=-1), \"center\" (shutter offset=0), and \"after\" (shutter offset=1)."]}], "indent": 0, "text": ["Shutter offset"], "role": "item", "attrs": {"hprop": "shutteroffset"}, "type": "parameters_item", "id": "shutteroffset"}], "container": true, "role": "item_group", "type": "parameters_item_group"}, {"body": [{"body": [{"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["Controls the number of primary rays Mantra will use to sample your scene per pixel. The two numbers represent an arrangement of samples in the X and Y axis and are generally the same number. However, for non-square pixels it may be necessary to use different values in X and Y. Multiplying these two values together will give you the number of primary rays per pixel."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/sampling_tab/PixelSampling.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling_tab/PixelSampling.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["Increasing Pixel Samples will result in a cleaner, higher quality image. However, since all other sampling values are multiplied by the number of Pixel Samples, they should only be increased when necessary. For more details on when to increase Pixel Samples, see the \u201cRemoving Noise\u201d section."]}], "indent": 0, "text": ["Pixel samples"], "role": "item", "attrs": {"ifdprop": "image:samples", "hprop": "vm_samples"}, "type": "parameters_item", "id": "vm_samples"}, {"body": [{"type": "para", "indent": 4, "text": ["Sampling color space for variance antialiasing.  Setting this to Gamma 2.2 will cause darker parts of the image to receive more samples."]}], "indent": 0, "text": ["Variance color space"], "role": "item", "attrs": {"ifdprop": "renderer:colorspace", "hprop": "vm_colorspace"}, "type": "parameters_item", "id": "vm_colorspace"}, {"body": [{"type": "para", "indent": 4, "text": ["When enabled, this parameter will cause Mantra to use ray variance antialiasing when determining the number of Secondary Rays to send for every Primary Ray."]}, {"type": "para", "indent": 4, "text": ["This means that rather than using a specific number of rays, Mantra will first send out a small number of rays and use this sample set to evaluate the Variance. Depending on the amount of various, Mantra will continue to send more rays up to the ", {"text": ["Max Ray Samples"], "type": "ui"}, " value. Ray Variance Antialiasing is useful for optimizing your render by sending more rays only in the areas they are needed."]}, {"type": "para", "indent": 4, "text": ["In cases where the minimum number of rays to remove noise is equal to the maximum number of rays, you may save a small amount of render time by disabling Ray Variance Antialiasing."]}], "indent": 0, "text": ["Ray variance anti-aliasing"], "role": "item", "attrs": {"ifdprop": "object:dorayvariance", "hprop": "vm_dorayvariance"}, "type": "parameters_item", "id": "vm_dorayvariance"}, {"body": [{"type": "para", "indent": 4, "text": ["This value is the ", {"text": ["minimum number of secondary rays"], "type": "strong"}, " to use for each BSDF type when generating an image. When ", {"text": ["Ray Variance anti-aliasing"], "type": "ui"}, " is disabled, this number represents the number of secondary rays to send regardless of the ", {"text": ["Noise Level"], "type": "ui"}, "."]}, {"type": "para", "indent": 4, "text": ["Remember, this number is multiplied by the current number of Pixel Samples ", {"text": ["and"], "type": "em"}, " the number of BSDF types on the material being evaluated."]}], "indent": 0, "text": ["Min Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:minraysamples", "hprop": "vm_minraysamples"}, "type": "parameters_item", "id": "vm_minraysamples"}, {"body": [{"type": "para", "indent": 4, "text": ["When ", {"text": ["Ray Variance anti-aliasing"], "type": "ui"}, " is enabled, this parameter represents the maximum number of secondary rays allowed for each BSDF type even if the ", {"text": ["Noise Level"], "type": "ui"}, " is never reached. This parameter, along with ", {"text": ["Min Ray Samples"], "type": "ui"}, ", essentially allows you to create a range of acceptable sampling for your image. Carefully controlling the total number of potential rays is the best way to optimize your renders."]}, {"type": "para", "indent": 4, "text": ["Remember, this number is multiplied by the current number of Pixel Samples ", {"text": ["and"], "type": "em"}, " the number of BSDF types on the material being evaluated. For example, if it\u2019s a purely diffuse material, and Pixel Samples are set to 3\u00d73, and the ", {"text": ["Max Ray Samples"], "type": "ui"}, " is set to 1, then it will cast up to 9 secondary rays (9 diffuse rays). If the material is both reflective ", {"text": ["and"], "type": "em"}, " refractive, then it will cast up to 18 secondary rays (9 reflection and 9 refraction rays)."]}, {"type": "para", "indent": 4, "text": ["For more details on when to increase ", {"text": ["Max Ray Samples"], "type": "ui"}, ", see ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, "."]}], "indent": 0, "text": ["Max Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:maxraysamples", "hprop": "vm_maxraysamples"}, "type": "parameters_item", "id": "vm_maxraysamples"}, {"body": [{"type": "para", "indent": 4, "text": ["Represents a threshold in the ", {"text": ["amount of variance allowed before mantra will send more secondary rays"], "type": "strong"}, ". Variance essentially represents how \u201cspread out\u201d the values in a set of samples are. For instance, a set of samples that were all the same would have a variance of 0. It is generally a good idea to keep this value as high as possible so that rays are sent only into those areas where an unacceptable amount of noise is present."]}, {"type": "para", "indent": 4, "text": ["Adding \u201cdirect samples\u201d and \u201cindirect samples\u201d image planes can help you track how many samples are being sent and to which parts of the image. For more information about sampling, see the \u201cSampling and Noise\u201d section."]}, {"type": "para", "indent": 4, "text": ["If you find that certain objects in your scene require substantially more samples than other parts of your image and you are unable to \u201ctarget\u201d those objects using the Noise Level parameter, it may be a better idea to add per-object sampling parameters to the problem areas. See ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, " for more details."]}], "indent": 0, "text": ["Noise Level"], "role": "item", "attrs": {"ifdprop": "object:variance", "hprop": "vm_variance"}, "type": "parameters_item", "id": "vm_variance"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls the quality of ", {"text": ["indirect diffuse"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Often, indirect sources of light (such as the surfaces of other objects, and light scattered inside of a volume) will be a significant cause of noise in your renders. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Diffuse Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary diffuse ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"type": "para", "indent": 4, "text": ["To find how much noise is in your indirect diffuse component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Diffuse component."]}], "indent": 0, "text": ["Diffuse Quality"], "role": "item", "attrs": {"ifdprop": "object:diffusequality", "hprop": "vm_diffusequality"}, "type": "parameters_item", "id": "vm_diffusequality"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls the quality of ", {"text": ["indirect reflection"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Indirect reflections (reflections of other objects in the scene) can sometimes add noise to the render. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Reflect Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary reflection ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"type": "para", "indent": 4, "text": ["To find how much noise is in your indirect reflection component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Reflection component."]}], "indent": 0, "text": ["Reflection Quality"], "role": "item", "attrs": {"ifdprop": "object:reflectionquality", "hprop": "vm_reflectionquality"}, "type": "parameters_item", "id": "vm_reflectionquality"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls the quality of ", {"text": ["indirect refraction"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Indirect refractions (refracted light from of other objects in the scene, such as when viewing an object through glass) can sometimes add noise to the render. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"type": "para", "indent": 4, "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Refract Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary refraction ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"type": "para", "indent": 4, "text": ["To find how much noise is in your indirect refraction component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Refraction component."]}], "indent": 0, "text": ["Refraction Quality"], "role": "item", "attrs": {"ifdprop": "object:refractionquality", "hprop": "vm_refractionquality"}, "type": "parameters_item", "id": "vm_refractionquality"}, {"body": [{"type": "para", "indent": 4, "text": ["Decouples the Direct from Indirect Rays, allowing for different sampling rates as well as separate noise levels. Generally speaking, it will only be necessary to enable this parameter if you find that too many samples are being sent as Direct Rays."]}, {"type": "para", "indent": 4, "text": ["Adding \u201cdirect samples\u201d and \u201cindirect samples\u201d image planes can help you track how many samples are being sent and to which parts of the image. For more information about sampling, see the \u201cSampling and Noise\u201d section."]}, {"type": "para", "indent": 4, "text": ["This parameter will enable three new parameters: ", {"text": ["Min Indirect Ray Samples"], "type": "ui"}, ", ", {"text": ["Max Indirect Ray Samples"], "type": "ui"}, ", and ", {"text": ["Indirect Noise Level"], "type": "ui"}, "."]}, {"type": "para", "indent": 4, "text": ["To understand the difference between Direct and Indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "."]}], "indent": 0, "text": ["Enable Indirect Sample Limits"], "role": "item", "attrs": {"ifdprop": "object:decoupleindirect", "hprop": "vm_decoupleindirect"}, "type": "parameters_item", "id": "vm_decoupleindirect"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["How finely or coarsely a volume is sampled as a ray travels through it. Volumetric objects are made up of 3d structures called Voxels, the value of this parameter represents the number of voxels a ray will travel through before performing another sample."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/sampling_tab/VolumeQuality.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling_tab/VolumeQuality.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["The default value is ", {"text": ["0.25"], "type": "code"}, ", which means that every one of every four voxels will be sampled. A value of ", {"text": ["1"], "type": "code"}, " would mean that all voxels are sampled and a value of 2 would mean that all voxels are sampled twice. This means that the volume step rate value behaves in a similar way to pixel samples, acting as a multiplier on the total number of samples for volumetric objects."]}, {"type": "para", "indent": 4, "text": ["For volumes that aren\u2019t voxel based, like CVEX procedural volumes, Mantra will divide the bounding box of the volume into roughly 100 \u201cvirtual\u201d voxels. In these cases, setting the Volume Step Rate correctly is essential to maintaining the correct level of detail."]}, {"type": "para", "indent": 4, "text": ["Keep in mind that increasing the volume step rate can dramatically increase render times, so it should only be adjusted when necessary. Also, while increasing the default from ", {"text": ["0.25"], "type": "code"}, " can reduce volumetric noise, increasing the value beyond ", {"text": ["1"], "type": "code"}, " will rarely see similar results."]}, {"type": "para", "indent": 4, "text": ["For more information about volume sampling, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "."]}], "indent": 0, "text": ["Volume step rate"], "role": "item", "attrs": {"ifdprop": "object:volumesteprate", "hprop": "vm_volumesteprate"}, "type": "parameters_item", "id": "vm_volumesteprate"}, {"body": [{"type": "para", "indent": 4, "text": ["A factor to proportionally decrease the volume step rate only for shadows, relative to the volume step rate. Smaller values will cause mantra to use a larger ray march step size for shadow rays than other shading rays.  A value of 1 will produce equal quality for shadow rays and shading rays."]}], "indent": 0, "text": ["Volume shadow step rate"], "role": "item", "attrs": {"ifdprop": "object:volumeshadowsteprate", "hprop": "vm_volumeshadowsteprate"}, "type": "parameters_item", "id": "vm_volumeshadowsteprate"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["The number of transparent samples to be shaded as a ray travels through translucent objects. Increasing this value will result in less noise in translucent objects and is generally less costly than increasing Pixel samples, Volume Step Rate, or Min and Max ray samples. Stochastic Sampling will not have any effect on noise from Indirect Sources however."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/sampling/VolumeSamplingStochastic.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling/VolumeSamplingStochastic.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["This may make the image noisier than without stochastic transparency, so you may need to compensate by, for example, increasing the pixel samples. You should generally leave this option on."]}, {"type": "para", "indent": 4, "text": ["The renderer ignores this option for micropolygon rendering (except for secondary ray tracing) and for renders that only generate opacity (such as deep shadow maps). In those cases it is more efficient to composite all the transparent shading results."]}, {"type": "para", "indent": 4, "text": ["Added in Houdini 12."]}], "indent": 0, "text": ["Stochastic transparency"], "role": "item", "attrs": {"ifdprop": "image:transparent", "hprop": "vm_transparent"}, "type": "parameters_item", "id": "vm_transparent"}, {"body": [{"type": "para", "indent": 4, "text": ["The number of transparent samples to shade when ", {"fragment": "#vm_transparent", "text": ["Stochastic Transparency"], "value": "#vm_transparent", "fullpath": "/props/mantra#vm_transparent", "scheme": null, "type": "link"}, " is on. Higher values improve shading quality for volumes and transparent surfaces, but are slower to render."]}], "indent": 0, "text": ["Stochastic samples"], "role": "item", "attrs": {"ifdprop": "image:transparentsamples", "hprop": "vm_transparentsamples"}, "type": "parameters_item", "id": "vm_transparentsamples"}, {"body": [{"type": "para", "indent": 4, "text": ["Sampling generally occurs in random patterns which change on every frame of an animation. This can cause a distracting \u201cbuzz\u201d when there is a significant amount of noise in your images which can make evaluation of other aspects of the scene difficult. Enabling this parameter will \u201clock\u201d the sampling patterns so that the noise remains the same on every frame."]}, {"type": "para", "indent": 4, "text": ["Also, in some cases where the final rendered images will be sent through a post-render de- noise process, it can be useful to have the noise remain constant frame to frame. Consistent sampling patterns can help when analyzing the noise."]}, {"type": "para", "indent": 4, "text": ["It defaults to \u201coff\u201d because it is generally unacceptable to have a locked sampling pattern for final sequences."]}], "indent": 0, "text": ["Sample lock"], "role": "item", "attrs": {"ifdprop": "image:samplelock", "hprop": "vm_samplelock"}, "type": "parameters_item", "id": "vm_samplelock"}, {"body": [{"type": "para", "indent": 4, "text": ["Adjusting this parameter will cause the pixel sampling patterns used by Mantra to be regenerated in different configurations. By default, the patterns change on every frame, so manually changing this value is not necessary."]}], "indent": 0, "text": ["Random seed"], "role": "item", "attrs": {"ifdprop": "renderer:randomseed", "hprop": "vm_randomseed"}, "type": "parameters_item", "id": "vm_randomseed"}, {"body": [{"type": "para", "indent": 4, "text": ["This parameter is related to the motion blur parameters which are available only when Motion Blur is enabled. Disabling this option will cause motion blur to be removed from the final rendered image, however the blurred Position will still be calculated, allowing for custom motion vector image planes to be created. For more information, see ", {"text": ["motion blur"], "fullpath": "/render/blur", "scheme": null, "type": "link", "value": "/render/blur"}, "."]}], "indent": 0, "text": ["Allow image motion blur"], "role": "item", "attrs": {"ifdprop": "renderer:imageblur", "hprop": "vm_imageblur"}, "type": "parameters_item", "id": "vm_imageblur"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Sampling"], "container": true, "type": "h", "id": "sampling_tab"}, {"body": [{"body": [{"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["The number of times a ray can be reflected in your scene."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectLimit.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["This example shows a classic \u201cHall of Mirrors\u201d scenario with the subject placed between two mirrors."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectSceneSetup.png", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectSceneSetup.png"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["This effectively creates an infinite series of reflections."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectLimitCompare.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["From this camera angle the reflection limits are very obvious and have a large impact on the accuracy of the final image. However, in most cases the reflection limit will be more subtle, allowing you to reduce the number of reflections in your scene and optimize the time it takes to render them."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectSubtleCompare.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["Remember that the first time a light source is reflected in an object, it is considered a direct reflection. Therefore, even with Reflect Limit set to 0, you will still see specular reflections of light sources."]}, {"type": "para", "indent": 4, "text": ["To control what happens when the maximum number of reflections is exceeded, use ", {"text": ["At Ray Limit"], "type": "ui"}, "."]}], "indent": 0, "text": ["Reflect limit"], "role": "item", "attrs": {"ifdprop": "object:reflectlimit", "hprop": "vm_reflectlimit"}, "type": "parameters_item", "id": "vm_reflectlimit"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["This parameter control the number of times a ray be refracted in your scene."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimit.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["This example shows a simple scene with ten grids all in a row."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractSceneSetup.png", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractSceneSetup.png"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["By applying a refractive shader, we will be able see through the grids to an image of a sunset in the background."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimitCompare.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["From this camera angle, in order for the image to be accurate, the refraction limit must match the number of grids that that are in the scene. However, most scenes will not have this number of refractive objects all in a row and so it is possible to reduce the refract limit without affecting the final image while also reducing the time it takes to render them."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractSubtleCompare.jpg"}, "\n    \ufffc\ufffc"], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["Keep in mind that this Refract Limit refers to the number of surfaces that the ray must travel through, not the number of objects."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimitSurfaces.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimitSurfaces.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["Remember that the first time a light source is refracted through a surface, it is considered a direct refraction. Therefore, even with Refract Limit set to 0, you will see refractions of Light Sources. However, since most objects in your scene will have at least two surfaces between it and the light source, direct refractions are often not evident in your final render.\n    \ufffc\n    To control what happens when the maximum number of refraction is exceeded, use ", {"text": ["At Ray Limit"], "type": "ui"}, "."]}], "indent": 0, "text": ["Refract limit"], "role": "item", "attrs": {"ifdprop": "object:refractlimit", "hprop": "vm_refractlimit"}, "type": "parameters_item", "id": "vm_refractlimit"}, {"body": [{"type": "para", "indent": 4, "text": ["The number of times diffuse rays can propagate through your scene."]}, {"body": [{"role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseLimit.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["Unlike the Reflect and Refract Limits, this parameter will increase the overall amount of light in your scene and contribute to the majority of global illumination. With this parameter set above zero diffuse surfaces will accumulate light from other objects in addition to direct light sources."]}, {"type": "para", "indent": 4, "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseLimitCompare.jpg"}]}, {"type": "para", "indent": 4, "text": ["In this example, increasing the Diffuse Limit has a dramatic effect on the appearance of the final image. To replicate realistic lighting conditions, it is often necessary to increase the Diffuse Limit. However, since the amount of light contribution usually decreases with each diffuse bounce, increasing the Diffuse Limit beyond 4 does little to improve the visual fidelity of a scene. Additionally, increasing the Diffuse Limit can dramatically increase noise levels and render times."]}, {"type": "para", "indent": 4, "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseSubtleCompare.jpg"}]}], "indent": 0, "text": ["Diffuse limit"], "role": "item", "attrs": {"ifdprop": "object:diffuselimit", "hprop": "vm_diffuselimit"}, "type": "parameters_item", "id": "vm_diffuselimit"}, {"body": [{"type": "para", "indent": 4, "text": ["The number of times a volumetric ray can propagate through a scene. It functions in a similar fashion to the ", {"text": ["Diffuse Limit"], "type": "ui"}, " parameter."]}, {"type": "para", "indent": 4, "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/VolumeLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/VolumeLimit.jpg"}]}, {"type": "para", "indent": 4, "text": ["Increasing the Volume Limit parameter will result in much more realistic volumetric effects. This is especially noticeable in situations where only part of a volume is receiving direct lighting. Also, in order for a volumetric object to receive indirect light from other objects, the Volume Limit parameter must be set above 0."]}, {"type": "para", "indent": 4, "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/VolumeLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/VolumeLimitCompare.jpg"}]}, {"type": "para", "indent": 4, "text": ["With the Volume Limit set to values above zero, the fog volume takes on the characteristic light scattering you would expect from light traveling through a volume. However, as with the Diffuse Limit, the light contribution generally decreases with each bounced ray and therefore using values above 4 does not necessarily result in a noticeably more realistic image."]}, {"type": "para", "indent": 4, "text": ["Also, increasing the value of this parameter can dramatically increase the amount of time spent rendering volumetric images."]}], "indent": 0, "text": ["Volume limit"], "role": "item", "attrs": {"ifdprop": "object:volumelimit", "hprop": "vm_volumelimit"}, "type": "parameters_item", "id": "vm_volumelimit"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["As a ray travels through many transparent surfaces, or through a volume, it will calculate the cumulative amount of Opacity. When this value exceeds the Opacity Limit mantra will assume all surfaces beyond this point are opaque."]}, {"type": "para", "indent": 8, "text": ["This parameter behaves in a similar fashion to both the Reflect and Refract Limit but operates on accumulated values rather than simply the number of surfaces the ray has passed through."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityLimitDiagram.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityLimitDiagram.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["In this example, each grid has a shader attached with an opacity value of 0.1. It is important to remember that in this case \u201ctransparent\u201d refers to objects whose opacity is less than 100% and does not include refractive objects which can appear transparent."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityLimit.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["In this example, the sphere of the left has an opacity of 0.5, with no refraction. The sphere on the right has an Opacity of 1 with refraction enabled. You can see that the Opacity Limit has no effect on the amount of refraction, only affecting objects whose opacity value is less than 1."]}, {"type": "para", "indent": 8, "text": ["While reducing the Opacity Limit may save a small amount of render time (1 \u2013 5%) using low values may result in banding and other artifacts when your camera is moving or an animation is evolving. This can be especially noticeable in smoke simulations where opacity values are constantly changing."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityVsRefract.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityVsRefract.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["The default value for Opacity Limit is quite aggressive, changing this value should be done carefully and the results inspected across a range of frames in an animated sequence."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/BadOpacityLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/BadOpacityLimit.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}], "indent": 0, "text": ["Opacity limit"], "role": "item", "attrs": {"ifdprop": "image:opacitylimit", "hprop": "vm_opacitylimit"}, "type": "parameters_item", "id": "vm_opacitylimit"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["The maximum value a shading sample is allowed to return from indirect sources. When rendering using PBR the path\u2019s total illumination is also constrained."]}, {"type": "para", "indent": 8, "text": ["Physically Based Rendering can cause \u201cspikes\u201d in color values when extremely bright indirect light sources are under sampled. This results in \u201cfireflies\u201d in the final rendered image which can be very difficult to remove without very high sampling rates."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimit.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["You can see in this example that even at 12\u00d712 pixel samples, the \u201cfireflies\u201d still remain. Adjusting Min and Max indirect rays sample settings could remove this noise, but at the cost of longer render times."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitPixelSamples.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitPixelSamples.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["Decreasing the Color Limit parameter clamps the color values in these indirect samples and can help to avoid these \u201cspikes\u201d."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitCompare.jpg"}], "indent": 4, "type": "fig"}, {"body": [{"type": "para", "indent": 8, "text": ["Reducing the color Limit can be an effective way of removing \u201cfireflies\u201d without increasing sampling rates. However, clamping the values in indirect lighting can result in an overall reduction in the amount of light in your scene. This is especially evident in scenes which are mostly illuminated by indirect light."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitCompareLight.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitCompareLight.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}], "indent": 0, "text": ["Color limit"], "role": "item", "attrs": {"ifdprop": "image:colorlimit", "hprop": "vm_colorlimit"}, "type": "parameters_item", "id": "vm_colorlimit"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 8, "text": ["Controls how Mantra deals with rays that reach the ray tracing limit (For example the ", {"text": ["Reflect Limit"], "type": "ui"}, " or ", {"text": ["Refract Limit"], "type": "ui"}, ")."]}, {"type": "para", "indent": 8, "text": ["In this example, the refract Limit has been set to 2."]}], "role": "item", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/AtRayLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/AtRayLimitCompare.jpg"}], "indent": 4, "type": "fig"}], "role": "item_group", "container": true, "type": "fig_group"}, {"type": "para", "indent": 4, "text": ["Setting At Ray Limit to ", {"text": ["Use Black Background"], "type": "ui"}, " will simply render black once the limits are reached. This is the default setting and will work in most scenes since the Reflect or Refract Limit is unlikely to be reached. However, in scenes where the limit is noticeable in the rendered image, the black color can be quite noticeable and stand out against the colors in the scene."]}, {"type": "para", "indent": 4, "text": ["In this case, increase the limit until the effect is avoided or use the ", {"text": ["Use Direct Lighting as Background Color"], "type": "ui"}, " option. This will replace the black color with whichever color or image is used in your direct lighting, for instance an Environment Light."]}, {"type": "para", "indent": 4, "text": ["For More Information about how the settings on an Environment Light affect this parameter see ", {"text": ["lighting"], "fullpath": "/render/lights", "scheme": null, "type": "link", "value": "/render/lights"}, "."]}], "indent": 0, "text": ["At ray limit"], "role": "item", "attrs": {"ifdprop": "renderer:raylimiteval", "hprop": "vm_raylimiteval"}, "type": "parameters_item", "id": "vm_raylimiteval"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Limits"], "container": true, "type": "h", "id": "limits_tab"}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["Global raytracing bias to be used for PBR rendering, specified in world space units.  Increase the raytracing bias only if doing so eliminates rendering artifacts in your render.  For really small scenes (1 unit in size), it is sometimes necessary to decrease the raytracing bias."]}], "indent": 0, "text": ["Raytracing bias"], "role": "item", "attrs": {"ifdprop": "renderer:raybias", "hprop": "vm_raybias"}, "type": "parameters_item", "id": "vm_raybias"}, {"body": [{"type": "para", "indent": 4, "text": ["When biases are used in VEX shaders, the bias can either be performed along the ray direction or along the surface normal. If this parameter is turned on, biasing will be along the surface normal - using the ", {"text": ["Ng"], "type": "code"}, " VEX variable. "]}, {"type": "para", "indent": 4, "text": ["If the ray direction and normal point in different directions, the normal will first be flipped and then biasing will be performed in the direction of the flipped normal.  This setting is particularly useful when ray traced surfaces that are seen edge-on."]}], "indent": 0, "text": ["Bias along normal"], "role": "item", "attrs": {"ifdprop": "object:biasnormal", "hprop": "vm_biasnormal"}, "type": "parameters_item", "id": "vm_biasnormal"}, {"body": [{"type": "para", "indent": 4, "text": ["To save on computation, mantra will only compute exports on surface shaders if the variable needs to be saved to an image plane.  This means that some surface exports may not be available in fog shaders for the ", {"text": ["simport()"], "type": "code"}, " function.  However, to properly render advanced features like absorption and nested dielectrics, additional exports from surface shaders are required.  This enables on these special exports."]}], "indent": 0, "text": ["Enable Absorption and Nested Dielectrics"], "role": "item", "attrs": {"ifdprop": "renderer:nesteddielectric", "hprop": "vm_nesteddielectric"}, "type": "parameters_item", "id": "vm_nesteddielectric"}, {"body": [{"type": "para", "indent": 4, "text": ["The type of path tracing to perform in PBR mode."]}, {"body": [{"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["diffuse"], "type": "code"}, " \u2013 Trace all diffuse and specular bounces, but once a diffuse bounce is encountered continue tracing only diffuse reflections."]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": [{"text": ["all"], "type": "code"}, " \u2013 All paths are traced.  This option can be used to enable rendering of caustics without the use of photon maps - however when using point or small area lights, the rendered result can turn out to be extremely noisy."]}], "type": "bullet_group", "container": true}], "indent": 0, "text": ["Allowable paths"], "role": "item", "attrs": {"ifdprop": "renderer:pbrpathtype", "hprop": "vm_pbrpathtype"}, "type": "parameters_item", "id": "vm_pbrpathtype"}, {"body": [{"type": "para", "indent": 4, "text": ["Roughness parameter in GGX BSDFs are clamped by the maximum roughness value propagated down the ray chain in pathtracing. Enabling this option can cut out a lot of noise in indirect specular (in particular, cases where glossy surface is reflected by a rough specular surface) at the cost of a bit of accuracy."]}], "indent": 0, "text": ["Constrain by Maximum Roughness"], "role": "item", "attrs": {"ifdprop": "renderer:constrainmaxrough", "hprop": "vm_constrainmaxrough"}, "type": "parameters_item", "id": "vm_constrainmaxrough"}, {"body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like refract bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Refract Components"], "role": "item", "attrs": {"ifdprop": "renderer:refractcomponents", "hprop": "vm_refractcomponents"}, "type": "parameters_item", "id": "vm_refractcomponents"}, {"body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like diffuse bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Diffuse Components"], "role": "item", "attrs": {"ifdprop": "renderer:diffusecomponents", "hprop": "vm_diffusecomponents"}, "type": "parameters_item", "id": "vm_diffusecomponents"}, {"body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like volume bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Volume Components"], "role": "item", "attrs": {"ifdprop": "renderer:volumecomponents", "hprop": "vm_volumecomponents"}, "type": "parameters_item", "id": "vm_volumecomponents"}, {"body": [{"type": "para", "indent": 4, "text": ["A space-separated list of component types that will behave like subsurface scatter bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["SSS Components"], "role": "item", "attrs": {"ifdprop": "renderer:ssscomponents", "hprop": "vm_ssscomponents"}, "type": "parameters_item", "id": "vm_ssscomponents"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Shading"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["The size (in pixels) of the tiles rendered by mantra. Larger tile sizes may consume more memory."]}], "indent": 0, "text": ["Tile size"], "role": "item", "attrs": {"ifdprop": "image:bucket", "hprop": "vm_bucketsize"}, "type": "parameters_item", "id": "vm_bucketsize"}, {"body": [{"type": "para", "indent": 4, "text": ["When enabled, automatically set the thread count (", {"text": ["renderer:threadcount"], "type": "code"}, " IFD property) to the number of CPUs of the rendering machine."]}], "indent": 0, "text": ["Use max processors"], "role": "item", "attrs": {"ifdprop": "renderer:usemaxthreads", "hprop": "vm_usemaxthreads"}, "type": "parameters_item", "id": "vm_usemaxthreads"}, {"body": [{"type": "para", "indent": 4, "text": ["When ", {"text": ["Use Max Processors"], "type": "ui"}, " (", {"text": ["renderer:usemaxthreads"], "type": "code"}, " IFD property) is disabled, sets the number of threads Mantra uses for rendering."]}], "indent": 0, "text": ["Thread count"], "role": "item", "attrs": {"ifdprop": "renderer:threadcount", "hprop": "vm_threadcount"}, "type": "parameters_item", "id": "vm_threadcount"}, {"body": [{"type": "para", "indent": 4, "text": ["Whether to use a fixed size cache (", {"text": ["vm_cachesize"], "type": "code"}, ") or whether to use a proportion of physical memory (", {"text": ["vm_cacheratio"], "type": "code"}, ")"]}], "indent": 0, "text": ["Cache Limit"], "role": "item", "attrs": {"ifdprop": "renderer:usecacheratio", "hprop": "vm_usecacheratio"}, "type": "parameters_item", "id": "vm_usecacheratio"}, {"body": [{"type": "para", "indent": 4, "text": ["The proportion of physical memory Mantra will use for its unified cache."]}, {"type": "para", "indent": 4, "text": ["For example, with the default ", {"text": ["vm_cacheratio"], "type": "code"}, " of ", {"text": ["0.25"], "type": "code"}, " and 16 Gb of physical memory, Mantra will use 4 Gb for its unified cache."]}, {"type": "para", "indent": 4, "text": ["The unified cache stores dynamic, unloadable data used by the render including the following:"]}, {"body": [{"type": "bullet", "blevel": 6, "indent": 4, "text": ["2D ", {"text": [".rat"], "type": "code"}, " texture tiles"]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": ["3D ", {"text": [".i3d"], "type": "code"}, " texture tiles"]}, {"type": "bullet", "blevel": 6, "indent": 4, "text": ["3D ", {"text": [".pc"], "type": "code"}, " point cloud pages (when not preloaded into memory)"]}, {"body": [{"body": [{"type": "bullet", "blevel": 10, "indent": 8, "text": ["Displacements"]}, {"type": "bullet", "blevel": 10, "indent": 8, "text": ["Subdivision surfaces"]}, {"type": "bullet", "blevel": 10, "indent": 8, "text": ["Bezier and NURBS primitives"]}], "type": "bullet_group", "container": true}], "type": "bullet", "blevel": 6, "indent": 4, "text": ["Tessellated meshes required by ray tracing:"]}], "type": "bullet_group", "container": true}], "indent": 0, "text": ["Cache Memory Ratio"], "role": "item", "attrs": {"ifdprop": "renderer:cacheratio", "hprop": "vm_cacheratio"}, "type": "parameters_item", "id": "vm_cacheratio"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls the type of ray tracing accelerator used by mantra. A ray tracing accelerator is a spatial data structure used to optimize the performance of ray intersection tests against complex geometry. "]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["Ray trace using a KD-Tree. Normally, the KD-Tree will produce the fastest raytracing performance at a modest initialization time. It is possible to control the performance/quality tradeoff for KD-Tree construction with the ", {"text": ["KD-Tree Memory Factor"], "type": "ui"}, " parameter (", {"text": ["vm_kdmemfactor"], "type": "code"}, "). "]}], "type": "dt", "indent": 4, "text": ["KD-Tree (", {"text": ["\"kdtree\""], "type": "code"}, ")"]}, {"body": [{"type": "para", "indent": 8, "text": ["Ray trace using a bounding volume hierarchy. Sometimes a bounding volume hierarchy will be faster to construct and/or faster to raytrace than a KD-Tree. "]}], "type": "dt", "indent": 4, "text": ["Bounding Volume Hierarchy (", {"text": ["\"bboxtree\""], "type": "code"}, ")"]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["Ray tracing accelerator"], "role": "item", "attrs": {"ifdprop": "renderer:octreestyle", "hprop": "vm_octreestyle"}, "type": "parameters_item", "id": "vm_octreestyle"}, {"body": [{"type": "para", "indent": 4, "text": ["Change the memory/performance tradeoff used when constructing KD-Tree acceleration data structures. Values larger than 1 will cause mantra to use proportionally more memory and take longer to optimize the tree in an attempt to make ray tracing faster. Smaller values will cause mantra to use proportionally less memory and take less time to optimize the tree, while possibly compromising ray tracing performance. The default value of 1 will try to balance the amount of memory used by ray tracing data structures with the amount of memory used by geometry."]}, {"type": "para", "indent": 4, "text": ["If you are noticing long tree construction times, try decreasing the KD memory factor to 0.1. If your render is too slow after tree construction, increase the value until you find a good balance of tree construction time vs. render performance."]}], "indent": 0, "text": ["KD-Tree memory factor"], "role": "item", "attrs": {"ifdprop": "renderer:kdmemfactor", "hprop": "vm_kdmemfactor"}, "type": "parameters_item", "id": "vm_kdmemfactor"}, {"body": [{"type": "para", "indent": 4, "text": ["When texture baking to UDIM images, this is the name of the texture\n    coordinate attribute used for unwrapping."]}], "indent": 0, "text": ["UV Attribute"], "role": "item", "attrs": {"ifdprop": "renderer:uvattribute", "hprop": "vm_uvattribute"}, "type": "parameters_item", "id": "vm_uvattribute"}, {"body": [{"type": "para", "indent": 4, "text": ["Perform hidden surface removal. When hidden surface removal is disabled, all surfaces in the camera\u2019s frustum will be rendered, regardless of whether they are occluded. This can impact render time significantly."]}], "indent": 0, "text": ["Enable hiding"], "role": "item", "attrs": {"ifdprop": "renderer:hidden", "hprop": "vm_hidden"}, "type": "parameters_item", "id": "vm_hidden"}, {"body": [{"type": "para", "indent": 4, "text": ["Enabling this checkbox will expand any variables in OTL paths, breaking the dependency on Houdini environment variables, but possibly making the IFD less portable."]}], "indent": 0, "text": ["Output OTLs with full paths"], "role": "item", "attrs": {"hprop": "vm_otlfullpath"}, "type": "parameters_item", "id": "vm_otlfullpath"}, {"body": [{"type": "para", "indent": 4, "text": ["Mantra is able to load the shader directly from the OTL when Houdini uses a shader defined in an OTL. When shaders are built using VOPs, the shader must be embedded in the IFD. Enabling this option will force Houdini to embed the shaders defined by OTLs."]}, {"type": "para", "indent": 4, "text": ["This option makes the IFD more self-contained so that machines which don\u2019t have the OTL installed (or a different version of the OTL) are able to evaluate the shaders correctly."]}, {"type": "para", "indent": 4, "text": ["However, if you have complicated shaders, embedding them will bloat the size of the IFD significantly."]}], "indent": 0, "text": ["Force VEX shader embedding"], "role": "item", "attrs": {"hprop": "vm_embedvex"}, "type": "parameters_item", "id": "vm_embedvex"}, {"body": [{"type": "para", "indent": 4, "text": ["Enabling this checkbox will expand any variables in OTL paths, breaking the dependency on Houdini environment variables, but possibly making the IFD less portable."]}], "indent": 0, "text": ["Output OTLs with full paths"], "role": "item", "attrs": {"hprop": "vm_otlfullpath"}, "type": "parameters_item", "id": "vm_otlfullpath"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls which style sheets defined in the hip file are embedded into the IFD. Standard Houdini pattern matching is used on each embedded style sheet name."]}], "indent": 0, "text": ["Declare style sheets"], "role": "item", "attrs": {"hprop": "declare_stylesheets"}, "type": "parameters_item", "id": "declare_stylesheets"}, {"body": [{"type": "para", "indent": 4, "text": ["Specifies which style sheets mantra should apply during rendering. This is a space separated list of either names of style sheets embedded in the hip file, or external JSON files on disk. As with individual styles within a single style sheet, style sheets later in the list take precedence over style sheets earlier in the list."]}], "indent": 0, "text": ["Apply style sheets"], "role": "item", "attrs": {"hprop": "apply_stylesheets"}, "type": "parameters_item", "id": "apply_stylesheets"}, {"body": [{"type": "para", "indent": 4, "text": ["Controls which SHOPs are embedded in the generated IFD. This parameter can be used to force all SHOPs or all Material SHOPs to be embedded even if Houdini does not find explicit references to those SHOPs on the output objects and geometry."]}], "indent": 0, "text": ["Declare materials"], "role": "item", "attrs": {"hprop": "declare_all_shops"}, "type": "parameters_item", "id": "declare_all_shops"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Render"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"type": "para", "indent": 4, "text": ["A global multiplier on all per-object ", {"fragment": "#vm_shadingquality", "text": ["shading quality"], "value": "/props/mantra#vm_shadingquality", "fullpath": "/props/mantra#vm_shadingquality", "scheme": null, "type": "link"}, " (", {"text": ["vm_shadingquality"], "type": "code"}, ") parameters in the scene.  This parameter can be used to globally increase or decrease shading quality.  The shading quality used for an object is determined by\u2026"]}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n    shadingquality = object:shadingquality * renderer:shadingfactor\n    "]}], "indent": 0, "text": ["Shading quality multiplier"], "role": "item", "attrs": {"ifdprop": "renderer:shadingfactor", "hprop": "vm_shadingfactor"}, "type": "parameters_item", "id": "vm_shadingfactor"}, {"body": [{"type": "para", "indent": 4, "text": ["Automatically adjusts the shading quality for objects which are significantly blurred. Increasing the motion factor of an object will dynamically decrease the shading quality based on the rate of motion. This can significantly speed up renderings of rapid moving objects. It also affects depth of field and may improve speed of scenes with deep depth of focus."]}, {"type": "para", "indent": 4, "text": ["Motion factor reduces shading quality using the following formula:"]}, {"lang": null, "type": "pre", "indent": 4, "text": ["\n    new shading quality = shading quality / max(pixels of motion * (1/16), 1)\n    "]}, {"type": "para", "indent": 4, "text": ["Objects traveling more than 16 pixels within the frame will have their shading quality reduced by the above factor. For example, an object blurred over 32 pixels with a shading quality of 1 will have the quality reduced to 0.5. You should not use very large values for this parameter. Values between 0 and 1 are reasonable."]}, {"type": "para", "indent": 4, "text": ["When using the Ray Tracing or Physically Based Rendering rendering engine, motion factor will only affect the geometric subdivision for subdivision surfaces, NURBS/beziers, or displacements and will not change the amount of shading."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["This parameter has only limited effect on Raytrace/PBR renders, reducing the geometry\u2019s subdivision frequency but not the shading. For more information, see ", {"text": ["Motion Factor"], "fullpath": "/render/blur", "scheme": null, "type": "link", "value": "/render/blur"}, " on the Motion blur page."]}], "role": "item", "indent": 4, "type": "note"}], "role": "item_group", "container": true, "type": "note_group"}], "indent": 0, "text": ["Motion factor"], "role": "item", "attrs": {"ifdprop": "object:motionfactor", "hprop": "vm_motionfactor"}, "type": "parameters_item", "id": "vm_motionfactor"}, {"body": [{"type": "para", "indent": 4, "text": ["When primitives are rendered in mantra, they are split into smaller primitives if they are too big to be rendered. The primitives are measured to determine if they are too big using the measurer."]}, {"type": "para", "indent": 4, "text": ["There are several different measurers available, each which take some optional arguments."]}, {"body": [{"body": [{"type": "para", "indent": 8, "text": ["This measures geometry in 3D. The ", {"text": ["Z-Importance"], "type": "ui"}, " can be used to bias the z-component of the surface. A ", {"text": ["Z-Importance"], "type": "ui"}, " of 0 means that the x and y components of the object will be the only metric in determining the size of the object. This is roughly equivalent to raster space measurement."]}, {"type": "para", "indent": 8, "text": ["By increasing the ", {"text": ["Z-Importance"], "type": "ui"}, " to 1, the z measurement becomes more meaningful. It is possible to increase the ", {"text": ["Z-Importance"], "type": "ui"}, " beyond 1."]}, {"type": "para", "indent": 8, "text": ["If you think of a grid in the XY plane, the z-importance has no effect. However, if the grid is nearly in the XZ plane, z-importance has more influence on the dicing. With a ", {"text": ["Z-Importance"], "type": "ui"}, " of 0, only the projected measurements will be used, which will result in long, thin strips being created. With a ", {"text": ["Z-Importance"], "type": "ui"}, " of 1, the grid will be more uniformly sub-divided. With a value greater than 1, more divisions will be performed in Z."]}, {"type": "para", "indent": 8, "text": ["This is important when displacement mapping is being performed. Increasing the ", {"text": ["Z-Importance"], "type": "ui"}, " will improve quality on displacement shaded ground planes (for example). The default value of 1 generally will result in sharp, high quality displacements at a shading quality of 1 for all incident angles."]}, {"type": "para", "indent": 8, "text": ["This is mantra\u2019s equivalent to prman\u2019s ", {"text": ["raster-orient"], "type": "code"}, " flag."]}], "type": "dt", "indent": 4, "text": ["Non-Raster Measuring (", {"text": ["nonraster [-z importance]"], "type": "code"}, ")"]}, {"body": [{"type": "para", "indent": 8, "text": ["Measures geometry in screen space. This is roughly equivalent to the ", {"text": ["\"nonraster -z 0\""], "type": "code"}, " measurer, so is deprecated in favor of that approach."]}], "type": "dt", "indent": 4, "text": ["Raster Space Measuring (", {"text": ["raster"], "type": "code"}, ")"]}, {"body": [{"type": "para", "indent": 8, "text": ["Generates uniform divisions. The size of the divisions is controlled by the ", {"text": ["Geometry Quality"], "type": "ui"}, " or ", {"text": ["Shading Quality"], "type": "ui"}, " in micropolygon renders."]}], "type": "dt", "indent": 4, "text": ["Uniform Measuring (", {"text": ["uniform"], "type": "code"}, ")"]}], "type": "dt_group", "container": true}], "indent": 0, "text": ["Geometry measuring"], "role": "item", "attrs": {"ifdprop": "object:measure", "hprop": "vm_measure"}, "type": "parameters_item", "id": "vm_measure"}, {"body": [{"type": "para", "indent": 4, "text": ["This parameter controls the z-importance for nonraster measuring.  See ", {"text": ["vm_measure"], "type": "code"}, " above."]}], "indent": 0, "text": ["Z-importance"], "role": "item", "attrs": {"ifdprop": "measure:zimportance", "hprop": "vm_measurezimportance"}, "type": "parameters_item", "id": "vm_measurezimportance"}, {"body": [{"type": "para", "indent": 4, "text": ["This parameter controls the shading quality scale factor for geometry that is not directly visible to the camera. For geometry that is outside the field of view (ie. visible only to secondary rays), mantra will smoothly reduce the shading quality based on the angle between the geometry and the edge of the viewing frustum.  Smaller values can increase performance particularly in scenes where the camera is within the displacement bound of nearby geometry, where it permits the hidden primitives to be diced more coarsely than those that are directly visible."]}], "indent": 0, "text": ["Offscreen Quality"], "role": "item", "attrs": {"ifdprop": "measure:offscreenquality", "hprop": "vm_measureoffscreenquality"}, "type": "parameters_item", "id": "vm_measureoffscreenquality"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 3, "text": ["Dicing"], "container": true, "type": "h", "id": null}], "indent": 0, "level": 2, "text": ["Rendering"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["The parameters on this tab determine which objects and lights are included in the IFD."]}, {"indent": 0, "type": "para", "text": ["Mantra processes these parameters in the following order:"]}, {"body": [{"indent": 0, "blevel": 2, "type": "ord", "text": ["Candidate objects/lights are selected."]}, {"indent": 0, "blevel": 2, "type": "ord", "text": ["Forced objects/lights are added. "]}, {"indent": 0, "blevel": 2, "type": "ord", "text": ["Objects/Lights matching the exclusion parameter are removed."]}], "container": true, "type": "ord_group"}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["The geometry objects in this parameter will be included in the IFD if their display flags are turned on and their display channel is enabled."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Candidate Objects"]}, {"body": [{"indent": 4, "type": "para", "text": ["Objects in this parameter are added to the IFD regardless of the state of their display. Objects can only be added to the IFD once."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Force Objects"]}, {"body": [{"indent": 4, "type": "para", "text": ["Objects forced to be output as matte objects."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Forced Matte"]}, {"body": [{"indent": 4, "type": "para", "text": ["Objects forced to be output as phantom objects."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Forced Phantom"]}, {"body": [{"indent": 4, "type": "para", "text": ["Objects in this parameter are excluded from the scene, regardless of whether they are selected in the ", {"text": ["Candidate Objects"], "type": "ui"}, " or ", {"text": ["Force Objects"], "type": "ui"}, "."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Exclude Objects"]}, {"body": [{"indent": 4, "type": "para", "text": ["Only lights in this parameter will be included in the IFD. This includes shadow map generation and illumination. If this parameter is set, the candidate, forced, and exclusion parameters are ignored."]}, {"indent": 4, "type": "para", "text": ["Using this parameter in conjunction with the ", {"text": ["render_viewcamera"], "type": "code"}, " property provides a quick way of generating shadow maps for selected lights."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Solo Light"]}, {"body": [{"indent": 4, "type": "para", "text": ["Each light in this parameter is added to the IFD if the dimmer channel of the light is not 0. The standard light sets the dimmer channel to 0 when the light is not enabled."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Candidate Lights"]}, {"body": [{"indent": 4, "type": "para", "text": ["The lights in this parameter are added to the IFD regardless of the value in their dimmer channels."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Force Lights"]}, {"body": [{"indent": 4, "type": "para", "text": ["These lights will be excluded from the scene, even if they are selected in ", {"text": ["Candidate Lights"], "type": "ui"}, " or Force Lights__."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Exclude Lights"]}, {"body": [{"indent": 4, "type": "para", "text": ["If there are no lights in the scene, a headlight is created by default. To disable, turn off this checkbox."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Headlight Creation"]}, {"body": [{"indent": 4, "type": "para", "text": ["The fog/atmosphere objects in this parameter are included in the IFD if their display flags are turned on and their display channel is enabled."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Visible Fog"]}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 2, "text": ["Objects"], "container": true, "type": "h", "id": "objects_tab"}, {"body": [{"indent": 0, "type": "para", "text": ["Each script command refers to an hscript command which will be run, regardless of the expression language selected for the parameter. The resulting string will be run as an hscript command. It is possible to use the python, unix or source hscript commands to perform complex processing."]}, {"indent": 0, "type": "para", "text": ["The commands are always run when rendering occurs. The command checks the parameters of the output driver when it is rendering a range or sending output to a command."]}, {"indent": 0, "type": "para", "text": ["Before the render occurs, Houdini will automatically set the current hscript directory to point to the output driver."]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["This command is run before any IFDs are generated. It is only run once per render."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Pre-Render Script"]}, {"body": [{"indent": 4, "type": "para", "text": ["This command is run before each IFD is generated."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Pre-Frame Script"]}, {"body": [{"indent": 4, "type": "para", "text": ["This command is run after each IFD is generated. Although the IFD may have been generated, this does not necessarily mean that mantra has finished rendering the image when this command is run."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Post-Frame Script"]}, {"body": [{"indent": 4, "type": "para", "text": ["This command is run one time, after all IFDs have been generated. Although the IFD may have been generated, this does not necessarily mean that mantra has finished rendering the image when this command is run."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Post-Render Script"]}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 2, "text": ["Scripts"], "container": true, "type": "h", "id": "scripts_tab"}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The command (i.e. mantra) where the IFD file is sent. This will be disabled if the IFD file is saved to disk."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["The Mantra ROP will not automatically gzip based on the file extension of the ", {"text": [".ifd"], "type": "code"}, " file. The file ", {"text": [".ifd.gz"], "type": "code"}, " will contain uncompressed data. However, you can set your render command to something like ", {"text": ["gzip > foo$F4.ifd.gz"], "type": "code"}, " to compress the file."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Command"]}, {"body": [{"indent": 4, "type": "para", "text": ["The location where the IFD file is saved to disk. You must turn on the Disk File checkbox to enable this parameter."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Disk File"]}, {"body": [{"indent": 4, "type": "para", "text": ["When sending the output to a command, Houdini will normally return control after it is finished writing the IFD. This allows the render process to complete in the background. Turning on this parameter will force Houdini to block until the mantra finishes rendering the frame."]}, {"indent": 4, "type": "para", "text": ["When rendering a frame range, this option is automatically turned on. However, the option is not automatically turned on when rendering in an hscript or python loop construct. Therefore caution must be used or it is possible to end up starting multiple background renders."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["The rps and rkill hscript commands can be used to query or kill background renders. "]}, {"indent": 8, "type": "para", "text": ["See the ", {"fragment": "#trouble", "text": ["Troubleshooting"], "value": "#trouble", "fullpath": "/nodes/out/ifd#trouble", "scheme": null, "type": "link"}, " section for more information."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Block Until Render Complete"]}, {"body": [{"indent": 4, "type": "para", "text": ["If this option is turned on, POP and DOP simulations will be initialized before rendering."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Initialize Simulation OPs"]}, {"body": [{"indent": 4, "type": "para", "text": ["Enabling this checkbox will cause the driver to show up in the viewport menu. By default, SOHO output drivers to not appear in the viewport menu."]}], "indent": 0, "role": "item", "type": "parameters_item", "text": ["Show In Viewport"]}, {"body": [{"type": "para", "indent": 4, "text": ["Saves binary geometry in the IFD. If this option is turned off, ASCII geometry is saved in the IFD. Binary is much more efficient. ASCII is readable."]}], "indent": 0, "text": ["Save Binary Geometry"], "role": "item", "attrs": {"hprop": "vm_binarygeometry"}, "type": "parameters_item", "id": "vm_binarygeometry"}], "container": true, "role": "item_group", "type": "parameters_item_group"}], "indent": 0, "level": 2, "text": ["Driver"], "container": true, "type": "h", "id": "driver_tab"}], "indent": 0, "level": 1, "text": "Parameters", "role": "section", "container": true, "type": "parameters_section", "id": "parameters"}, {"body": [{"body": [{"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["RenderMan"], "fullpath": "/nodes/out/rib", "scheme": "Node", "type": "link", "value": "/nodes/out/rib"}]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["How to render wireframes"], "fullpath": "/render/renderwireframes", "scheme": null, "type": "link", "value": "/render/renderwireframes"}]}], "container": true, "type": "bullet_group"}], "indent": 0, "level": 1, "text": "Related", "role": "section", "container": true, "type": "related_section", "id": "related"}], "title": ["Mantra"], "summary": ["Renders the scene using Houdini\u2019s standard mantra renderer and generates IFD files."], "attrs": {"version": null, "namespace": null, "internal": "ifd", "context": "out", "type": "node", "icon": "ROP/mantra"}, "included": ["/nodes/out/standard", "/props/_minmax_styles", "/props/mantra"], "type": "root"}