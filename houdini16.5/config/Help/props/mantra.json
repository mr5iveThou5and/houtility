{"body": [{"indent": 0, "text": ["Mantra rendering properties"], "type": "title", "level": 0}, {"body": [{"indent": 0, "type": "para", "text": ["These properties control rendering in mantra. They are in the ", {"text": ["mantra"], "type": "code"}, " folder in the list of properties available under the ", {"text": ["Render Properties"], "type": "ui"}, " tab of the ", {"text": ["Edit parameter interface window"], "fullpath": "/ref/windows/edit_parameter_interface", "scheme": null, "type": "link", "value": "/ref/windows/edit_parameter_interface"}, ". Select a node, and in the parameter editor click the ", {"text": "", "fullpath": "/props/BUTTONS/gear", "scheme": "Smallicon", "type": "link", "value": "BUTTONS/gear"}, " Gear menu and choose ", {"text": ["Edit rendering properties"], "type": "ui"}, " to add or remove properties to a render driver, camera, object, shader, or properties node."]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["All command line options to mantra (except ", {"text": ["-H"], "type": "code"}, " and ", {"text": ["-P"], "type": "code"}, ") now have property equivalents, so you can add them to the driver node instead of specifying them on the command line."]}], "indent": 0, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}, {"indent": 0, "type": "para", "text": ["For advanced users, to get a complete list of all properties defined in mantra (including undocumented properties), you can run the ", {"text": ["ray_show"], "type": "code"}, " command in mantra.  For example:"]}, {"lang": "sh", "indent": 0, "type": "pre", "text": ["\necho ray_show object | mantra\necho ray_show renderer | mantra\n"]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["Mantra reads default values from the ", {"text": ["RenderProperties.json"], "type": "code"}, " file at startup (unless the ", {"text": ["-D"], "type": "code"}, " option is specified).  This can let studios change mantra\u2019s default values for properties."]}], "indent": 0, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["Any undocumented properties may change at any time and may not be fully supported."]}], "indent": 0, "role": "item", "type": "warning"}], "container": true, "role": "item_group", "type": "warning_group"}], "indent": 0, "level": 2, "text": ["Overview"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["When generating an image, mantra runs the sample filter to composite samples to a single color. Mantra then runs the pixel filter to produce the final color for a pixel. A deep resolver is used to store information about each sample prior to sample filtering. This allows the image resolver to store information about each individual sample before compositing. "]}, {"indent": 4, "type": "para", "text": [{"text": ["No Deep Resolver"], "type": "code"}, ": \n    Deep image will not be output\n    ", {"text": ["Deep Shadow Map"], "type": "code"}, ":\n    Only the opacity (", {"text": ["Of"], "type": "code"}, ") and depth (", {"text": ["Pz"], "type": "code"}, ") image planes will be written out.\n    ", {"text": ["Deep Camera Map"], "type": "code"}, ":\n    All planes selected for deep images will be written out. Use the ", {"text": ["Exclude from DCM"], "type": "code"}, " toggle to leave a specific image plane from the deep image output."]}], "indent": 0, "text": ["Deep Resolver"], "role": "item", "attrs": {"ifdprop": "image:deepresolver", "hprop": "vm_deepresolver"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The file to generate when the Deep Camera Map resolver is used."]}], "indent": 0, "text": ["DCM Filename"], "role": "item", "attrs": {"hprop": "vm_dcmfilename"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["discrete"], "type": "code"}, " \u2013 Each depth sample represents a discrete surface."]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["continuous"], "type": "code"}, " \u2013 Each depth sample is part of a continuum (i.e. volume)."]}], "container": true, "type": "bullet_group"}], "indent": 4, "type": "para", "text": ["Deprecated in Houdini 14.5. Specifies how each pixel sample should be interpreted. Unlike some other deep image formats, mantra only writes out a single depth value for each sample."]}], "indent": 0, "text": ["DCM Interpolation"], "role": "item", "attrs": {"hprop": "vm_dcmdepthinterp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Compression value between 0 and 10. Used to limit the number of samples which are stored in a lossy compression mode for volume samples.  The compression parameter applies to opacity values, and determines the maximum possible error in opacity for each sample.  For compression greater than 0, the following relationship holds: ", {"text": ["OfError = 1/(2^(10-compression))"], "type": "code"}]}], "indent": 0, "text": ["DCM Compression"], "role": "item", "attrs": {"hprop": "vm_dcmcompression"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The samples stored in the deep file can be stored as either uncomposited, meaning that each sample is independent of any other sample for the same pixel; or it can be stored pre-composited, meaning that each sample stores the accumulated opacity of the sample behind it and the opacity of the sample itself."]}], "indent": 0, "text": ["DCM Pre-Composite Samples"], "role": "item", "attrs": {"hprop": "vm_dcmcompositing"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering DCM, force regular/non-deep image planes to have the same pixel filtering as DCM\u2019s (i.e. Unit Box filter)."]}], "indent": 0, "text": ["Force DCM Pixel Filter on Image Planes"], "role": "item", "attrs": {"ifdprop": "image:matchdeeppixelfilter", "hprop": "vm_matchdeeppixelfilter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the amount of bits to use to store opacity samples. The default is 16 bits. Larger values may cause the file size to increase substantially, with little gain in fidelty."]}, {"indent": 4, "type": "para", "text": [{"text": ["16 bit float"], "type": "code"}, ": \n    16 bit floating point values.\n    ", {"text": ["32 bit float"], "type": "code"}, ":\n    32 bit floating point values.\n    ", {"text": ["64 bit float"], "type": "code"}, ":\n    64 bit floating point values."]}], "indent": 0, "text": ["DCM Of Storage"], "role": "item", "attrs": {"hprop": "vm_dcmofstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the amount of bits to use to store opacity samples. The default is 32 bits. Smaller values may cause unnecessary discretization of samples of sample far away from the camera, but can save substantially on file size."]}, {"indent": 4, "type": "para", "text": [{"text": ["16 bit float"], "type": "code"}, ":\n    16 bit floating point values.\n    ", {"text": ["32 bit float"], "type": "code"}, ":\n    32 bit floating point values.\n    ", {"text": ["64 bit float"], "type": "code"}, ":\n    64 bit floating point values."]}], "indent": 0, "text": ["DCM Z Storage"], "role": "item", "attrs": {"hprop": "vm_dcmpzstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used in compression to merge together samples which are closer than the given threshold. Samples that are closer together than this bias value, are merged into a single sample and stored at the average z value of all the merged samples."]}], "indent": 0, "text": ["DCM Z-Bias"], "role": "item", "attrs": {"hprop": "vm_dcmzbias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Opacity is usually computed as a full-color value and stored as such. To cut down on file size, if full color is not needed, this settings can be used to store a monochromatic version of the full color value."]}, {"indent": 4, "type": "para", "text": [{"text": ["Monochrome"], "type": "code"}, ":\n    The opacity is stored as a single, grayscale channel.0\n    ", {"text": ["Full Color"], "type": "code"}, ":\n    The opacity is stored with full red, green and blue separation."]}], "indent": 0, "text": ["DCM Of Size"], "role": "item", "attrs": {"hprop": "vm_dcmofsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Deprecated in Houdini 14.5. Used in compression to determine whether to keep the nearest, the farthest or the midpoint of samples."]}, {"indent": 4, "type": "para", "text": [{"text": ["Nearest sample"], "type": "code"}, ":\n    Choose the smallest ", {"text": ["Pz"], "type": "code"}, " value.\n    ", {"text": ["Midpoint sampling"], "type": "code"}, ":\n    Choose the midpoint of ", {"text": ["Pz"], "type": "code"}, " values.\n    ", {"text": ["Farthest sample"], "type": "code"}, ": \n    Choose the largest ", {"text": ["Pz"], "type": "code"}, " value."]}], "indent": 0, "text": ["DCM Z-Sample Filter"], "role": "item", "attrs": {"hprop": "vm_dcmdepthmode"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"body": [{"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["zfront"], "type": "code"}, " \u2013 The z value of the depth sample."]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["zback"], "type": "code"}, " \u2013 For volume samples, this specifies the farthest extent of the sample."]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["deepcover"], "type": "code"}, " \u2013 Store sample coverage as a bit mask"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["deepflags"], "type": "code"}, " \u2013 Store flags indicating whether the shading sample is a volume or a matte surface."]}], "container": true, "type": "bullet_group"}], "indent": 4, "type": "dt", "text": ["Deep camera images can contain several \"special\" image planes.  These can be used to improve compositing of deep images.  The special planes currently recognized are"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["These special channels are discussed in: ", {"text": ["Improved Deep Compositing"], "scheme": null, "type": "link", "exists": true, "value": "http://research.dreamworks.com/papers/Improved_Deep_Compositing_DWA_2015.pdf"}]}], "indent": 0, "text": ["DCM Special Planes"], "role": "item", "attrs": {"hprop": "vm_dcmdepthplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to create MIP mapped images for deep camera images."]}, {"indent": 4, "type": "para", "text": ["By default, MIP maps are not created for deep camera images, since deep camera images tend to be used for deep compositing (which doesn\u2019t require MIP maps)."]}], "indent": 0, "text": ["DCM Create MIP Maps"], "role": "item", "attrs": {"hprop": "vm_dcmmipmaps"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmfilename", "text": ["DCM Filename"], "value": "#vm_dcmfilename", "fullpath": "/props/mantra#vm_dcmfilename", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Filename"], "role": "item", "attrs": {"hprop": "vm_dsmfilename"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmdepthinterp", "text": ["DCM Interpolation"], "value": "#vm_dcmdepthinterp", "fullpath": "/props/mantra#vm_dcmdepthinterp", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Interpolation"], "role": "item", "attrs": {"hprop": "vm_dsmdepthinterp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmcompression", "text": ["DCM Compression"], "value": "#vm_dcmcompression", "fullpath": "/props/mantra#vm_dcmcompression", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Compression"], "role": "item", "attrs": {"hprop": "vm_dsmcompression"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmcompositing", "text": ["DCM Pre-Composite Samples"], "value": "#vm_dcmcompositing", "fullpath": "/props/mantra#vm_dcmcompositing", "scheme": null, "type": "link"}, " for details."]}, {"indent": 4, "type": "para", "text": ["Mantra expects deep shadow images to be pre-composited.\n    If you use un-composited shadow maps, rendering may be slower or\n    generate bad results."]}], "indent": 0, "text": ["DSM Pre-Composite Samples"], "role": "item", "attrs": {"hprop": "vm_dsmcompositing"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmofstorage", "text": ["DCM Of Storage"], "value": "#vm_dcmofstorage", "fullpath": "/props/mantra#vm_dcmofstorage", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Of Storage"], "role": "item", "attrs": {"hprop": "vm_dsmofstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmpzstorage", "text": ["DCM Z Storage"], "value": "#vm_dcmpzstorage", "fullpath": "/props/mantra#vm_dcmpzstorage", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Z Storage"], "role": "item", "attrs": {"hprop": "vm_dsmpzstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmzbias", "text": ["DCM Z-Bias"], "value": "#vm_dcmzbias", "fullpath": "/props/mantra#vm_dcmzbias", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Z-Bias"], "role": "item", "attrs": {"hprop": "vm_dsmzbias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmofsize", "text": ["DCM Of Size"], "value": "#vm_dcmofsize", "fullpath": "/props/mantra#vm_dcmofsize", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Of Size"], "role": "item", "attrs": {"hprop": "vm_dsmofsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"fragment": "#vm_dcmdepthmode", "text": ["DCM Z-Sample Filter"], "value": "#vm_dcmdepthmode", "fullpath": "/props/mantra#vm_dcmdepthmode", "scheme": null, "type": "link"}, " for details."]}], "indent": 0, "text": ["DSM Z-Sample Filter"], "role": "item", "attrs": {"hprop": "vm_dsmdepthmode"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"body": [{"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["zfront"], "type": "code"}, " \u2013 The z value of the depth sample."]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["zback"], "type": "code"}, " \u2013 For volume samples, this specifies the farthest extent of the sample."]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["deepcover"], "type": "code"}, " \u2013 Store sample coverage as a bit mask"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["deepflags"], "type": "code"}, " \u2013 Store flags indicating whether the shading sample is a volume or a matte surface."]}], "container": true, "type": "bullet_group"}], "indent": 4, "type": "dt", "text": ["Deep shadow images can contain several \"special\" image planes.  These can be used to improve compositing of deep images.  The special planes currently recognized are"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["These special channels are discussed in: ", {"text": ["Improved Deep Compositing"], "scheme": null, "type": "link", "exists": true, "value": "http://research.dreamworks.com/papers/Improved_Deep_Compositing_DWA_2015.pdf"}]}], "indent": 0, "text": ["DSM Special Planes"], "role": "item", "attrs": {"hprop": "vm_dsmdepthplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to create MIP mapped images for deep shadow images."]}, {"indent": 4, "type": "para", "text": ["By default, MIP maps are created for deep shadow images, since shadow evaluation can make use of MIP maps for filtering."]}], "indent": 0, "text": ["DSM Create MIP Maps"], "role": "item", "attrs": {"hprop": "vm_dsmmipmaps"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Deep Output"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The number of cryptomatte layers to output. This must be set to 1 or higher to enable the cryptomatte resolver. The cryptomatte resolver is used to store the ID (based on hash of user-specified string property) and opacity pair of each sample prior to sample filtering."]}], "indent": 0, "text": ["Cryptomatte Layers"], "role": "item", "attrs": {"hprop": "vm_cryptolayers"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Property to generate IDs from. ", {"text": ["materialname"], "type": "code"}, " and ", {"text": ["name"], "type": "code"}, " are built-in property names for material path and object path respectively. It can also be any object property of string type, including user property."]}], "indent": 0, "text": ["Property"], "role": "item", "attrs": {"hprop": "vm_cryptolayerprop"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Channel name used to store current layer."]}], "indent": 0, "text": ["Channel Name"], "role": "item", "attrs": {"hprop": "vm_cryptolayername"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Maximum number of IDs that can be stored in a single pixel. A value of 6 is recommended."]}], "indent": 0, "text": ["Overlap limit"], "role": "item", "attrs": {"hprop": "vm_cryptolayerrank"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Output path of the cryptomatte layer. OpenEXR format recommended. Each layer must be written to a unique file. The layer will be disabled if the output file name is in use by another layer."]}], "indent": 0, "text": ["Output Picture"], "role": "item", "attrs": {"hprop": "vm_cryptolayeroutput"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Optional external manifest file. It will be saved into same directory as the ", {"text": ["Output Picture"], "type": "code"}, ". If this path is unspecified, the manifest will be embedded into ", {"text": ["Output Picture"], "type": "code"}, " as metadata."]}], "indent": 0, "text": ["Manifest File"], "role": "item", "attrs": {"hprop": "vm_cryptolayersidecar"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Cryptomatte"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["A global multiplier on all per-object ", {"fragment": "#vm_shadingquality", "text": ["shading quality"], "value": "/props/mantra#vm_shadingquality", "fullpath": "/props/mantra#vm_shadingquality", "scheme": null, "type": "link"}, " (", {"text": ["vm_shadingquality"], "type": "code"}, ") parameters in the scene.  This parameter can be used to globally increase or decrease shading quality.  The shading quality used for an object is determined by\u2026"]}, {"lang": null, "indent": 4, "type": "pre", "text": ["\n    shadingquality = object:shadingquality * renderer:shadingfactor\n    "]}], "indent": 0, "text": ["Shading quality multiplier"], "role": "item", "attrs": {"ifdprop": "renderer:shadingfactor", "hprop": "vm_shadingfactor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the geometric subdivision resolution for all rendering engines and additionally controls the shading resolution for micropolygon rendering.  With all other parameters at their defaults, a value of 1 means that approximately 1 micropolygon will be created per pixel.  A higher value will generate smaller micropolygons meaning that more shading will occur - but the quality will be higher."]}, {"indent": 4, "type": "para", "text": ["In ray tracing engines, shading quality only affects the geometric subdivision quality for smooth surfaces (NURBS, render as subdivision) and for displacements - without changing the amount of surface shading.  When using ray tracing, pixel samples and ray sampling parameters must be used to improve surface shading quality."]}, {"indent": 4, "type": "para", "text": ["The effect of changing the shading quality is to increase or decrease the amount of shading by a factor of ", {"text": ["vm_shadingquality"], "type": "code"}, " ", {"text": ["squared"], "type": "strong"}, " - so a shading quality of 2 will perform 4 times as much shading and a shading quality of 0.5 will perform 1/4 times as much shading."]}], "indent": 0, "text": ["Shading quality"], "role": "item", "attrs": {"ifdprop": "object:shadingquality", "hprop": "vm_shadingquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering a curve, turns the curve into a surface and dices the surface, running the surface shader on multiple points across the surface. This may be useful when the curves become curved surfaces, but is less efficient. The default is to simply run the shader on the points of the curve and duplicate those shaded points across the created surface."]}], "indent": 0, "text": ["Shade curves as surfaces"], "role": "item", "attrs": {"ifdprop": "object:curvesurface", "hprop": "vm_curvesurface"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Automatically adjusts the shading quality for objects which are significantly blurred. Increasing the motion factor of an object will dynamically decrease the shading quality based on the rate of motion. This can significantly speed up renderings of rapid moving objects. It also affects depth of field and may improve speed of scenes with deep depth of focus."]}, {"indent": 4, "type": "para", "text": ["Motion factor reduces shading quality using the following formula:"]}, {"lang": null, "indent": 4, "type": "pre", "text": ["\n    new shading quality = shading quality / max(pixels of motion * (1/16), 1)\n    "]}, {"indent": 4, "type": "para", "text": ["Objects traveling more than 16 pixels within the frame will have their shading quality reduced by the above factor. For example, an object blurred over 32 pixels with a shading quality of 1 will have the quality reduced to 0.5. You should not use very large values for this parameter. Values between 0 and 1 are reasonable."]}, {"indent": 4, "type": "para", "text": ["When using the Ray Tracing or Physically Based Rendering rendering engine, motion factor will only affect the geometric subdivision for subdivision surfaces, NURBS/beziers, or displacements and will not change the amount of shading."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["This parameter has only limited effect on Raytrace/PBR renders, reducing the geometry\u2019s subdivision frequency but not the shading. For more information, see ", {"text": ["Motion Factor"], "fullpath": "/render/blur", "scheme": null, "type": "link", "value": "/render/blur"}, " on the Motion blur page."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["Motion factor"], "role": "item", "attrs": {"ifdprop": "object:motionfactor", "hprop": "vm_motionfactor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When primitives are rendered in mantra, they are split into smaller primitives if they are too big to be rendered. The primitives are measured to determine if they are too big using the measurer."]}, {"indent": 4, "type": "para", "text": ["There are several different measurers available, each which take some optional arguments."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["This measures geometry in 3D. The ", {"text": ["Z-Importance"], "type": "ui"}, " can be used to bias the z-component of the surface. A ", {"text": ["Z-Importance"], "type": "ui"}, " of 0 means that the x and y components of the object will be the only metric in determining the size of the object. This is roughly equivalent to raster space measurement."]}, {"indent": 8, "type": "para", "text": ["By increasing the ", {"text": ["Z-Importance"], "type": "ui"}, " to 1, the z measurement becomes more meaningful. It is possible to increase the ", {"text": ["Z-Importance"], "type": "ui"}, " beyond 1."]}, {"indent": 8, "type": "para", "text": ["If you think of a grid in the XY plane, the z-importance has no effect. However, if the grid is nearly in the XZ plane, z-importance has more influence on the dicing. With a ", {"text": ["Z-Importance"], "type": "ui"}, " of 0, only the projected measurements will be used, which will result in long, thin strips being created. With a ", {"text": ["Z-Importance"], "type": "ui"}, " of 1, the grid will be more uniformly sub-divided. With a value greater than 1, more divisions will be performed in Z."]}, {"indent": 8, "type": "para", "text": ["This is important when displacement mapping is being performed. Increasing the ", {"text": ["Z-Importance"], "type": "ui"}, " will improve quality on displacement shaded ground planes (for example). The default value of 1 generally will result in sharp, high quality displacements at a shading quality of 1 for all incident angles."]}, {"indent": 8, "type": "para", "text": ["This is mantra\u2019s equivalent to prman\u2019s ", {"text": ["raster-orient"], "type": "code"}, " flag."]}], "indent": 4, "type": "dt", "text": ["Non-Raster Measuring (", {"text": ["nonraster [-z importance]"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Measures geometry in screen space. This is roughly equivalent to the ", {"text": ["\"nonraster -z 0\""], "type": "code"}, " measurer, so is deprecated in favor of that approach."]}], "indent": 4, "type": "dt", "text": ["Raster Space Measuring (", {"text": ["raster"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Generates uniform divisions. The size of the divisions is controlled by the ", {"text": ["Geometry Quality"], "type": "ui"}, " or ", {"text": ["Shading Quality"], "type": "ui"}, " in micropolygon renders."]}], "indent": 4, "type": "dt", "text": ["Uniform Measuring (", {"text": ["uniform"], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Geometry measuring"], "role": "item", "attrs": {"ifdprop": "object:measure", "hprop": "vm_measure"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the z-importance for nonraster measuring.  See ", {"text": ["vm_measure"], "type": "code"}, " above."]}], "indent": 0, "text": ["Z-importance"], "role": "item", "attrs": {"ifdprop": "measure:zimportance", "hprop": "vm_measurezimportance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the shading quality scale factor for geometry that is not directly visible to the camera. For geometry that is outside the field of view (ie. visible only to secondary rays), mantra will smoothly reduce the shading quality based on the angle between the geometry and the edge of the viewing frustum.  Smaller values can increase performance particularly in scenes where the camera is within the displacement bound of nearby geometry, where it permits the hidden primitives to be diced more coarsely than those that are directly visible."]}], "indent": 0, "text": ["Offscreen Quality"], "role": "item", "attrs": {"ifdprop": "measure:offscreenquality", "hprop": "vm_measureoffscreenquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter sets a minimum rendering width, in raster space, for curves and points. \n    Any point, or curve segment, smaller than this value, at the projected point, will \n    instead have its opacity scaled down as a ratio of the minimum width and\n    the actual width. This helps rendering very small points and thin curves, \n    such as hair and fur, without having to adversely increase the pixel samples to \n    compensate."]}, {"indent": 4, "type": "para", "text": ["This value should be kept at around 0.5 to 1.0. Larger values may significantly \n    increase render time, since the geometry is wider and more transparent samples \n    may be taken. A value of 0 disables the option."]}, {"indent": 4, "type": "para", "text": ["This option can be used in conjunction with ", {"fragment": "#vm_transparent", "text": ["Stochastic Transparency"], "value": "#vm_transparent", "fullpath": "/props/mantra#vm_transparent", "scheme": null, "type": "link"}, "\n    for additional performance."]}], "indent": 0, "text": ["Geometry Filter Width"], "role": "item", "attrs": {"ifdprop": "object:geofilterwidth", "hprop": "vm_geofilterwidth"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This property controls the tesselation levels for nearly flat primitives. By increasing the value, more primitives will be considered flat and will be sub-divided less. Turn this option ", {"text": ["down"], "type": "em"}, " for more accurate (less optimized) nearly-flat surfaces."]}], "indent": 0, "text": ["Dicing flatness"], "role": "item", "attrs": {"ifdprop": "object:flatness", "hprop": "vm_flatness"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This property will cause this object to generate all displaced and subdivided geometry before the render begins. Ray tracing can be significantly faster when this setting is enabled at the cost of potentially huge memory requirements."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Geometry is diced when it is hit by a ray."]}], "indent": 4, "type": "dt", "text": [{"text": ["Disable Predicing"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Generate and store all diced geometry at once."]}], "indent": 4, "type": "dt", "text": [{"text": ["Full Predicing"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Generate all diced geometry just to compute accurate bounding boxes.  This setting will discard the diced geometry as soon as the box has been computed, so it is very memory efficient.  This can be useful to improve efficiency when using displacements with a large displacement bound without incurring the memory cost of full predicing."]}], "indent": 4, "type": "dt", "text": [{"text": ["Precompute Bounds"], "type": "code"}]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["When ray-tracing, if all polygons on the model are visible (either to primary or secondary rays) it can be more efficient to pre-dice all the geometry in that model rather than caching portions of the geometry and re-generating the geometry on the fly. This is especially true when global illumination is being computed (since there is less coherency among rays)."]}, {"indent": 4, "type": "para", "text": ["Currently not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Ray predicing"], "role": "item", "attrs": {"ifdprop": "object:raypredice", "hprop": "vm_raypredice"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Dicing"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Saves binary geometry in the IFD. If this option is turned off, ASCII geometry is saved in the IFD. Binary is much more efficient. ASCII is readable."]}], "indent": 0, "text": ["Save Binary Geometry"], "role": "item", "attrs": {"hprop": "vm_binarygeometry"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Writes geometry into the IFD file. When this is off, Houdini writes geometry to external temporary files instead. Leaving this option off (the default) makes rendering faster and uses less disk space. See ", {"text": ["IFD geometry"], "fullpath": "/render/geometry", "scheme": null, "type": "link", "value": "/render/geometry"}, " for more information."]}, {"indent": 4, "type": "para", "text": ["See also ", {"fragment": "#vm_tmpsharedstorage", "text": ["Shared temp storage"], "value": "/props/mantra#vm_tmpsharedstorage", "fallback_text": "vm_tmpsharedstorage", "fullpath": "/props/mantra#vm_tmpsharedstorage", "scheme": "Mantra", "type": "link"}, " and ", {"fragment": "#vm_tmplocalstorage", "text": ["Local temp storage"], "value": "/props/mantra#vm_tmplocalstorage", "fallback_text": "vm_tmplocalstorage", "fullpath": "/props/mantra#vm_tmplocalstorage", "scheme": "Mantra", "type": "link"}, "."]}], "indent": 0, "text": ["Save Geometry Inline"], "role": "item", "attrs": {"default": "False", "hprop": "vm_inlinestorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Normally, when ", {"fragment": "#vm_inlinestorage", "text": ["Save inline geometry"], "value": "/props/mantra#vm_inlinestorage", "fallback_text": "vm_inlinestorage", "fullpath": "/props/mantra#vm_inlinestorage", "scheme": "Mantra", "type": "link"}, " is off, Houdini always writes geometry files during IFD generation, overwriting any existing files. When this option is on, if a file of the same name already exists, Houdini will re-use the existing geometry files instead of overwriting it. This does ", {"text": ["not"], "type": "em"}, " compare file modification times, it ", {"text": ["only"], "type": "em"}, " checks the file name, so after geometry is generated once it will never be updated as long as this is on. Turning this on can speed up lighting significantly, as long as you know you won\u2019t be updating your geometry."]}, {"indent": 4, "type": "para", "text": ["If you add this property, remember to always turn it off for final renders to ensure you get the up-to-date geometry."]}], "indent": 0, "text": ["Reuse cached outlined geometry"], "role": "item", "attrs": {"hprop": "vm_reuseoutlinecache"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"fragment": "#vm_inlinestorage", "text": ["Save inline geometry"], "value": "/props/mantra#vm_inlinestorage", "fallback_text": "vm_inlinestorage", "fullpath": "/props/mantra#vm_inlinestorage", "scheme": "Mantra", "type": "link"}, " is off, Houdini saves geometry files to this directory when you save an IFD."]}, {"indent": 4, "type": "para", "text": ["You can use ", {"text": ["$F"], "type": "code"}, " (for example ", {"text": ["$HIP/ifds/storage/frame$F4"], "type": "code"}, ") to create separate directories for each frame. This helps avoid filename collisions and makes cleanup easier."]}, {"indent": 4, "type": "para", "text": ["See also ", {"fragment": "#vm_tmplocalstorage", "text": ["Local temp storage"], "value": "/props/mantra#vm_tmplocalstorage", "fallback_text": "vm_tmplocalstorage", "fullpath": "/props/mantra#vm_tmplocalstorage", "scheme": "Mantra", "type": "link"}, "."]}], "indent": 0, "text": ["Shared temp storage"], "role": "item", "attrs": {"hprop": "vm_tmpsharedstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"fragment": "#vm_inlinestorage", "text": ["Save inline geometry"], "value": "#vm_inlinestorage", "fullpath": "/props/mantra#vm_inlinestorage", "scheme": null, "type": "link"}, " is off, Houdini saves geometry files to  this directory when you pipe an IFD ", {"text": ["directly"], "type": "em"}, " to Mantra (as opposed to saving the IFD to disk). This is useful because you may be saving IFDs to a network disk, but when you pipe directly to Mantra you want to always use fast local storage and avoid slow network storage."]}, {"indent": 4, "type": "para", "text": ["Temporary files stored for pipes should automatically be cleaned up, but due to crashes or interrupted jobs, Houdini might leave these files on disk. You should periodically remove any old files left in this directory."]}, {"indent": 4, "type": "para", "text": ["See also ", {"fragment": "#vm_tmpsharedstorage", "text": ["Shared temp storage"], "value": "/props/mantra#vm_tmpsharedstorage", "fallback_text": "vm_tmpsharedstorage", "fullpath": "/props/mantra#vm_tmpsharedstorage", "scheme": "Mantra", "type": "link"}, "."]}], "indent": 0, "text": ["Local temp storage"], "role": "item", "attrs": {"default": "\"$HOUDINI_TEMP_DIR/ifds/storage\"", "hprop": "vm_tmplocalstorage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enabling this option will cause mantra to abort the render with an error if it encounters a missing texture map."]}], "indent": 0, "text": ["Abort on missing texture"], "role": "item", "attrs": {"ifdprop": "renderer:abortmissingtexture", "hprop": "vm_abort_missing_texture"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter can be used to specify a JSON file containing overrides for default property values.  See also the ", {"text": ["-D"], "type": "code"}, "command line option on mantra and the default render properties in ", {"text": ["$HH/RenderProperties.json"], "type": "code"}]}], "indent": 0, "text": ["Mantra Defaults"], "role": "item", "attrs": {"hprop": "vm_defaults"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Driver"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["When baking, instead of writing shading position ", {"text": ["P"], "type": "code"}, " raw, it will be normalized to 0~1 based on bounding cube of the UV Object."]}], "indent": 0, "text": ["Fit P To Object Bounding Box"], "role": "item", "attrs": {"ifdprop": "renderer:bake_normalizep", "hprop": "vm_bake_normalizep"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, image planes contained in the output image will be extracted to separate files. The files will be saved alongside the output image, in the format: <basename>.<plane name>.<extension>."]}], "indent": 0, "text": ["Extract image planes"], "role": "item", "attrs": {"ifdprop": "renderer:extractimageplanes", "hprop": "vm_extractimageplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Determines the file format to use when extracting image planes to separate files."]}], "indent": 0, "text": ["Extract image planes format"], "role": "item", "attrs": {"ifdprop": "renderer:extractimageplanesformat", "hprop": "vm_extractimageplanesformat"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, intermediate output file (vm_uvoutputpicture) will be deleted after the image planes have been extracted."]}], "indent": 0, "text": ["Remove Intermediate Output"], "role": "item", "attrs": {"ifdprop": "renderer:extractremoveintermediate", "hprop": "vm_extractremoveintermediate"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This pattern specifies planes which should be extracted in linear color space rather than the color space of the image format.  For example, if gamma correction is applied to tangent planes when saving to JPG or Targa images, there can be significant precision lost."]}], "indent": 0, "text": ["Extract linear planes"], "role": "item", "attrs": {"ifdprop": "renderer:extractlinearplanes", "hprop": "vm_extractlinearplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Comma-separated list of planes that will have the alpha channel (copied from the primary plane). Alpha data comes from before the UDIM post-processing. Note that alpha will not be premultiplied, even if the extract format expects it (such as EXR format)."]}], "indent": 0, "text": ["Copy alpha to planes"], "role": "item", "attrs": {"ifdprop": "renderer:bake_alphadestplanes", "hprop": "vm_bake_alphadestplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When extracting images for baking, this is the separator string that\u2019s inserted between the filename and the channel name.  For with a separator of ", {"text": ["."], "type": "code"}, ", the extracted image might be ", {"text": ["texture.Nt.png"], "type": "code"}, " instead of ", {"text": ["texture_Nt.png"], "type": "code"}, "."]}], "indent": 0, "text": ["Name Separator"], "role": "item", "attrs": {"ifdprop": "renderer:extractseparator", "hprop": "vm_extractseparator"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A whitespace-separated list of shading component names that will be computed for export. If you have defined new component labels in your materials, these can be added to the list so that they are exported for per-component export planes. If you are not using some components, remove them from the list to improve render efficiency."]}, {"indent": 4, "type": "para", "text": ["PBR light exports assume that this list is complete - that is, all components created by shaders are listed. If there are unlisted components, light exports may be missing illumination from these components."]}], "indent": 0, "text": ["Export components"], "role": "item", "attrs": {"ifdprop": "renderer:exportcomponents", "hprop": "vm_exportcomponents"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Show extra image plane parameters"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_showextraplaneparms"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shading position (P)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_P"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shading depth (Pz)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Pz"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shading normal (N)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_N"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shading tangent-space normal (Nt)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Nt"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Direct lighting (per-component)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_comp"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Indirect lighting (per-component)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_indirect_comp"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Combined emission"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_all_emission"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Direct unshadowed"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_noshadow"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Direct Unshadowed (per-component, PBR only)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_noshadow_comp"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Direct ray samples"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_direct_samples"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Indirect ray samples"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_indirect_samples"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["SSS single/multi"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_sss"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Unlit Base Color (basecolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_basecolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Unlit Diffuse Color (diffcolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_diffcolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Unlit Specular Color (speccolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_speccolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Emission Color (emitcolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_emitcolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface SSS color (ssscolor)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_ssscolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Metallic (metallic)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_metallic"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface Roughness (specrough)"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_specrough"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Nt Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Nt_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Ds Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Ds_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Vd Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Vd_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Vdt Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Vdt_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Oc Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Oc_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Cv Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Cv_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Th Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Th_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Cu Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Cu_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["P Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_P_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["N Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_N_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Pz Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Pz_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Ab Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_Ab_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["basecolor Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_basecolor_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["diffcolor Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_diffcolor_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["speccolor Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_speccolor_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["emitcolor Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_emitcolor_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["ssscolor Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_ssscolor_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["metallic Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_metallic_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["specrough Channel Name"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_quickplane_specrough_channel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Generate Op IDs for objects"], "role": "item", "attrs": {"hprop": "vm_generate_opid"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Extra image planes"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Mantra only runs atmosphere shaders after surface shaders have been run. This means that there are no atmosphere shaders run if there are no objects rendered. When this setting is true, a giant box is created surrounding the scene. The box has a matte shader applied. The size of the box is determined by ", {"text": ["sqrt(1/3) * ", {"text": ["far_clip"], "type": "var"}], "type": "code"}, " (the camera\u2019s far clipping plane)."]}], "indent": 0, "text": ["Add background for fog"], "role": "item", "attrs": {"ifdprop": "renderer:fogbackground", "hprop": "vm_fogbackground"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Fog"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [], "indent": 0, "text": ["Float precision"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_precision"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Safe object names"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_almostzero"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Indent step"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_indentstep"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Line wrap"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_linewrap"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Almost zero"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_almostzero"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Formatting"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["When geometry has shaders defined on a per-primitive basis, this parameter will override these shaders and use only the object\u2019s shader. This is useful when performing matte shading on objects."]}, {"indent": 4, "type": "para", "text": ["Not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Ignore geometry attribute shaders"], "role": "item", "attrs": {"ifdprop": "object:overridedetail", "hprop": "vm_overridedetail"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies comma separated list of names for the velocity field for volume primitives."]}], "indent": 0, "text": ["Volume Velocity Names"], "role": "item", "attrs": {"ifdprop": "geometry:volumevelocitynames", "hprop": "vm_volumevelocitynames"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Normally, mantra will create an internal representation for curve primitives which can be used to accelerate curve intersection.  However, this internal representation consumes memory.  This setting will avoid creation of the internal representation until it\u2019s actually required by mantra.  This improves start-up time and keeps memory down but requires more compute cycles to perform intersections."]}, {"indent": 4, "type": "para", "text": ["For IPR, turning on JIT curves can improve interactivity for scenes with a lot of curves (i.e. hair or fur)."]}], "indent": 0, "text": ["Just In Time Curve Creation"], "role": "item", "attrs": {"ifdprop": "object:jitcurves", "hprop": "vm_jitcurves"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how material overrides are evaluated and output to the IFD. "]}, {"indent": 4, "type": "para", "text": ["When set to ", {"text": ["Evaluate Once"], "type": "ui"}, ", any parameter on the material, that\n    uses channels or expressions, will be evaluated only once\n    for the entire detail. This results in significantly faster IFD \n    generation, due to the material parameter assignment being handled\n    entirely by Mantra, rather than Houdini. \n    Setting the parameter value to ", {"text": ["Evaluate for Each Primitive/Point"], "type": "ui"}, "  \n    will evaluate those parameters for each primitive and/or point. \n    It\u2019s also possible to skip material overrides entirely by setting \n    the parameter value to ", {"text": ["Disabled"], "type": "ui"}, "."]}], "indent": 0, "text": ["Material Override"], "role": "item", "attrs": {"ifdprop": "geometry:materialoverride", "hprop": "vm_materialoverride"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Geometry SHOP used by the renderer to generate render geometry for this object."]}], "indent": 0, "text": ["Procedural shader"], "role": "item", "attrs": {"hprop": "shop_geometrypath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Auto-archiving"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_auto_archive"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Geometry disk file"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_archive"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Render Polygon Curves as Subdivision (Mantra)"], "role": "item", "attrs": {"status": "nd", "ifdprop": "object:rendersubdcurves", "hprop": "vm_rendersubdcurves"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how points from geometry are rendered. At the default settings, ", {"text": ["No Point Rendering"], "type": "ui"}, ", only points from particle systems are rendered. \n    Setting this value to ", {"text": ["Render Only Points"], "type": "ui"}, ", will render the geometry using only the point attributes, ignoring all vertex and primitive information.\n    ", {"text": ["Render Unconnected Points"], "type": "ui"}, " works in a similar way, but only for points not used by any of the geometry\u2019s primitives."]}, {"indent": 4, "type": "para", "text": ["Two attributes control the point primitives if they exist."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["A vector which determines the normal of the point geometry. If the attribute doesn\u2019t exist, points are oriented to face the incoming ray (the VEX ", {"text": ["I"], "type": "code"}, " variable)."]}], "indent": 4, "type": "dt", "text": [{"text": ["orient"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Determines the 3D size of the points (defaults to 0.05)."]}], "indent": 4, "type": "dt", "text": [{"text": ["width"], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Render as points (Mantra)"], "role": "item", "attrs": {"ifdprop": "object:renderpoints", "hprop": "vm_renderpoints"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Determines the interpretation of how point primitives are rendered.  The light-weight point primitives can be rendered as either spheres or circles."]}], "indent": 0, "text": ["Render points as (Mantra)"], "role": "item", "attrs": {"ifdprop": "object:renderpointsas", "hprop": "vm_renderpointsas"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Scales the width of point primitives by the value given. This is applied \n    on top of any point width attribute specified on the geometry."]}], "indent": 0, "text": ["Point Scale"], "role": "item", "attrs": {"ifdprop": "object:pointscale", "hprop": "vm_pointscale"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Treat point scale as diameter instead of radius"], "role": "item", "attrs": {"status": "nd", "ifdprop": "object:pscalediameter", "hprop": "vm_pscalediameter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Detect common Alembic shapes (or other shared packed primitives) and share\n    the geometry when rendering in mantra."]}, {"indent": 4, "type": "para", "text": ["With this option enabled, most attributes defined on the packed primitive\n    cannot be passed to shaders.  Since the underlying geometry is shared,\n    there\u2019s no way to change the attribute values for each instance.  For\n    example, a Packed Alembic Primitive with a ", {"text": ["Cd"], "type": "code"}, " attribute may not render as\n    expected.  The exceptions to this are the ", {"text": ["shop_materialpath"], "type": "code"}, " and\n    ", {"text": ["material_override"], "type": "code"}, " attributes which work as expected (since mantra is able\n    to change these properties independently for each instance)."]}], "indent": 0, "text": ["Auto-Instancing Of Alembic/Packed Primitives"], "role": "item", "attrs": {"ifdprop": "object:packinstance", "hprop": "vm_packinstance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["For efficiency, mantra usually merges separate fragments into a single piece of geometry.  This typically uses less geometry and renders more efficiently."]}, {"indent": 4, "type": "para", "text": ["However, since the geometry is merged into a single piece of geometry for rendering, the individual packed fragments are not available for material stylesheets and their attributes aren\u2019t available for the ", {"text": ["renderstate()"], "type": "code"}, " function."]}, {"indent": 4, "type": "para", "text": ["Disabling this option will cause each fragment primitive to be rendered as a separate mantra object.  This will typically take more memory and may impact rendering performance."]}], "indent": 0, "text": ["Merge packed fragments into single geometry"], "role": "item", "attrs": {"ifdprop": "object:pack_mergefragments", "hprop": "vm_pack_mergefragments"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering packed disk sequence primitives, mantra will automatically\n    blend sub-frame geometry to create accurate motion blur.  When there are a\n    large number of packed disk sequence primitives, this can use significant\n    memory.  By limiting the number of sub-frame blending samples, memory can\n    be decreased."]}], "indent": 0, "text": ["Packed Sequence Segments"], "role": "item", "attrs": {"ifdprop": "object:pack_sequencesubsteps", "hprop": "vm_pack_sequencesubsteps"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This option is for very advanced users only."]}, {"indent": 4, "type": "para", "text": ["It\u2019s typically only used for debugging (or possibly for HDK users)."]}, {"indent": 4, "type": "para", "text": ["When packed geometry is refined by mantra using the GT HDK classes, this option can be used to specify a Python style dictionary of options that are passed through the ", {"text": ["GT_RefineParms"], "type": "code"}, ".  This dictionary is loaded into a ", {"text": ["UT_Options"], "type": "code"}, " object and passed to the ", {"text": ["GT_RefineParms::load()"], "type": "code"}, " method."]}], "indent": 0, "text": ["Packed refinement options"], "role": "item", "attrs": {"ifdprop": "object:pack_refineoptions", "hprop": "vm_pack_refineoptions"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering multiple instances as subdivision or displaced surfaces,\n    mantra chooses the \"best\" level of detail for rendering.  Procedurals are\n    only evaluated when they are actually rendered.  So, if procedurals share\n    underlying geometry (i.e. Alembic primitives), it\u2019s possible that the level\n    of detail will be chosen before all procedurals have been evaluated.  This\n    means that the level of detail may be chosen incorrectly (depending on\n    rendering order)."]}, {"indent": 4, "type": "para", "text": ["This option can be set on a per-object basis and will cause all required\n    procedurals to be evaluated so the proper level of detail can be chosen\n    for instanced geometry."]}, {"indent": 4, "type": "para", "text": ["If this option is disabled, mantra will emit warnings when it detects a\n    potential level of detail issue."]}, {"indent": 4, "type": "para", "text": ["Enabling this option may increase render start up time and memory\n    requirements."]}], "indent": 0, "text": ["Flatten Procedurals"], "role": "item", "attrs": {"ifdprop": "object:flattenprocedural", "hprop": "vm_flattenprocedural"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When there are nested procedurals, this optimizes the layout of the acceleration structure."]}], "indent": 0, "text": ["Flatten Procedurals To Root Level"], "role": "item", "attrs": {"ifdprop": "object:flattentoroot", "hprop": "vm_flattentoroot"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enabling this option will cause procedurals to use their root transform. The default behavior is to use the leaf\u2019s transform."]}, {"indent": 4, "type": "para", "text": ["This will most notably impact the transform space on packed primitives.  If the ", {"text": ["vm_procuseroottransform"], "type": "code"}, " is turned on, the object space for the packed primitive will be the space of the object containing the geometry.  If the option is turned off, the transform space for a packed primitive will be the local space of the packed primitive (i.e. combining the packed primitive\u2019s transform with the object that contains the geometry)."]}, {"indent": 4, "type": "para", "text": ["See also ", {"text": ["vm_sharedisplace"], "type": "code"}, "."]}], "indent": 0, "text": ["Proc Use Root Transform"], "role": "item", "attrs": {"ifdprop": "object:procuseroottransform", "hprop": "vm_procuseroottransform"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Mantra will initialize the ", {"text": ["N"], "type": "code"}, " global from the ", {"text": ["N"], "type": "code"}, " attribute when rendering point primitives. When disabled (the default), point normals will be initialized to face the camera."]}], "indent": 0, "text": ["Use N for point rendering"], "role": "item", "attrs": {"ifdprop": "object:usenforpoints", "hprop": "vm_usenforpoints"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Render metaballs as volumes as opposed to surfaces.  The volume quality for metaballs will be set based on the average size of all metaballs in the geometry, so increasing or decreasing the metaball size will automatically adjust the render quality to match."]}], "indent": 0, "text": ["Metaballs as volume"], "role": "item", "attrs": {"ifdprop": "object:metavolume", "hprop": "vm_metavolume"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables unit s/t values when rendering curves.  Unit t values start at 0 at one end of the curve, and increase to 1 at the tip regardless of the number of bezier segments that comprise the curve.  Non-unit t values restart at 0 for each curve segment.  Unit s/t values are required for correct shading of fur."]}], "indent": 0, "text": ["Use unit s/t for curves"], "role": "item", "attrs": {"ifdprop": "object:curveunitst", "hprop": "vm_curveunitst"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Typically, mantra doesn\u2019t automatically fill in the normal variable for\n    volume primitives.  This is because it\u2019s not usually required for lighting\n    and can be expensive to compute."]}, {"indent": 4, "type": "para", "text": ["However, when generating deep raster planes for normals, it\u2019s sometimes\n    useful to have the normals computed, which this option enables."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Photon map generation relies on having 0 length normals for volume primitives, so this option should be turned off during photon map generation."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["Compute Volume Normals"], "role": "item", "attrs": {"ifdprop": "object:volumenormal", "hprop": "vm_volumenormal"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Toggles the weighting of the global ", {"text": ["dPdz"], "type": "code"}, " parameter across the field of view of the camera. This has the effect of normalizing opacity across the projected field."]}], "indent": 0, "text": ["Normalize dPdz over FOV"], "role": "item", "attrs": {"ifdprop": "object:volumedpdzfov", "hprop": "vm_volumedpdzfov"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables output of geometry when a procedural shader is assigned.  If you know that the procedural you have assigned does not rely on geometry being present for the procedural to operate correctly, you can disable this toggle."]}], "indent": 0, "text": ["Force procedural geometry output"], "role": "item", "attrs": {"hprop": "vm_forcegeometry"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether Mantra will try to prevent cracks."]}, {"indent": 4, "type": "para", "text": ["Coving is the process of filling cracks in diced geometry\n    at render time, where different levels of dicing side-by-side\n    create gaps at T-junctions."]}, {"indent": 4, "type": "para", "text": ["The default setting, ", {"text": ["Coving for displacement/sub-d"], "type": "ui"}, ", only does\n    coving for surfaces with a displacement shader and subdivision\n    surfaces, where the displacement of points can potentially create\n    large cracks. This is sufficient for more rendering, however\n    you may want to use ", {"text": ["Coving for all primitives"], "type": "ui"}, " if you are\n    using a very low shading rate or see cracks in the alpha of the\n    rendered image."]}, {"indent": 4, "type": "para", "text": ["Do not use ", {"text": ["Disable coving"], "type": "ui"}, ". It has no performance\n    benefit, and may actually harm performance since Houdini has to\n    render any geometry visible through the crack."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["No coving."]}], "indent": 4, "type": "dt", "text": [{"text": ["0"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Only displaced surfaces and sub-division surfaces will be coved."]}], "indent": 4, "type": "dt", "text": [{"text": ["1"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["All primitives will be coved."]}], "indent": 4, "type": "dt", "text": [{"text": ["2"], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Coving"], "role": "item", "attrs": {"ifdprop": "object:coving", "hprop": "vm_coving"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When coving is enabled, this indicates to perform coving by implicitly\n    expanding diced geometry, instead of by creating new polygons, to\n    fill cracks caused by T-junctions where different levels of dicing\n    are side-by-side."]}, {"indent": 4, "type": "para", "text": ["Because no additional polygons are required, this can save memory,\n    but if geometry is expanded too far, it can result in slow raytracing.\n    The ", {"text": ["Sample Coving Expansion Factor"], "type": "ui"}, " parameter indicates how much to\n    implicitly expand the geometry, relative to the size of each diced piece."]}, {"indent": 4, "type": "para", "text": ["Sample coving does not apply to micropolygon rendering."]}], "indent": 0, "text": ["Use Sample Coving"], "role": "item", "attrs": {"ifdprop": "object:samplecoving", "hprop": "vm_samplecoving"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When sample coving is enabled with the ", {"text": ["Use Sample Coving"], "type": "ui"}, " parameter,\n    this dictates how much to implicitly expand diced geometry, relative\n    to the size of each diced piece, to fill cracks caused by T-junctions\n    where different levels of dicing are side-by-side."]}, {"indent": 4, "type": "para", "text": ["If geometry is expanded too far, it can result in slow raytracing.\n    For example, a value of 10 can be quite slow.  Setting small negative\n    values, e.g. -0.1, or the minimum allowed value, -1, can help visualize\n    how geometry is diced."]}], "indent": 0, "text": ["Sample Coving Expansion Factor"], "role": "item", "attrs": {"ifdprop": "object:samplecovingexpansion", "hprop": "vm_samplecovingexpansion"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If enabled, geometry that are facing away from the camera are not\n    rendered."]}], "indent": 0, "text": ["Backface removal (Mantra)"], "role": "item", "attrs": {"ifdprop": "object:rmbackface", "hprop": "vm_rmbackface"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Each object references a geometry object. Houdini geometry allows multiple primitive groups to be defined. If the ", {"text": ["object:geometrygroup"], "type": "code"}, " parameter is set to a string, only the primitives which are members of the named group will be rendered by this instance. This allows multiple objects to instance the same geometry, but render different parts."]}, {"indent": 4, "type": "para", "text": ["Not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Render group"], "role": "item", "attrs": {"ifdprop": "object:geometrygroup", "hprop": "vm_geometrygroup"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If there are no normals on an object, this indicates what type of normals to compute before saving the geometry, if any.  If this is set to ", {"text": ["Vertex Normals"], "type": "ui"}, ", any edges with dihedral angles greater than the ", {"text": ["Cusp Angle for Vertex Normals"], "type": "ui"}, " parameter will be cusped."]}], "indent": 0, "text": ["Add Normals to Geometry"], "role": "item", "attrs": {"hprop": "vm_addnormalsto"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If there are no normals on an object, and ", {"text": ["Add Normals To Geometry"], "type": "ui"}, " is set to ", {"text": ["Vertex Normals"], "type": "ui"}, ", any edges with dihedral angles greater than this parameter will be cusped."]}], "indent": 0, "text": ["Cusp Angle for Vertex Normals"], "role": "item", "attrs": {"hprop": "vm_cuspangle"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether mantra should compute the N attribute automatically. If the N attribute exists, the value will remain unchanged. However, if no N attribute exists, it will be created. This allows polygon geometry which doesn\u2019t have the N attribute already computed to be smooth shaded."]}, {"indent": 4, "type": "para", "text": ["Not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Automatically Compute Normals (Old)"], "role": "item", "attrs": {"ifdprop": "geometry:computeN", "hprop": "vm_computeN"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the geometry attributes that will have segments created when\n    computing motion blur. The ", {"text": ["P"], "type": "code"}, " attribute is included by default."]}], "indent": 0, "text": ["Motion Blurred Attributes"], "role": "item", "attrs": {"ifdprop": "geometry:segmentattrs", "hprop": "vm_segmentattrs"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Geometry"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Turns point instancing on."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Instance the target object in place of this object."]}], "indent": 4, "type": "dt", "text": [{"text": ["0"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Instance the target object ", {"text": ["on each point"], "type": "em"}, " of this object."]}], "indent": 4, "type": "dt", "text": [{"text": ["1"], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Point instancing"], "role": "item", "attrs": {"hprop": "ptinstance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Path to the object to instance (may be a subnetwork, light, etc.)."]}], "indent": 0, "text": ["Instance object"], "role": "item", "attrs": {"hprop": "instancepath"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how the point position will be evaluated when transformation blur is enabled on the objects.  It does not turn motion blur on for the points. Possible values are ", {"text": ["off"], "type": "code"}, " (no motion blur), ", {"text": ["deform"], "type": "code"}, " (compute sub-frame geometry), or ", {"text": ["velocity"], "type": "code"}, " (use point velocity attribute)."]}], "indent": 0, "text": ["Point motion blur"], "role": "item", "attrs": {"hprop": "ptmotionblur"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When this option is on (1), the transform of the target (instanced) object is combined with the transform of this object. When this option is off (0), only this object\u2019s transform is used."]}], "indent": 0, "text": ["Instance Transform"], "role": "item", "attrs": {"hprop": "instancexform"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Instance"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Enables the irradiance cache, which can significantly improve the performance of the irradiance and occlusion VEX function calls."]}, {"indent": 4, "type": "para", "text": ["This has no effect when using area lights or the PBR rendering engines.  Normally the irradiance cache should only be used with a VEX Global Illumination light or with shaders that use the occlusion() or irradiance() functions."]}], "indent": 0, "text": ["Enable irradiance cache"], "role": "item", "attrs": {"ifdprop": "object:gienable", "hprop": "vm_gienable"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The file to store the irradiance cache. If multiple objects specify the same file, the cache file will contain samples from all objects."]}], "indent": 0, "text": ["Irradiance cache file"], "role": "item", "attrs": {"ifdprop": "object:gifile", "hprop": "vm_gifile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The read-write mode for the global irradiance file."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Read only."]}], "indent": 4, "type": "dt", "text": [{"text": ["r"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Write only. This will generate a new irradiance cache file on disk at the specified sampling rate"]}], "indent": 4, "type": "dt", "text": [{"text": ["w"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Read and write. This will load an irradiance cache file from disk and use the pre-existing results where they exist It will also generate new samples for parts of the image that were not rendered in the original cache file generation."]}], "indent": 4, "type": "dt", "text": [{"text": ["rw"], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Read/write mode"], "role": "item", "attrs": {"ifdprop": "object:gifilemode", "hprop": "vm_gifilemode"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The default number of samples used to compute irradiance when the shader doesn\u2019t specify it. In most cases, the shader does specify the value."]}], "indent": 0, "text": ["Default samples"], "role": "item", "attrs": {"ifdprop": "object:gisample", "hprop": "vm_gisample"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The maximum error tolerance between samples in the irradiance map.  Normally you should only decrease this value from the default of 0.1 if there are artifacts in the render."]}], "indent": 0, "text": ["Irradiance error"], "role": "item", "attrs": {"ifdprop": "object:gierror", "hprop": "vm_gierror"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["In some cases, you can get a very dense clustering of irradiance samples in the cache. This parameter prevents the clustering by ensuring that there are at least this many pixels between samples. Clustering usually occurs between non-smooth intersections between different primitives."]}], "indent": 0, "text": ["Min spacing (pixels)"], "role": "item", "attrs": {"ifdprop": "object:giminspacing", "hprop": "vm_giminspacing"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The maximum screen space between irradiance samples. Lowering this value will force more samples to be computed, creating a more accurate representation of the irradiance information."]}], "indent": 0, "text": ["Max spacing (pixels)"], "role": "item", "attrs": {"ifdprop": "object:gimaxspacing", "hprop": "vm_gimaxspacing"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Irradiance"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["Lights objects inherit many of the geometry object properties in addition to the special light properties."]}, {"body": [{"body": [], "indent": 0, "text": ["Light color"], "role": "item", "attrs": {"status": "nd", "hprop": "light_color"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Export plane prefix"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_export_prefix"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Export plane suffix"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_export_suffix"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The shape of an area light."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["point"], "type": "code"}, " \u2013 No area shape"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["line"], "type": "code"}, " \u2013 Line light (unit line along x-axis)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["grid"], "type": "code"}, " \u2013 Grid light (unit square in XY plane)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["disk"], "type": "code"}, " \u2013 Circle shaped light (radius 0.5 in XY plane)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["sphere"], "type": "code"}, " \u2013 Sphere shaped light (radius 0.5)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["environment"], "type": "code"}, " \u2013 Sphere shaped light (infinite radius)"]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Area shape"], "role": "item", "attrs": {"ifdprop": "light:areashape", "hprop": "vm_areashape"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The size of the area light. The sizes are interpreted slightly differently for each shape."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["line"], "type": "code"}, " \u2013 Only the X size is used"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["grid"], "type": "code"}, " \u2013 The X & Y size of the grid"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["disk"], "type": "code"}, " \u2013 The X & Y radii of the circle"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["sphere"], "type": "code"}, " \u2013 The average of the sizes is used as the radius"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["environment"], "type": "code"}, " \u2013 Ignored"]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Area size"], "role": "item", "attrs": {"ifdprop": "light:areasize", "hprop": "vm_areasize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Only used for the environment light. This specifies an environment map which is used for illuminating the scene. The map may be an HDRI map."]}, {"indent": 4, "type": "para", "text": ["See ", {"text": ["how to create an environment/reflection map"], "fullpath": "/render/envmaps", "scheme": null, "type": "link", "value": "/render/envmaps"}, "."]}], "indent": 0, "text": ["Area texture"], "role": "item", "attrs": {"ifdprop": "light:areamap", "hprop": "vm_areamap"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["For the environment light, whether the light source represents the full sphere or the upper hemisphere"]}], "indent": 0, "text": ["Full sphere environment"], "role": "item", "attrs": {"ifdprop": "light:areafullsphere", "hprop": "vm_areafullsphere"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the resolution of the internally generated image used for environment map sampling.  The value is the logarithm of the image resolution in the x and y dimensions.  The default value of 8 produces a sampling image of resolution 256\u00d7256 pixels.  Larger values will produce a more accurate render when using high resolution environment maps for environment lighting, but may require additional memory and processing time during startup."]}], "indent": 0, "text": ["Light importance levels"], "role": "item", "attrs": {"ifdprop": "light:importancelevels", "hprop": "vm_importancelevels"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The active radius of the light source can be used to optimize renders. When illuminating a surface, only surfaces within the active radius will be considered."]}, {"indent": 4, "type": "para", "text": ["Example: Consider a car tunnel with lights every 10 meters. If the light has a sharp falloff, then it\u2019s possible to have thousands of lights and still render in a reasonable amount of time. No shaders will be run (neither the illumination nor the shadow shader)."]}], "indent": 0, "text": ["Active radius"], "role": "item", "attrs": {"ifdprop": "light:activeradius", "hprop": "vm_activeradius"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When true, the light will not contribute to ", {"text": ["diffuse()"], "type": "code"}, " calls."]}], "indent": 0, "text": ["Non diffuse light"], "role": "item", "attrs": {"ifdprop": "light:__nondiffuse", "hprop": "vm_nondiffuse"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When true, the light will not contribute to ", {"text": ["specular()"], "type": "code"}, " calls."]}], "indent": 0, "text": ["Non specular light"], "role": "item", "attrs": {"ifdprop": "light:__nonspecular", "hprop": "vm_nonspecular"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Typically handled automatically during IFD generation.  A boolean indicating whether the light stores a cache (i.e. indirect and point cloud lights)."]}], "indent": 0, "text": ["Light stores cached illumination"], "role": "item", "attrs": {"ifdprop": "light:lightcache", "hprop": "vm_lightcache"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is typically handled automatically for light sources.  It\u2019s set to true if the ", {"text": ["env_mode"], "type": "code"}, " parameter on environment light is set to ", {"text": ["background"], "type": "code"}, ".  That is, whether rays are traced against the environment light."]}], "indent": 0, "text": ["Ray tracing background"], "role": "item", "attrs": {"ifdprop": "light:raybackground", "hprop": "vm_raybackground"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is typically handled automatically for Sun lights.  It is the solid angle (specified in degrees) used to sample the \"sun\" light."]}], "indent": 0, "text": ["Sun angle"], "role": "item", "attrs": {"ifdprop": "light:envangle", "hprop": "vm_envangle"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls whether multiple importance sampling samples from the BSDF, the light, or both the BSDF and light."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["-1"], "type": "code"}, " \u2013 Sample only from the BSDF"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["0"], "type": "code"}, " \u2013 Sample from both the BSDF and the light"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["1"], "type": "code"}, " \u2013 Sample only from the light"]}], "container": true, "type": "bullet_group"}, {"indent": 4, "type": "para", "text": ["The default ", {"text": ["vm_misbias"], "type": "code"}, " for area lights and environment lights with an\n    environment map is 0."]}, {"indent": 4, "type": "para", "text": ["Environment lights that have no environment map assigned will use a\n    default ", {"text": ["vm_misbias"], "type": "code"}, " of -1. This means that sampling will only use BSDF\n    samples for constant environment illumination - which can speed up\n    renders substantially in this situation. As soon as a map is assigned,\n    the MIS bias default is set back to 0. If you add the ", {"text": ["vm_misbias"], "type": "code"}, "\n    property it will always override the default."]}], "indent": 0, "text": ["MIS Bias"], "role": "item", "attrs": {"hprop": "vm_misbias"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}, {"indent": 0, "type": "para", "text": [""]}], "indent": 0, "level": 2, "text": ["Light"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["As a ray travels through many transparent surfaces, or through a volume, it will calculate the cumulative amount of Opacity. When this value exceeds the Opacity Limit mantra will assume all surfaces beyond this point are opaque."]}, {"indent": 8, "type": "para", "text": ["This parameter behaves in a similar fashion to both the Reflect and Refract Limit but operates on accumulated values rather than simply the number of surfaces the ray has passed through."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityLimitDiagram.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityLimitDiagram.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["In this example, each grid has a shader attached with an opacity value of 0.1. It is important to remember that in this case \u201ctransparent\u201d refers to objects whose opacity is less than 100% and does not include refractive objects which can appear transparent."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityLimit.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["In this example, the sphere of the left has an opacity of 0.5, with no refraction. The sphere on the right has an Opacity of 1 with refraction enabled. You can see that the Opacity Limit has no effect on the amount of refraction, only affecting objects whose opacity value is less than 1."]}, {"indent": 8, "type": "para", "text": ["While reducing the Opacity Limit may save a small amount of render time (1 \u2013 5%) using low values may result in banding and other artifacts when your camera is moving or an animation is evolving. This can be especially noticeable in smoke simulations where opacity values are constantly changing."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/OpacityVsRefract.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/OpacityVsRefract.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["The default value for Opacity Limit is quite aggressive, changing this value should be done carefully and the results inspected across a range of frames in an animated sequence."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/BadOpacityLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/BadOpacityLimit.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}], "indent": 0, "text": ["Opacity limit"], "role": "item", "attrs": {"ifdprop": "image:opacitylimit", "hprop": "vm_opacitylimit"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["The maximum value a shading sample is allowed to return from indirect sources. When rendering using PBR the path\u2019s total illumination is also constrained."]}, {"indent": 8, "type": "para", "text": ["Physically Based Rendering can cause \u201cspikes\u201d in color values when extremely bright indirect light sources are under sampled. This results in \u201cfireflies\u201d in the final rendered image which can be very difficult to remove without very high sampling rates."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimit.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["You can see in this example that even at 12\u00d712 pixel samples, the \u201cfireflies\u201d still remain. Adjusting Min and Max indirect rays sample settings could remove this noise, but at the cost of longer render times."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitPixelSamples.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitPixelSamples.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Decreasing the Color Limit parameter clamps the color values in these indirect samples and can help to avoid these \u201cspikes\u201d."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitCompare.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Reducing the color Limit can be an effective way of removing \u201cfireflies\u201d without increasing sampling rates. However, clamping the values in indirect lighting can result in an overall reduction in the amount of light in your scene. This is especially evident in scenes which are mostly illuminated by indirect light."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ColorLimitCompareLight.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ColorLimitCompareLight.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}], "indent": 0, "text": ["Color limit"], "role": "item", "attrs": {"ifdprop": "image:colorlimit", "hprop": "vm_colorlimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the path depth beyond which Color Limit clamping is applied."]}], "indent": 0, "text": ["Color limit depth"], "role": "item", "attrs": {"ifdprop": "image:colorlimitdepth", "hprop": "vm_colorlimitdepth"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["To improve efficiency when shading transparent objects, mantra will queue a number of transparent surfaces before shading.  This specifies the number of surfaces to queue.  This can have a dramatic effect on volume rendering for example."]}], "indent": 0, "text": ["Ray Unshaded limit"], "role": "item", "attrs": {"ifdprop": "renderer:unshadedlimit", "hprop": "vm_unshadedlimit"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["Controls how Mantra deals with rays that reach the ray tracing limit (For example the ", {"text": ["Reflect Limit"], "type": "ui"}, " or ", {"text": ["Refract Limit"], "type": "ui"}, ")."]}, {"indent": 8, "type": "para", "text": ["In this example, the refract Limit has been set to 2."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/AtRayLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/AtRayLimitCompare.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["Setting At Ray Limit to ", {"text": ["Use Black Background"], "type": "ui"}, " will simply render black once the limits are reached. This is the default setting and will work in most scenes since the Reflect or Refract Limit is unlikely to be reached. However, in scenes where the limit is noticeable in the rendered image, the black color can be quite noticeable and stand out against the colors in the scene."]}, {"indent": 4, "type": "para", "text": ["In this case, increase the limit until the effect is avoided or use the ", {"text": ["Use Direct Lighting as Background Color"], "type": "ui"}, " option. This will replace the black color with whichever color or image is used in your direct lighting, for instance an Environment Light."]}, {"indent": 4, "type": "para", "text": ["For More Information about how the settings on an Environment Light affect this parameter see ", {"text": ["lighting"], "fullpath": "/render/lights", "scheme": null, "type": "link", "value": "/render/lights"}, "."]}], "indent": 0, "text": ["At ray limit"], "role": "item", "attrs": {"ifdprop": "renderer:raylimiteval", "hprop": "vm_raylimiteval"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["At Ray Limit"], "type": "ui"}, " is set to ", {"text": ["Use Direct Lighting as Background Color"], "type": "ui"}, ", direct lighting will be used for components in this list that have exceeded their limit. For example, if set to ", {"text": ["refract reflect"], "type": "code"}, " only rays that have exceeded the refract/reflect limits would use direct lighting."]}], "indent": 0, "text": ["Ray limit components"], "role": "item", "attrs": {"ifdprop": "renderer:raylimitcomponents", "hprop": "vm_raylimitcomponents"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["At Ray Limit"], "type": "ui"}, " is set to ", {"text": ["Use Direct Lighting as Background Color"], "type": "ui"}, " this mask controls which lights contribute to direct lighting. "]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["This mask is intersected with lights affecting the material being shaded. Lights not found in both masks are ignored."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["Ray limit light mask"], "role": "item", "attrs": {"ifdprop": "renderer:raylimitlightmask", "hprop": "vm_raylimitlightmask"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["The number of times a ray can be reflected in your scene."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectLimit.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["This example shows a classic \u201cHall of Mirrors\u201d scenario with the subject placed between two mirrors."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectSceneSetup.png", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectSceneSetup.png"}]}, {"body": [{"indent": 8, "type": "para", "text": ["This effectively creates an infinite series of reflections."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectLimitCompare.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["From this camera angle the reflection limits are very obvious and have a large impact on the accuracy of the final image. However, in most cases the reflection limit will be more subtle, allowing you to reduce the number of reflections in your scene and optimize the time it takes to render them."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/ReflectSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/ReflectSubtleCompare.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["Remember that the first time a light source is reflected in an object, it is considered a direct reflection. Therefore, even with Reflect Limit set to 0, you will still see specular reflections of light sources."]}, {"indent": 4, "type": "para", "text": ["To control what happens when the maximum number of reflections is exceeded, use ", {"text": ["At Ray Limit"], "type": "ui"}, "."]}], "indent": 0, "text": ["Reflect limit"], "role": "item", "attrs": {"ifdprop": "object:reflectlimit", "hprop": "vm_reflectlimit"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["This parameter control the number of times a ray be refracted in your scene."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimit.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["This example shows a simple scene with ten grids all in a row."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractSceneSetup.png", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractSceneSetup.png"}]}, {"body": [{"indent": 8, "type": "para", "text": ["By applying a refractive shader, we will be able see through the grids to an image of a sunset in the background."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimitCompare.jpg"}]}, {"body": [{"indent": 8, "type": "para", "text": ["From this camera angle, in order for the image to be accurate, the refraction limit must match the number of grids that that are in the scene. However, most scenes will not have this number of refractive objects all in a row and so it is possible to reduce the refract limit without affecting the final image while also reducing the time it takes to render them."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractSubtleCompare.jpg"}, "\n    \ufffc\ufffc"]}, {"body": [{"indent": 8, "type": "para", "text": ["Keep in mind that this Refract Limit refers to the number of surfaces that the ray must travel through, not the number of objects."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/RefractLimitSurfaces.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/RefractLimitSurfaces.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["Remember that the first time a light source is refracted through a surface, it is considered a direct refraction. Therefore, even with Refract Limit set to 0, you will see refractions of Light Sources. However, since most objects in your scene will have at least two surfaces between it and the light source, direct refractions are often not evident in your final render.\n    \ufffc\n    To control what happens when the maximum number of refraction is exceeded, use ", {"text": ["At Ray Limit"], "type": "ui"}, "."]}], "indent": 0, "text": ["Refract limit"], "role": "item", "attrs": {"ifdprop": "object:refractlimit", "hprop": "vm_refractlimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of times diffuse rays can propagate through your scene."]}, {"body": [{"indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseLimit.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["Unlike the Reflect and Refract Limits, this parameter will increase the overall amount of light in your scene and contribute to the majority of global illumination. With this parameter set above zero diffuse surfaces will accumulate light from other objects in addition to direct light sources."]}, {"indent": 4, "type": "para", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseLimitCompare.jpg"}]}, {"indent": 4, "type": "para", "text": ["In this example, increasing the Diffuse Limit has a dramatic effect on the appearance of the final image. To replicate realistic lighting conditions, it is often necessary to increase the Diffuse Limit. However, since the amount of light contribution usually decreases with each diffuse bounce, increasing the Diffuse Limit beyond 4 does little to improve the visual fidelity of a scene. Additionally, increasing the Diffuse Limit can dramatically increase noise levels and render times."]}, {"indent": 4, "type": "para", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/DiffuseSubtleCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/DiffuseSubtleCompare.jpg"}]}], "indent": 0, "text": ["Diffuse limit"], "role": "item", "attrs": {"ifdprop": "object:diffuselimit", "hprop": "vm_diffuselimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of times sub-surface scattering rays can propagate through your scene."]}], "indent": 0, "text": ["SSS limit"], "role": "item", "attrs": {"ifdprop": "object:ssslimit", "hprop": "vm_ssslimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of times a volumetric ray can propagate through a scene. It functions in a similar fashion to the ", {"text": ["Diffuse Limit"], "type": "ui"}, " parameter."]}, {"indent": 4, "type": "para", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/VolumeLimit.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/VolumeLimit.jpg"}]}, {"indent": 4, "type": "para", "text": ["Increasing the Volume Limit parameter will result in much more realistic volumetric effects. This is especially noticeable in situations where only part of a volume is receiving direct lighting. Also, in order for a volumetric object to receive indirect light from other objects, the Volume Limit parameter must be set above 0."]}, {"indent": 4, "type": "para", "text": [{"text": "", "fullpath": "/images/render/mug/limits_tab/VolumeLimitCompare.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/limits_tab/VolumeLimitCompare.jpg"}]}, {"indent": 4, "type": "para", "text": ["With the Volume Limit set to values above zero, the fog volume takes on the characteristic light scattering you would expect from light traveling through a volume. However, as with the Diffuse Limit, the light contribution generally decreases with each bounced ray and therefore using values above 4 does not necessarily result in a noticeably more realistic image."]}, {"indent": 4, "type": "para", "text": ["Also, increasing the value of this parameter can dramatically increase the amount of time spent rendering volumetric images."]}], "indent": 0, "text": ["Volume limit"], "role": "item", "attrs": {"ifdprop": "object:volumelimit", "hprop": "vm_volumelimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["As rays propagate through the scene, they contribute less and less to the final color of the surface. When the contribution becomes less than the ray weight, no further rays will be sent. This is similar to the ", {"text": ["renderer:opacitylimit"], "type": "code"}, ". ", {"text": ["vm_rayweight"], "type": "code"}, " will not affect volume renders."]}], "indent": 0, "text": ["Contribution limit"], "role": "item", "attrs": {"ifdprop": "object:rayweight", "hprop": "vm_rayweight"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables random early cut off of ray paths when path tracing.  This lets you increase overall path limits (i.e. the ", {"text": ["Diffuse Limit"], "type": "ui"}, ") while trading off a little stochastic noise for rendering efficiency."]}], "indent": 0, "text": ["Stochastic Path Early Cut Off"], "role": "item", "attrs": {"ifdprop": "renderer:pathcutoff", "hprop": "vm_pathcutoff"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the method used to determine for early cut off of ray paths."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["The chance for termination is determined by the ", {"text": ["Cut Off Threshold"], "type": "ui"}, " value."]}], "indent": 4, "type": "dt", "text": ["Probability"]}, {"body": [{"indent": 8, "type": "para", "text": ["The albedo of the surface at each bounce is used as the probability to cut short ray paths.  This means that darker surfaces will result in earlier cut off."]}], "indent": 4, "type": "dt", "text": ["Albedo"]}, {"body": [{"indent": 8, "type": "para", "text": ["The path\u2019s combined throughput divided by the value of the ", {"text": ["Cut Off Threshold"], "type": "ui"}, " determines the probability."]}], "indent": 4, "type": "dt", "text": ["Throughput"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Cut Off Method"], "role": "item", "attrs": {"ifdprop": "renderer:pathcutoffmethod", "hprop": "vm_pathcutoffmethod"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This value affects the probability that ray paths will be cut short.  Smaller values will cause paths to be cut off earlier (faster renders)."]}], "indent": 0, "text": ["Cut Off Threshold"], "role": "item", "attrs": {"ifdprop": "renderer:pathcutoffthresh", "hprop": "vm_pathcutoffthresh"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter specifies the minimum number of bounces that occur before paths can be cut off."]}], "indent": 0, "text": ["Cut Off Depth"], "role": "item", "attrs": {"ifdprop": "image:pathcutoffdepth", "hprop": "vm_pathcutoffdepth"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shading queue size"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_shadingqueuesize"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Limits"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["A string containing a space-separated list of property values to save into the output ", {"text": [".rat"], "type": "code"}, "/", {"text": [".tbf"], "type": "code"}, " file (such as a texture or ", {"text": ["deep shadow map"], "fullpath": "/render/shadows", "scheme": null, "type": "link", "value": "/render/shadows"}, "). You can read the saved values out of a texture using the ", {"text": "", "value": "/vex/functions/teximport", "fallback_text": "teximport()", "fullpath": "/vex/functions/teximport", "scheme": "Vex", "type": "link"}, " VEX function in a shader."]}, {"indent": 4, "type": "para", "text": ["The defaults save mostly camera- and image-related properties, but you can save the value of any mantra property, such as ", {"text": ["renderer:version"], "type": "code"}, "."]}], "indent": 0, "text": ["Save settings"], "role": "item", "attrs": {"ifdprop": "image:saveoptions", "hprop": "vm_saveoptions"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The name of the image creator. By default uses the current user\u2019s log in name."]}, {"indent": 4, "type": "para", "text": ["Houdini, TIFF, PNG formats"]}], "indent": 0, "text": ["Artist"], "role": "item", "attrs": {"hprop": "vm_image_artist"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A text comment to include in the output file."]}, {"indent": 4, "type": "para", "text": ["Houdini, OpenEXR, PNG formats"]}], "indent": 0, "text": ["Comment"], "role": "item", "attrs": {"hprop": "vm_image_comment"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The name of the computer where this image was created."]}], "indent": 0, "text": ["Hostname"], "role": "item", "attrs": {"hprop": "vm_image_hostname"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["After rendering an EXR image, Mantra can post-process the image to set the data window, store the render time and additional information in the image header.  This option disables this post-processing."]}], "indent": 0, "text": ["Enable EXR Post Processing"], "role": "item", "attrs": {"hprop": "vm_image_exr_postprocess"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["After rendering an EXR image, Mantra will determine and record the rectangle of data whose values are above ", {"text": ["EXR Data Window Threshold"], "type": "ui"}, " in the image planes specified by ", {"text": ["EXR Data Window Planes"], "type": "ui"}, ", with an added padding of ", {"text": ["EXR Data Window Padding"], "type": "ui"}, " pixels on each side of the rectangle.  This is equivalent to running the ", {"text": ["iautocrop"], "type": "code"}, " program on the output image."]}], "indent": 0, "text": ["Set EXR Data Window"], "role": "item", "attrs": {"ifdprop": "global:setexrdatawindow", "hprop": "vm_setexrdatawindow"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Set EXR Data Window"], "type": "ui"}, " is on, the number of pixels to expand the computed data window on each side. This can give a bit of padding around the data window, if it is needed for filtering purposes in another application."]}], "indent": 0, "text": ["EXR Data Window Padding"], "role": "item", "attrs": {"ifdprop": "renderer:exrdatawindowpadding", "hprop": "vm_exrdatawindowpadding"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Set EXR Data Window"], "type": "ui"}, " is on, include all pixels in any planes specified by ", {"text": ["EXR Data Window Planes"], "type": "ui"}, " whose values are strictly greater than this value. For example, if the value is 0 and only the A plane is selected, the data window rectangle will include all pixels with opacity greater than zero."]}], "indent": 0, "text": ["EXR Data Window Threshold"], "role": "item", "attrs": {"ifdprop": "renderer:exrdatawindowthreshold", "hprop": "vm_exrdatawindowthreshold"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Set EXR Data Window"], "type": "ui"}, " is on, include all pixels whose values are strictly greater than ", {"text": ["EXR Data Window Threshold"], "type": "ui"}, " in any of these image planes. This field supports wildcards and removals, like ", {"text": ["*"], "type": "code"}, ", to specify all planes, or ", {"text": ["diffuse* ^diffuse3"], "type": "code"}, ", to specify all planes whose names start with diffuse, except the diffuse3 plane."]}], "indent": 0, "text": ["EXR Data Window Planes"], "role": "item", "attrs": {"ifdprop": "renderer:exrdatawindowplanes", "hprop": "vm_exrdatawindowplanes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Type of image compression to use in TIFF files. Possible values are ", {"text": ["\"None\", \"LZW\", \"AdobeDeflate\", \"Deflate\", \"PackBits\", \"JPEG\", \"PixarLog\", \"SGILog\", \"SGILog24\""], "type": "code"}, "."]}], "indent": 0, "text": ["TIFF compression"], "role": "item", "attrs": {"hprop": "vm_image_tiff_compression"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Parameter to TIFF compressor. Leave this set to \"auto\". Possible values are ", {"text": ["\"auto\", \"none\", \"horizontal\""], "type": "code"}, "."]}], "indent": 0, "text": ["TIFF predictor"], "role": "item", "attrs": {"hprop": "vm_image_tiff_predictor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Type of image compression to use in RAT (Houdini texture) files. Possible values are ", {"text": ["\"deflate\", \"none\""], "type": "code"}, "."]}], "indent": 0, "text": ["RAT compression"], "role": "item", "attrs": {"hprop": "vm_image_rat_compression"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable generation of MIP MAPS when creating RAT files."]}], "indent": 0, "text": ["RAT generate MIP maps"], "role": "item", "attrs": {"hprop": "vm_image_rat_makemips"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["JPEG Quality, integer from ", {"text": ["10"], "type": "code"}, " to ", {"text": ["100"], "type": "code"}, "."]}], "indent": 0, "text": ["JPEG quality"], "role": "item", "attrs": {"hprop": "vm_image_jpeg_quality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Color space for Cineon format images. Possible values are ", {"text": ["\"log\""], "type": "code"}, " (unconverted), and ", {"text": ["\"lin\""], "type": "code"}, " (linear)."]}], "indent": 0, "text": ["Cineon color space"], "role": "item", "attrs": {"hprop": "vm_image_cineon_space"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Filename of a Look Up Table file to use for display of Cineon images in MPlay."]}], "indent": 0, "text": ["Cineon LUT"], "role": "item", "attrs": {"hprop": "vm_image_cineon_lut"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["White point for Cineon format images, integer from ", {"text": ["0"], "type": "code"}, " to ", {"text": ["1023"], "type": "code"}, ". The white-point of the image used during quantization.  Normally you should leave this parameter at the default value of 1 unless you wish to darken or lighten the image."]}], "indent": 0, "text": ["Cineon white point"], "role": "item", "attrs": {"hprop": "vm_image_cineon_whitepoint"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Cineon gamma"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_image_cineon_gamma"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Compression type for EXR format images. Possible values are ", {"text": ["\"none\", \"rle\", \"zips\", \"zip\", \"piz\", \"pix\""], "type": "code"}, "."]}], "indent": 0, "text": ["EXR Compression"], "role": "item", "attrs": {"hprop": "vm_image_exr_compression"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sets the amount of compression to use with OpenEXR\u2019s DWA compression type. \n    Higher values result in better compression and faster reads, but lower quality."]}], "indent": 0, "text": ["DWA Compression Level"], "role": "item", "attrs": {"hprop": "vm_image_exr_dwa_level"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Storage method for EXR format images. Possible values are ", {"text": ["\"scan\""], "type": "code"}, " (scanline) and ", {"text": ["\"tile\""], "type": "code"}, "."]}], "indent": 0, "text": ["EXR Storage"], "role": "item", "attrs": {"hprop": "vm_image_exr_storage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Additional attributes to set on EXR format images. The string is interpreted as \n    a Python dictionary, such as ", {"text": ["{'int_attr':1, 'flt_attr':2.3, 'vec3_attr':(0,1,2), 'str_attr':'foo'}"], "type": "code"}, ".\n    Any values that cannot be parsed or isn\u2019t recognized, will be silently ignored. The set of Python\n    value types recognized for use as an EXR attributes are: ", {"text": ["bool"], "type": "code"}, ", ", {"text": ["int"], "type": "code"}, ", ", {"text": ["float"], "type": "code"}, ", ", {"text": ["string"], "type": "code"}, ", and\n    3-, 4-, 9-, 16-value ", {"text": ["tuple"], "type": "code"}, " and ", {"text": ["list"], "type": "code"}, " of ", {"text": ["float"], "type": "code"}, ". Due to lack of 4-value vector attributes in the\n    EXR format, the ", {"text": ["Box"], "type": "code"}, " type attribute is used instead."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["The standard attributes cannot be overridden by this attribute string."]}], "indent": 4, "role": "item", "type": "note", "text": [" "]}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["EXR Attributes"], "role": "item", "attrs": {"hprop": "vm_image_exr_attributes"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["How to interpret mantra\u2019s framebuffer when saving out PNG. Possible values are ", {"text": ["\"premult\""], "type": "code"}, " or ", {"text": ["\"unpremult\""], "type": "code"}, ". Note that mantra\u2019s framebuffer always stores colors premultiplied by alpha, whereas PNG expects unpremultiplied colors, so using the default setting of ", {"text": ["\"premult\""], "type": "code"}, ", it will correctly interpret the data and predivide RGB channels upon write. If set to ", {"text": ["\"unpremult\""], "type": "code"}, ", then it will assume that the alpha is unassociated and will not touch RGB channels. "]}, {"indent": 4, "type": "para", "text": [{"text": ["\"unpremult\""], "type": "code"}, " option may be used for storing certain effects losslessly (such as emission that\u2019s not tied to opacity and thus does not contribute to alpha), however keep in mind that it will be outside the PNG specification and will be interpreted incorrectly without user intervention."]}], "indent": 0, "text": ["PNG premultiplied"], "role": "item", "attrs": {"hprop": "vm_image_png_frompremult"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how MPlay deals with new frames. Possible values are ", {"text": ["\"current\""], "type": "code"}, " (add rendered frames to MPlay\u2019s current sequence) or ", {"text": ["\"new\""], "type": "code"}, " (have MPlay start a new sequence)."]}], "indent": 0, "text": ["MPlay render mode"], "role": "item", "attrs": {"hprop": "vm_image_mplay_rendermode"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how MPlay inserts new frames into the current sequence. Possible values are ", {"text": ["\"append\""], "type": "code"}, " (add new frames on to the end of the current sequence), or ", {"text": ["\"match\""], "type": "code"}, " (replace frames with the same number in the current sequence)."]}], "indent": 0, "text": ["MPlay frame mode"], "role": "item", "attrs": {"hprop": "vm_image_mplay_framemode"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sets the background image, which will appear behind the rendered image."]}], "indent": 0, "text": ["MPlay background image"], "role": "item", "attrs": {"hprop": "vm_image_mplay_bgimage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering to MPlay, all Houdini sessions will send the output to the same MPlay flipbook. This can be problematic when running multiple Houdini sessions. The MPlay Label lets you specify a label for the MPlay associated with the output driver. Only renders which match the given label will be sent to that MPlay."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Uses the operating system process identifier so that the MPlay flipbook will only accept renders from that Houdini session."]}], "indent": 4, "type": "dt", "text": ["Houdini Process ID"]}, {"body": [{"indent": 8, "type": "para", "text": ["Uses the ", {"text": ["$HIPNAME"], "type": "code"}, " variable so the MPlay will only accept renders from the running ", {"text": ["$HIP"], "type": "code"}, " file."]}], "indent": 4, "type": "dt", "text": ["HIP Name"]}, {"body": [{"indent": 8, "type": "para", "text": ["The MPlay flipbook will only accept renders from the given output driver. For example, if you copy paste the output driver, each output driver will be sent to different MPlay flipbooks because the operators will have different names. "]}, {"indent": 8, "type": "para", "text": ["If there are multiple Houdini sessions, there may be output drivers in the other session which match the same operator name."]}, {"indent": 8, "type": "para", "text": ["For example, say you have two output drivers: \"High quality\" and \"Low Quality\". If you set the MPlay Label to different values for the two output drivers, each render will be sent to different MPlay sessions."]}], "indent": 4, "type": "dt", "text": ["Output Driver Name"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["MPlay session label"], "role": "item", "attrs": {"hprop": "vm_image_mplay_label"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["MPlay remote host"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_image_mplay_sockethost"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["MPlay remote host port"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_image_mplay_socketport"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The direction in which MPlay renders the image. Possible values are ", {"text": ["\"middle\""], "type": "code"}, " (middle out), ", {"text": ["\"top\""], "type": "code"}, " (top down), or ", {"text": ["\"bottom\""], "type": "code"}, " (bottom up)."]}], "indent": 0, "text": ["MPlay tile order"], "role": "item", "attrs": {"hprop": "vm_image_mplay_direction"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Display gamma for MPlay, from ", {"text": ["0.0"], "type": "code"}, " to ", {"text": ["4.0"], "type": "code"}, "."]}], "indent": 0, "text": ["MPlay gamma"], "role": "item", "attrs": {"hprop": "vm_image_mplay_gamma"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Filename of a Look Up Table file for MPlay."]}], "indent": 0, "text": ["MPlay display LUT"], "role": "item", "attrs": {"hprop": "vm_image_mplay_lut"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Meta data"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [], "indent": 0, "text": ["Force headlight creation"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_forceheadlight"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Objects"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The image or device where the resulting image will be rendered. You can set this value to ", {"text": ["ip"], "type": "code"}, " which renders the image in MPlay, or you can save it to an image. The following image types are supported: ", {"text": [".pic"], "type": "code"}, ", ", {"text": [".tif"], "type": "code"}, ", ", {"text": [".sgi"], "type": "code"}, ", ", {"text": [".pic.gz"], "type": "code"}, ", ", {"text": [".rat"], "type": "code"}, ", ", {"text": [".jpg"], "type": "code"}, ", ", {"text": [".cin"], "type": "code"}, ", ", {"text": [".rta"], "type": "code"}, ", ", {"text": [".bmp"], "type": "code"}, ", ", {"text": [".tga"], "type": "code"}, ", ", {"text": [".rad"], "type": "code"}, ", ", {"text": [".exr"], "type": "code"}, ", and ", {"text": [".png"], "type": "code"}, "."]}, {"indent": 4, "type": "para", "text": ["Include ", {"text": ["$F"], "type": "code"}, " in the file name to insert the frame number. This is necessary when rendering animation. See ", {"text": ["expressions in file names"], "fullpath": "/render/expressions", "scheme": null, "type": "link", "value": "/render/expressions"}, " for more information."]}], "indent": 0, "text": ["Output picture"], "role": "item", "attrs": {"ifdprop": "image:filename", "hprop": "vm_picture"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The image format or device for the output image.  If you leave this at the default value of ", {"text": ["Infer from filename"], "type": "ui"}, ", the image format will be selected based on the file extension (eg. .pic will automatically generate a Houdini format image.)"]}], "indent": 0, "text": ["Output device"], "role": "item", "attrs": {"ifdprop": "image:device", "hprop": "vm_device"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["no"], "type": "code"}, " \u2013 Overwrite any existing files"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["exist:vm_picture"], "type": "code"}, " \u2013 Skip rendering when a disk file already exists"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": [{"text": ["valid:vm_picture"], "type": "code"}, " \u2013 Skip rendering only when the disk file that exists is a valid image file."]}], "container": true, "type": "bullet_group"}], "indent": 4, "type": "para", "text": ["Determine how the output driver should deal with existing rendered frames."]}, {"indent": 4, "type": "para", "text": ["This parameter checks only the main image, not any deep raster or secondary images."]}], "indent": 0, "text": ["Skip Rendered Frames"], "role": "item", "attrs": {"hprop": "soho_skip_frame"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how transparent samples are combined to produce the color values for individual pixel samples. The sample filter is used to composite transparent surfaces before the pixel filter produces final pixel colors."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Uses the opacity (Of) values for transparent samples for compositing. This option should be used whenever correct transparent compositing is required. For example, when rendering volumes, sprites, or transparency."]}], "indent": 4, "type": "dt", "text": ["Opacity Filtering (", {"text": ["alpha"], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["Full Opacity Filtering (", {"text": ["fullopacity"], "type": "code"}, "):\n    When stochastic transparency is enabled, this option causes a channel to be evaluated and composited with every opacity evaluation - as opposed to only being composited with the samples that are selected for full shading.  It can be used to produce smoother results for channels that are fast to evaluate such as ", {"text": ["Ce"], "type": "code"}, " or ", {"text": ["direct_emission"], "type": "code"}, ".  When stochastic transparency is disabled, this option behaves the same way as ", {"text": ["Opacity Filtering"], "type": "ui"}, "."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Ignores the opacity values and just copies the color for the closest transparent sample into the image. This option disables transparency for a given deep raster plane and will only produce the closest sample results."]}], "indent": 4, "type": "dt", "text": ["Closest Surface (", {"text": ["closest"], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Sample filter"], "role": "item", "attrs": {"ifdprop": "plane:sfilter", "hprop": "vm_sfilter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the pixel filter used to combine sub-pixel samples to generate the value for the single pixel.  The filter is normally specified as a filter type (eg. ", {"text": ["gauss"], "type": "code"}, ") followed by an x and y filter width in pixels.  To blur the image, increase the filter width."]}, {"indent": 4, "type": "para", "text": ["There are several different pixel filters available."]}, {"body": [{"body": [{"indent": 0, "type": "para", "text": ["The style may be one of:"]}, {"body": [{"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["min"], "type": "code"}, " \u2013 Choose the value of the sample with the smallest z value (closest to camera)."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["max"], "type": "code"}, " \u2013 Choose the value of the sample with the maximum z value (farthest from camera)."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["median"], "type": "code"}, " \u2013 Choose the value of the sample that has the median z value of all samples."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["edge"], "type": "code"}, " \u2013 Filter using a unit box but only averages samples with object coverage.  This filter will have the effect of disabling external edge antialiasing."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["ocover"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then take the average value from the sub-pixels of that object only.  This filter is similar to ", {"text": ["edge"], "type": "code"}, " but it also disables internal edge antialiasing between object boundaries."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["idcover"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then select a single sample from that object for the pixel value.  This filter is similar to ", {"text": ["ocover"], "type": "code"}, " but it will not average any samples.  Use this filter mode for planes that will be interpreted as integers, such as object or primitive identifiers.  The sample chosen will be unordered."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["omin"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the smallest z value (closest to camera)."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["omax"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the maximum z value (farthest)."]}, {"indent": 0, "blevel": 2, "type": "bullet", "text": [{"text": ["omedian"], "type": "code"}, " \u2013 First, choose the object which covers most of the pixel, then choose a single sample from that object for the pixel value.  Chooses the sample with the median z value."]}], "container": true, "type": "bullet_group"}], "indent": 4, "type": "dt", "text": [{"text": ["minmax ", {"text": ["style"], "type": "var"}], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Choose the sub-pixel closest to the center of the pixel."]}], "indent": 4, "type": "dt", "text": [{"text": ["point"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a box filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["box [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Gaussian filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["gaussian [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Bartlett (cone)  filter to combine the sub-pixels with a size width given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["bartlett [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Blackman filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["blackman [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Catmull-Rom filter to combine the sub-pixels with a size width given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["catrom [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Hanning filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["hanning [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Mitchell filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["mitchell [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a sinc filter to combine the sub-pixels with a filter size given by width/height."]}], "indent": 4, "type": "dt", "text": [{"text": ["sinc [", {"text": ["width"], "type": "var"}, " ", {"text": ["height"], "type": "var"}, "]"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use an edge detection filter to find edges based on z-depth, object boundaries, and color gradients."]}], "indent": 4, "type": "dt", "text": [{"text": ["edgedetect"], "type": "code"}]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a Ray Histogram Fusion-based filter to combine the sub-pixels with the given similarity tolerance."]}, {"body": [{"body": [{"indent": 12, "type": "para", "text": ["This option is very slow and may eliminate some noise in an image, even if the noise is supposed to be there (ie, not just noise due to undersampling), resulting in loss of detail. "]}], "indent": 8, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 4, "type": "dt", "text": [{"text": ["combine -t ", {"text": ["tolerance"], "type": "var"}], "type": "code"}]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Pixel filter"], "role": "item", "attrs": {"ifdprop": "plane:pfilter", "hprop": "vm_pfilter"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Gamma"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_gamma"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Gain"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_gain"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Dither amount for the image plane."]}], "indent": 0, "text": ["Dither"], "role": "item", "attrs": {"ifdprop": "plane:dither", "hprop": "vm_dither"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The storage type for the main image.  The type of quantization used will affect image quality and size.  If you need to adjust the image\u2019s dynamic range in compositing, you should normally leave this value at the default of 16-bit floating point."]}, {"indent": 4, "type": "para", "text": ["The default is ", {"text": ["\"float16\""], "type": "code"}, " for the first plane, and ", {"text": ["\"float\""], "type": "code"}, " for secondary planes. You can override the first plane\u2019s value with the ", {"text": ["-b"], "type": "code"}, " command line argument to mantra."]}], "indent": 0, "text": ["Quantization"], "role": "item", "attrs": {"hprop": "vm_quantize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["White point for the image plane."]}], "indent": 0, "text": ["White point"], "role": "item", "attrs": {"ifdprop": "plane:whitepoint", "hprop": "vm_whitepoint"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Normally the image resolution is set on the camera object. Turn this on to enable controls that modify or override the camera\u2019s settings."]}], "indent": 0, "text": ["Override camera resolution"], "role": "item", "attrs": {"hprop": "override_camerares"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Override camera resolution"], "type": "ui"}, " is on and ", {"text": ["Resolution scale"], "type": "ui"}, " is \"User specified resolution\", lets you set the resolution of the output image, overriding the settings on the camera."]}], "indent": 0, "text": ["Resolution override"], "role": "item", "attrs": {"hprop": "res_override"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Choose resolution"], "role": "item", "attrs": {"status": "nd", "hprop": "res_overrideMenu"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Override camera resolution"], "type": "ui"}, " is on, allows you to scale whatever resolution is set on the camera. To completely override the camera\u2019s resolution, choose \"User specified resolution\"."]}], "indent": 0, "text": ["Resolution scale"], "role": "item", "attrs": {"hprop": "res_fraction"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The pixel aspect ratio represents the width of a pixel divided by the height of a pixel. It is not the aspect ratio of the image (which is determined by the resolution of the image). This parameter does not affect rendering, it is only used to change how images are displayed, by stretching the pixels by this factor."]}], "indent": 0, "text": ["Pixel Aspect Ratio"], "role": "item", "attrs": {"hprop": "aspect_override"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When you render a target node with this option on using HQueue, the server will split frames to render into separate tiles and render each tile as a separate job. When you render locally with this option on, Mantra will render a single tile instead of the entire frame."]}, {"indent": 4, "type": "para", "text": ["Tiled render can also be enabled using ", {"text": ["-t"], "type": "code"}, " command line option to mantra, which can be used to render a tile locally without having to generate an IFD for each tile with ", {"text": ["Tiled render"], "type": "ui"}, " enabled."]}], "indent": 0, "text": ["Tiled render"], "role": "item", "attrs": {"hprop": "vm_tile_render"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Split the frame into this number of tiles horizontally, when ", {"text": ["Tile render"], "type": "ui"}, " is on."]}], "indent": 0, "text": ["Horizontal tiles"], "role": "item", "attrs": {"ifdprop": "image:tiledrendercount", "hprop": "vm_tile_count_x"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Split the frame into this number of tiles vertically, when ", {"text": ["Tile render"], "type": "ui"}, " is on."]}], "indent": 0, "text": ["Vertical tiles"], "role": "item", "attrs": {"ifdprop": "image:tiledrendercount", "hprop": "vm_tile_count_y"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Which tile to render, when rendering locally with ", {"text": ["Tile render"], "type": "ui"}, " on. Tile numbers start at 0 in the top left and increase left to right, top to bottom."]}], "indent": 0, "text": ["Tile index"], "role": "item", "attrs": {"ifdprop": "image:tiledrenderindex", "hprop": "vm_tile_index"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, image tile data will be frequently written out to a checkpoint file in the same directory as the output file.  If the process is terminated before completing the render, it can then be resumed by turning on ", {"text": ["Resume from Checkpoint Files"], "type": "ui"}, " and restarting.  To specify an alternative checkpoint file name, enable __Checkpoint File Name___."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Checkpointing does not work when creating a deep shadow map or deep camera map."]}], "indent": 4, "role": "item", "type": "warning"}], "container": true, "role": "item_group", "type": "warning_group"}, {"indent": 4, "type": "para", "text": ["The checkpoint file will be deleted if the render completes successfully."]}], "indent": 0, "text": ["Output Checkpoint Files"], "role": "item", "attrs": {"ifdprop": "renderer:writecheckpoint", "hprop": "vm_writecheckpoint"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, before rendering, Mantra will look for a checkpoint file corresponding with the current output file, generated by a previous partial render that had ", {"text": ["Output Checkpoint Files"], "type": "ui"}, " enabled.  If possible, Mantra will only render areas that are needed for remaining regions of the output image.  To specify an alternative checkpoint file name, enable __Checkpoint File Name___."]}, {"indent": 4, "type": "para", "text": ["If both ", {"text": ["Output Checkpoint Files"], "type": "ui"}, " and ", {"text": ["Resume from Checkpoint Files"], "type": "ui"}, " are enabled and a valid checkpoint file is loaded, any additional image tile data rendered will be appended to the checkpoint file."]}], "indent": 0, "text": ["Resume from Checkpoint Files"], "role": "item", "attrs": {"ifdprop": "renderer:readcheckpoint", "hprop": "vm_readcheckpoint"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, checkpoint files used by ", {"text": ["Output Checkpoint Files"], "type": "ui"}, " and ", {"text": ["Resume from Checkpoint Files"], "type": "ui"}, " will be named based on ", {"text": ["Checkpoint File Name"], "type": "ui"}, "."]}], "indent": 0, "text": ["Override Checkpoint File Name"], "role": "item", "attrs": {"ifdprop": "renderer:overridecheckpointname", "hprop": "vm_overridecheckpointname"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Override Checkpoint File Name"], "type": "ui"}, " is enabled, this specifies the names for checkpoint files used by ", {"text": ["Output Checkpoint Files"], "type": "ui"}, " and ", {"text": ["Resume from Checkpoint Files"], "type": "ui"}, ".  It can contain expressions."]}], "indent": 0, "text": ["Checkpoint File Name"], "role": "item", "attrs": {"ifdprop": "renderer:checkpointname", "hprop": "vm_checkpointname"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Tile suffix"], "role": "item", "attrs": {"status": "nd", "ifdprop": "image:tiledrendersuffix", "hprop": "vm_tile_filename_suffix"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Normally, sub-pixel samples are filtered using the pixel filter defined on an image plane. When this is turned on, each sub-pixel is output without any pixel filtering performed. "]}, {"indent": 4, "type": "para", "text": ["The ", {"text": ["image:resolution"], "type": "code"}, " property will be scaled by the ", {"text": ["image:samples"], "type": "code"}, " property to determine the actual output image resolution. For example, if ", {"text": ["image:resolution"], "type": "code"}, " was ", {"text": ["(1024,512)"], "type": "code"}, " and ", {"text": ["image:samples"], "type": "code"}, " was ", {"text": ["(4,6)"], "type": "code"}, ", the image rendered would have a resolution of 4096 by 3072. Each pixel would represent a single unfiltered sub-pixel sample."]}], "indent": 0, "text": ["Sub-pixel output"], "role": "item", "attrs": {"ifdprop": "image:subpixel", "hprop": "vm_subpixel"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable rendering to MPlay"], "role": "item", "attrs": {"status": "nd", "ifdprop": "image:batchmode", "hprop": "vm_imagebatchmode"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Video field"], "role": "item", "attrs": {"hprop": "vm_field"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Renders an image from the viewing camera. Sometimes, it is useful to skip this render, for example, when rendering shadow maps."]}], "indent": 0, "text": ["Create image from viewing camera"], "role": "item", "attrs": {"hprop": "render_viewcamera"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable or disable shadow map generation. Each light also has its own controls to determine whether shadow maps will be generated."]}], "indent": 0, "text": ["Auto-generate shadow maps"], "role": "item", "attrs": {"hprop": "render_any_shadowmap"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable or disable environment map generation. Each object can be set up to generate an environment map of all the other objects in the scene."]}], "indent": 0, "text": ["Auto-generate environment maps"], "role": "item", "attrs": {"hprop": "render_any_envmap"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable or disable photon map generation."]}], "indent": 0, "text": ["Auto-generate photon maps"], "role": "item", "attrs": {"hprop": "render_any_photonmap"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Auto-generate light point clouds"], "role": "item", "attrs": {"status": "nd", "hprop": "render_any_pointcloud"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Auto-generate shadow map"], "role": "item", "attrs": {"status": "nd", "hprop": "render_shadowmap"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Auto-generate environment map"], "role": "item", "attrs": {"status": "nd", "hprop": "render_envmap"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Auto-generate photon map"], "role": "item", "attrs": {"status": "nd", "hprop": "render_photonmap"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Output"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The shader used to evaluate samples for the PBR rendering engine. If no shader is specified, the default VEX Pathtracer shader is used.  Normally you should not need to assign a shader for this parameter unless you are a shader writer and need to make adjustments to the PBR shading algorithm."]}], "indent": 0, "text": ["PBR shader"], "role": "item", "attrs": {"ifdprop": "renderer:pbrshader", "hprop": "vm_pbrshader"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["PBR"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The number of photons sent when ", {"text": ["renderer:renderengine"], "type": "code"}, " is set to \"photon\"."]}], "indent": 0, "text": ["Photon storage count"], "role": "item", "attrs": {"ifdprop": "photon:photoncount", "hprop": "vm_photoncount"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add this property to control the minimum photon acceptance ratio. This parameter is a value between 0 and 1 to control the minimum proportion of photons sent that must be stored before mantra will bail out on photon generation from that light."]}], "indent": 0, "text": ["Minimum photon storage ratio"], "role": "item", "attrs": {"ifdprop": "renderer:photonminratio", "hprop": "vm_photonminratio"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["renderer:renderengine"], "type": "code"}, " is \"photon\", this determines the photon map file for diffuse photons (irradiance)."]}], "indent": 0, "text": ["Global photon file"], "role": "item", "attrs": {"ifdprop": "photon:photongfile", "hprop": "vm_photongfile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["renderer:renderengine"], "type": "code"}, " is \"photon\", this determines the photon map file for caustic photons (specular bounces)."]}], "indent": 0, "text": ["Caustic photon file"], "role": "item", "attrs": {"ifdprop": "photon:photoncfile", "hprop": "vm_photoncfile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When sending photons from this light source, this is the category expression to determine which objects will receive photons."]}], "indent": 0, "text": ["Photon target"], "role": "item", "attrs": {"ifdprop": "light:photontarget", "hprop": "vm_photontarget"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the proportion of photons that should be generated by this light relative to other lights in the scene.  By default, all lights have an equal weight of 1."]}], "indent": 0, "text": ["Photon weight"], "role": "item", "attrs": {"ifdprop": "light:photonweight", "hprop": "vm_photonweight"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Affects the way that photons are traced through the scene. When a photon hits a surface the parameter affects it depending on the selected option. This is only used if the scene has a light (such as the GI Light) that uses photon mapping."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Photon is not modified, bouncing as usual (this is the default)."]}], "indent": 4, "type": "dt", "text": ["None"]}, {"body": [{"indent": 8, "type": "para", "text": ["Photon passes through the surface, not being stored."]}], "indent": 4, "type": "dt", "text": ["Pass Through"]}, {"body": [{"indent": 8, "type": "para", "text": ["Photon is stopped, ending the path trace for that photon."]}], "indent": 4, "type": "dt", "text": ["Block"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Photon modifier"], "role": "item", "attrs": {"ifdprop": "object:photonmodifier", "hprop": "vm_photonmodifier"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Photon"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Enable IPR rendering"]}], "indent": 0, "text": ["Enable preview"], "role": "item", "attrs": {"ifdprop": "renderer:preview", "hprop": "vm_preview"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The IPR rendering mode (blur, sharp or ordered)."]}], "indent": 0, "text": ["Preview mode"], "role": "item", "attrs": {"ifdprop": "renderer:previewmode", "hprop": "vm_previewmode"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Target time to spend on a tile in IPR."]}], "indent": 0, "text": ["Preview time"], "role": "item", "attrs": {"ifdprop": "renderer:previewtime", "hprop": "vm_previewtime"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Adaptively update tile sampling."]}], "indent": 0, "text": ["Enable adaptive preview"], "role": "item", "attrs": {"ifdprop": "renderer:previewadaptive", "hprop": "vm_previewadaptive"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls how much of an effect the adaptive sampling contributes per tile."]}], "indent": 0, "text": ["Adaptive preview factor"], "role": "item", "attrs": {"ifdprop": "renderer:previewadaptivefactor", "hprop": "vm_previewadaptivefactor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable IPR image relighting."]}], "indent": 0, "text": ["Use the relighting buffer for preview"], "role": "item", "attrs": {"ifdprop": "renderer:relightingbuffer", "hprop": "vm_relightingbuffer"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Base the number of samples per pass on ", {"text": ["vm_iprpasssamples"], "type": "code"}, ". Primarily useful for performance testing."]}], "indent": 0, "text": ["Preview uses fixed samples per pass"], "role": "item", "attrs": {"ifdprop": "renderer:iprfixsamples", "hprop": "vm_iprfixsamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sets the number of samples taken per pass, as a multiple of the minimum number of samples per pass. Primarily useful for performance testing."]}], "indent": 0, "text": ["Preview samples per pass"], "role": "item", "attrs": {"ifdprop": "renderer:iprpasssamples", "hprop": "vm_iprpasssamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Only used for performance testing. A fake relighting buffer is created and zeroed."]}], "indent": 0, "text": ["Use fake relighting buffer"], "role": "item", "attrs": {"ifdprop": "renderer:iprfakerelight", "hprop": "vm_iprfakerelight"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Allows IPR to use tile sizes less than 64\u00d764 pixels."]}], "indent": 0, "text": ["Minimum preview tile size"], "role": "item", "attrs": {"ifdprop": "renderer:iprbucket", "hprop": "vm_iprbucketsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["IPR mouse radius control."]}], "indent": 0, "text": ["Preview mouse radius"], "role": "item", "attrs": {"ifdprop": "renderer:previewmouseradius", "hprop": "vm_previewmouseradius"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Always use ray-traced shadows in IPR rendering."]}], "indent": 0, "text": ["Always use raytraced shadows in preview mode"], "role": "item", "attrs": {"hprop": "vm_iprraytraceshadows"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Allows IPR to determine which material style sheets contributed to a pixel in the render output."]}], "indent": 0, "text": ["Output extra material style sheet data"], "role": "item", "attrs": {"ifdprop": "renderer:stylesheets", "hprop": "vm_stylesheets"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Preview"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [], "indent": 0, "text": ["Display as"], "role": "item", "attrs": {"status": "nd", "hprop": "viewportlod"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Is UV rendering"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_isuvrendering"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["UV Current UV Object"], "role": "item", "attrs": {"status": "nd", "ifdprop": "renderer:uvcurrentuvobject", "hprop": "vm_uvcurrentuvobject"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["UV Current Cage Object"], "role": "item", "attrs": {"status": "nd", "ifdprop": "renderer:uvcurrentcageobject", "hprop": "vm_uvcurrentcageobject"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["UV Current Hires Object"], "role": "item", "attrs": {"status": "nd", "ifdprop": "renderer:uvcurrenthiresobject", "hprop": "vm_uvcurrenthiresobject"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The size (in pixels) of the tiles rendered by mantra. Larger tile sizes may consume more memory."]}], "indent": 0, "text": ["Tile size"], "role": "item", "attrs": {"ifdprop": "image:bucket", "hprop": "vm_bucketsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Set the color of the tile borders to indicate which thread was responsible \n    for rendering it. This can be be used to visually check for thread balancing\n    issues."]}], "indent": 0, "text": ["Color Tile Borders by Thread Index"], "role": "item", "attrs": {"ifdprop": "image:bucketthreadcolor", "hprop": "vm_bucketthreadcolor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This property will be used to cull out parts of the volume behind fully opaque portions.\n    After shading of a surface, if the Of variable is less than this threshold, mantra will consider that the surface doesn\u2019t exist and samples will be ignored."]}], "indent": 0, "text": ["Opacity threshold"], "role": "item", "attrs": {"ifdprop": "image:opacitythresh", "hprop": "vm_opacitythresh"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to use a fixed size cache (", {"text": ["vm_cachesize"], "type": "code"}, ") or whether to use a proportion of physical memory (", {"text": ["vm_cacheratio"], "type": "code"}, ")"]}], "indent": 0, "text": ["Cache Limit"], "role": "item", "attrs": {"ifdprop": "renderer:usecacheratio", "hprop": "vm_usecacheratio"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The proportion of physical memory Mantra will use for its unified cache."]}, {"indent": 4, "type": "para", "text": ["For example, with the default ", {"text": ["vm_cacheratio"], "type": "code"}, " of ", {"text": ["0.25"], "type": "code"}, " and 16 Gb of physical memory, Mantra will use 4 Gb for its unified cache."]}, {"indent": 4, "type": "para", "text": ["The unified cache stores dynamic, unloadable data used by the render including the following:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": ["2D ", {"text": [".rat"], "type": "code"}, " texture tiles"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["3D ", {"text": [".i3d"], "type": "code"}, " texture tiles"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["3D ", {"text": [".pc"], "type": "code"}, " point cloud pages (when not preloaded into memory)"]}, {"body": [{"body": [{"indent": 8, "blevel": 10, "type": "bullet", "text": ["Displacements"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": ["Subdivision surfaces"]}, {"indent": 8, "blevel": 10, "type": "bullet", "text": ["Bezier and NURBS primitives"]}], "container": true, "type": "bullet_group"}], "indent": 4, "blevel": 6, "type": "bullet", "text": ["Tessellated meshes required by ray tracing:"]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Cache Memory Ratio"], "role": "item", "attrs": {"ifdprop": "renderer:cacheratio", "hprop": "vm_cacheratio"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["An explicit memory limit for the unified shading cache.  This is deprecated in favor of using the ", {"text": ["Cache Memory Ratio"], "type": "ui"}, "."]}], "indent": 0, "text": ["Cache Size (MB)"], "role": "item", "attrs": {"ifdprop": "renderer:cachesize", "hprop": "vm_cachesize"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Sample data cache size (MB)"], "role": "item", "attrs": {"status": "nd", "ifdprop": "renderer:samplecachesize", "hprop": "vm_samplecachesize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Perform hidden surface removal. When hidden surface removal is disabled, all surfaces in the camera\u2019s frustum will be rendered, regardless of whether they are occluded. This can impact render time significantly."]}], "indent": 0, "text": ["Enable hiding"], "role": "item", "attrs": {"ifdprop": "renderer:hidden", "hprop": "vm_hidden"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, automatically set the thread count (", {"text": ["renderer:threadcount"], "type": "code"}, " IFD property) to the number of CPUs of the rendering machine."]}], "indent": 0, "text": ["Use max processors"], "role": "item", "attrs": {"ifdprop": "renderer:usemaxthreads", "hprop": "vm_usemaxthreads"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Use Max Processors"], "type": "ui"}, " (", {"text": ["renderer:usemaxthreads"], "type": "code"}, " IFD property) is disabled, sets the number of threads Mantra uses for rendering."]}], "indent": 0, "text": ["Thread count"], "role": "item", "attrs": {"ifdprop": "renderer:threadcount", "hprop": "vm_threadcount"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls what value is set for ", {"text": ["$HIP"], "type": "code"}, " in the IFD file. By default this is the same as ", {"text": ["$HIP"], "type": "code"}, " in Houdini, which is usually what you want. However, you may need to set ", {"text": ["$HIP"], "type": "code"}, " to something different in the IFD if you are doing interesting things with a render farm, for example."]}], "indent": 0, "text": ["Override HIP in IFD"], "role": "item", "attrs": {"hprop": "vm_hippath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Inherit properties"], "role": "item", "attrs": {"status": "nd", "hprop": "vm_inheritproperties"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls which style sheets defined in the hip file are embedded into the IFD. Standard Houdini pattern matching is used on each embedded style sheet name."]}], "indent": 0, "text": ["Declare style sheets"], "role": "item", "attrs": {"hprop": "declare_stylesheets"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies which style sheets mantra should apply during rendering. This is a space separated list of either names of style sheets embedded in the hip file, or external JSON files on disk. As with individual styles within a single style sheet, style sheets later in the list take precedence over style sheets earlier in the list."]}], "indent": 0, "text": ["Apply style sheets"], "role": "item", "attrs": {"hprop": "apply_stylesheets"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enabling this option forces all node bundles to be saved to the IFD.  Bundles can be used by style sheets to target objects. If this feature is used in style sheets defined on disk, you may need to enable this option to get the expected results from the style sheets."]}], "indent": 0, "text": ["Declare all bundles"], "role": "item", "attrs": {"hprop": "declare_bundles"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls which SHOPs are embedded in the generated IFD. This parameter can be used to force all SHOPs or all Material SHOPs to be embedded even if Houdini does not find explicit references to those SHOPs on the output objects and geometry."]}], "indent": 0, "text": ["Declare materials"], "role": "item", "attrs": {"hprop": "declare_all_shops"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enabling this checkbox will expand any variables in OTL paths, breaking the dependency on Houdini environment variables, but possibly making the IFD less portable."]}], "indent": 0, "text": ["Output OTLs with full paths"], "role": "item", "attrs": {"hprop": "vm_otlfullpath"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Mantra is able to load the shader directly from the OTL when Houdini uses a shader defined in an OTL. When shaders are built using VOPs, the shader must be embedded in the IFD. Enabling this option will force Houdini to embed the shaders defined by OTLs."]}, {"indent": 4, "type": "para", "text": ["This option makes the IFD more self-contained so that machines which don\u2019t have the OTL installed (or a different version of the OTL) are able to evaluate the shaders correctly."]}, {"indent": 4, "type": "para", "text": ["However, if you have complicated shaders, embedding them will bloat the size of the IFD significantly."]}], "indent": 0, "text": ["Force VEX shader embedding"], "role": "item", "attrs": {"hprop": "vm_embedvex"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to enable motion blur sampling for scanline rendering."]}], "indent": 0, "text": ["Enable motion blur"], "role": "item", "attrs": {"ifdprop": "renderer:blurquality", "hprop": "vm_blurquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to allow motion blur sampling for ray-traced rendering."]}], "indent": 0, "text": ["Enable raytraced motion blur"], "role": "item", "attrs": {"ifdprop": "renderer:rayblurquality", "hprop": "vm_rayblurquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Allow depth of field rendering."]}], "indent": 0, "text": ["Enable Depth of Field"], "role": "item", "attrs": {"ifdprop": "renderer:dofquality", "hprop": "vm_dofquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to allow ray-tracing.  By disallowing ray-tracing no ray-traced shadows, reflections, refractions, etc. will be performed."]}], "indent": 0, "text": ["Enable raytracing"], "role": "item", "attrs": {"ifdprop": "renderer:rayquality", "hprop": "vm_rayquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to enable the irradiance and occlusion VEX functions. This also controls whether irradiance caching will be enabled."]}], "indent": 0, "text": ["Enable GI"], "role": "item", "attrs": {"ifdprop": "renderer:giquality", "hprop": "vm_giquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to enable dicing of displacements/subdivisions. Disabling this setting will have the same effect as disabling ", {"text": ["Polygons as subdivision"], "type": "code"}, " on all objects and disabling ", {"text": ["true displacements"], "type": "code"}, " on all materials."]}], "indent": 0, "text": ["Enable dicing"], "role": "item", "attrs": {"ifdprop": "renderer:dicingquality", "hprop": "vm_dicingquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Allow interruption of rendering.  This is typically enabled for IPR rendering."]}], "indent": 0, "text": ["Enable render interrupt"], "role": "item", "attrs": {"ifdprop": "renderer:renderinterrupt", "hprop": "vm_renderinterrupt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the type of ray tracing accelerator used by mantra. A ray tracing accelerator is a spatial data structure used to optimize the performance of ray intersection tests against complex geometry. "]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Ray trace using a KD-Tree. Normally, the KD-Tree will produce the fastest raytracing performance at a modest initialization time. It is possible to control the performance/quality tradeoff for KD-Tree construction with the ", {"text": ["KD-Tree Memory Factor"], "type": "ui"}, " parameter (", {"text": ["vm_kdmemfactor"], "type": "code"}, "). "]}], "indent": 4, "type": "dt", "text": ["KD-Tree (", {"text": ["\"kdtree\""], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Ray trace using a bounding volume hierarchy. Sometimes a bounding volume hierarchy will be faster to construct and/or faster to raytrace than a KD-Tree. "]}], "indent": 4, "type": "dt", "text": ["Bounding Volume Hierarchy (", {"text": ["\"bboxtree\""], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Ray tracing accelerator"], "role": "item", "attrs": {"ifdprop": "renderer:octreestyle", "hprop": "vm_octreestyle"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Change the memory/performance tradeoff used when constructing KD-Tree acceleration data structures. Values larger than 1 will cause mantra to use proportionally more memory and take longer to optimize the tree in an attempt to make ray tracing faster. Smaller values will cause mantra to use proportionally less memory and take less time to optimize the tree, while possibly compromising ray tracing performance. The default value of 1 will try to balance the amount of memory used by ray tracing data structures with the amount of memory used by geometry."]}, {"indent": 4, "type": "para", "text": ["If you are noticing long tree construction times, try decreasing the KD memory factor to 0.1. If your render is too slow after tree construction, increase the value until you find a good balance of tree construction time vs. render performance."]}], "indent": 0, "text": ["KD-Tree memory factor"], "role": "item", "attrs": {"ifdprop": "renderer:kdmemfactor", "hprop": "vm_kdmemfactor"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables a ray tracing tree construction algorithm that uses rotations to locally align the axes with the dominant geometric directions. This approach only works on curves, and will usually increase the amount of time required to build the ray tracing tree. However the resulting trees may improve ray tracing performance particularly for bundles of long curves that are not aligned to the x, y, or z axis as can commonly occur when rendering long hair."]}], "indent": 0, "text": ["Enable Oriented BVH Construction"], "role": "item", "attrs": {"ifdprop": "renderer:bvhoriented", "hprop": "vm_bvhoriented"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of curve segments to group together when building ray tracing objects for curves. Larger values will reduce memory use but will decrease performance since the ray tracer needs to attempt more ray intersections. A value of 1 will create one ray tracing object per curve segment resulting in the best possible ray tracing performance but can increase memory use substantially."]}], "indent": 0, "text": ["Ray Tracing Curve Bunch Size"], "role": "item", "attrs": {"ifdprop": "renderer:curvebunchsize", "hprop": "vm_curvebunchsize"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Use ray level of detail"], "role": "item", "attrs": {"status": "nd", "ifdprop": "renderer:bboxenablelod", "hprop": "vm_bboxenablelod"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the amount of time to render in seconds, or 0 to render until completion."]}], "indent": 0, "text": ["Render Time Limit"], "role": "item", "attrs": {"ifdprop": "renderer:timelimit", "hprop": "vm_timelimit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["By default, mantra lets the system perform a cleanup of the process resources.  A quick-exit is very efficient, but this case, mantra won\u2019t do any cleanup itself.  This means that custom VEX cleanup functions may not be run."]}], "indent": 0, "text": ["Quick exit"], "role": "item", "attrs": {"hprop": "vm_quickexit"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["true"], "type": "code"}, ", the object will not be rendered by primary rays. Only secondary rays will hit the object."]}, {"indent": 4, "type": "para", "text": ["(See the ", {"fragment": "#vm_rendervisibility", "text": ["Render Visibility"], "value": "/props/mantra#vm_rendervisibility", "fallback_text": "vm_rendervisibility", "fullpath": "/props/mantra#vm_rendervisibility", "scheme": "Mantra", "type": "link"}, " property)."]}], "indent": 0, "text": ["Phantom"], "role": "item", "attrs": {"ifdprop": "object:phantom", "hprop": "vm_phantom"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If this option is turned off, then the instance will not be rendered. The object\u2019s properties can still be queried from within VEX, but no geometry will be rendered. This is roughly equivalent to turning the object into a transform space object."]}, {"indent": 4, "type": "para", "text": ["See ", {"text": ["Render Visibility"], "type": "ui"}, " (", {"text": ["vm_rendervisibility"], "type": "code"}, " property)."]}], "indent": 0, "text": ["Renderable"], "role": "item", "attrs": {"ifdprop": "object:renderable", "hprop": "vm_renderable"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the visibility of an object to different types of rays using a category expression. This parameter generalizes the Phantom and Renderable toggles and allows more specific control over the visibility of an object to the different ray types supported by mantra and VEX."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": ["\"primary\" - Rays sent from the camera"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["\"shadow\" - Shadow rays"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["\"diffuse\" - Diffuse rays"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["\"reflect\" - Reflections"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["\"refract\" - Refractions"]}], "container": true, "type": "bullet_group"}, {"indent": 4, "type": "para", "text": ["For example, to create a phantom object, set the expression to \"-primary\". To create an unrenderable object, set the expression to the empty string \"\". These tokens correspond to the string given to \"raystyle\" in the VEX trace() and gather() functions."]}], "indent": 0, "text": ["Render Visibility"], "role": "item", "attrs": {"ifdprop": "object:rendervisibility", "hprop": "vm_rendervisibility"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is set to the \"root\" of the object tree. In Houdini, this is typically ", {"text": ["/obj"], "type": "code"}, ". If object names are specified using relative paths (i.e. ", {"text": ["light1"], "type": "code"}, " or ", {"text": ["subnet1/light1"], "type": "code"}, "), this is used to determine the full path. This will be deprecated in the future in favor of category selection."]}], "indent": 0, "text": ["Object root path"], "role": "item", "attrs": {"ifdprop": "renderer:objroot", "hprop": "vm_objroot"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Render polygons as a subdivision surface. The ", {"text": ["creaseweight"], "type": "code"}, " attribute is used to perform linear creasing. This attribute may appear on points, vertices or primitives."]}, {"indent": 4, "type": "para", "text": ["When rendering using OpenSubdiv, in addition to the ", {"text": ["creaseweight"], "type": "code"}, ", ", {"text": ["cornerwieght"], "type": "code"}, " attributes and the ", {"text": ["subdivision_hole"], "type": "code"}, " group, additional attributes are scanned to control the behaviour of refinement.  These override any other settings:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["int osd_scheme"], "type": "code"}, ", ", {"text": ["string osd_scheme"], "type": "code"}, ":  Specifies the scheme for OSD subdivision (0 or \"catmull-clark\"; 1 or \"loop\";  2 or \"bilinear\").  Note that for Loop subdivision, the geometry can only contain triangles."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["int osd_vtxboundaryinterpolation"], "type": "code"}, ": The Vertex Boundary Interpolation method (see ", {"text": ["vm_osd_vtxinterp"], "type": "code"}, " for further details)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["int osd_fvarlinearinterpolation"], "type": "code"}, ": The Face-Varying Linear Interpolation method (see ", {"text": ["vm_osd_fvarinterp"], "type": "code"}, " for further details)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["int osd_creasingmethod"], "type": "code"}, ": Specify the creasing method, 0 for Catmull-Clark, 1 for Chaikin"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["int osd_trianglesubdiv"], "type": "code"}, ": Specifies the triangle weighting algorithm, 0 for Catmull-Clark weights, 1 for \"smooth triangle\" weights."]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Polygons as subdivision (Mantra)"], "role": "item", "attrs": {"ifdprop": "object:rendersubd", "hprop": "vm_rendersubd"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The algorithm used to render subdivision surfaces.  Currently, this can be either ", {"text": ["mantra_catclark"], "type": "code"}, " or ", {"text": ["osd_catclark"], "type": "code"}, "."]}], "indent": 0, "text": ["Subdivision Style"], "role": "item", "attrs": {"ifdprop": "object:subdstyle", "hprop": "vm_subdstyle"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A primitive group of polygons which should be rendered as a subdivision surface.  This is only effective if ", {"text": ["vm_rendersubd"], "type": "code"}, " is enabled."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["This is a group on the final geometry that is being rendered. For example, if the top-level primitive is an Alembic primitive, then the ", {"text": ["vm_subdgroup"], "type": "code"}, " refers to a given face set in that primitive."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["Subdivision Group"], "role": "item", "attrs": {"ifdprop": "object:subdgroup", "hprop": "vm_subdgroup"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The dicing quality when rendering subdivision surfaces as ", {"text": ["osd_catclark"], "type": "code"}, ".  This value is multiplied by the shading quality and shading factor to determine the number of refinement levels for the surface."]}], "indent": 0, "text": ["OpenSubdiv Quality"], "role": "item", "attrs": {"ifdprop": "object:osd_quality", "hprop": "vm_osd_quality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["How subdivision vertex (Houdini point) attributes are interpolated on boundaries."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": ["0: Do not interpolate boundaries"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["1: Sharpen edges"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["2: Sharpen edges and corners"]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["OpenSubdiv Vertex Boundary Interpolation"], "role": "item", "attrs": {"ifdprop": "object:osd_vtxinterp", "hprop": "vm_osd_vtxinterp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["How subdivision face varying (Houdini vertex) attributes are interpolated."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": ["0: Smooth everywhere (\"edge only\")"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["1: Sharpen corners only"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["2: Sharpen edges and corners"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["3: Sharpen edges and corners and propagate corners"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["4: Sharpen all boundaries (\"always sharp\")"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["5: Bilinear interpolation"]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["OpenSubdiv FVar Linear Interpolation"], "role": "item", "attrs": {"ifdprop": "object:osd_fvarinterp", "hprop": "vm_osd_fvarinterp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls whether geometry groups are saved to the IFD.  Groups can require \n    a significant amount of storage and are normally unused during rendering - \n    so leaving this option disabled will improve IFD generation time and \n    reduce file size."]}], "indent": 0, "text": ["Save geometry groups"], "role": "item", "attrs": {"hprop": "vm_savegroups"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Render"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Mantra will render with depth of field. The parameters controlling depth of field may be found on the camera object."]}], "indent": 0, "text": ["Enable depth of field"], "role": "item", "attrs": {"hprop": "vm_dof"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Mantra will render the image using motion blur. The shutter parameter on the camera determines the duration of the shutter, specified as a fraction of the frame.  The ", {"text": ["Xform Time Samples"], "type": "ui"}, " and ", {"text": ["Geo Time Samples"], "type": "ui"}, " parameters should be used in motion blur renders to control how motion blur is computed.  By default, only transformation motion blur with 2 segments will be computed - meaning that animated SOPs will not produce blur in the render.  To enable motion blur for moving geometry, it\u2019s necessary to increase the ", {"text": ["Geo Time Samples"], "type": "ui"}, "."]}], "indent": 0, "text": ["Allow motion blur"], "role": "item", "attrs": {"hprop": "allowmotionblur"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is an advanced property which can be added per object."]}, {"indent": 4, "type": "para", "text": ["If the property is set, SOHO will automatically enable the Engine\n    Procedural for this object.  The object network itself will be saved as an\n    HDA in the IFD stream for use by the Engine Procedural.  At render time,\n    mantra will take the geometry generated by the Display SOP and instance it\n    to each point in the geometry on the Render SOP\u2019s geometry.  For each\n    instance, point attributes on the Render SOP\u2019s points that match parameters\n    on the object network will be applied, allowing for geometry variation at\n    render time."]}, {"indent": 4, "type": "para", "text": ["Mantra has three different levels of support for the engine procedural.\n    These modes are set using the ", {"text": ["-e"], "type": "code"}, " command line option (or the\n    ", {"text": ["MANTRA_ENGINE_PROCEDURAL"], "type": "code"}, " environment variable):"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["none"], "type": "code"}, ": In this mode, mantra can bypass setting up an environment to evaluate SOP networks.  This can improve start-up time for mantra.  In most cases, this is an insignificant amount of time."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["basic"], "type": "code"}, ": Allows generation of point and curve geometry."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["full"], "type": "code"}, ": Allows generation of any types of geometry.  This option will make mantra use an Engine license instead of a Render license."]}], "container": true, "type": "bullet_group"}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["The engine procedural will try to set a parameter named ", {"text": ["cooking_in_engine"], "type": "code"}, " to 1 when the HDA is being evaluated in mantra.  This allows the SOP network to cook differently for display in Houdini and rendering in Mantra."]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["Auto Engine Procedural"], "role": "item", "attrs": {"hprop": "vm_auto_engine_procedural"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the ", {"text": ["Auto Engine Procedural"], "type": "code"}, " is set, this property will tell mantra\n    whether to unload the SOP geometry after cooking.  Unloading SOP geometry\n    will free up memory in mantra, but may cause some SOP/Object networks to\n    perform additional computation."]}], "indent": 0, "text": ["Engine Procedural - Unload SOP Geometry"], "role": "item", "attrs": {"hprop": "vm_auto_engine_unload"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the ", {"text": ["Auto Engine Procedural"], "type": "code"}, " is set, this property will tell mantra\n    whether to compute the bounding box LOD and set a ", {"text": ["lod"], "type": "code"}, " parameter the HDA.\n    This allows the SOP network to generate different geometry based on the\n    level of detail in mantra."]}, {"indent": 4, "type": "para", "text": ["When the LOD is not required, mantra can share geometry between instances\n    that have the same render parameters (similar to ", {"text": ["Cache Stamping Geometry"], "type": "code"}, "\n    parameter on the Copy Stamp SOP).  If the LOD is required, mantra can not\n    perform any sharing of geometry."]}], "indent": 0, "text": ["Engine Procedural - HDA Uses LOD Parameter"], "role": "item", "attrs": {"hprop": "vm_auto_engine_requirelod"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the ", {"text": ["Auto Engine Procedural"], "type": "code"}, " is set, this property controls whether\n    the instanced geometry should be rotated based on the point attributes.\n    Each instance will always be translated to the instance point, but this\n    parameter controls whether attributes like ", {"text": ["pscale"], "type": "code"}, " and ", {"text": ["N"], "type": "code"}, " will be applied\n    to the instance transform."]}], "indent": 0, "text": ["Engine Procedural - Orient HDA instances to points"], "role": "item", "attrs": {"hprop": "vm_auto_engine_doorient"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the ", {"text": ["Auto Engine Procedural"], "type": "code"}, " is set, the SOP specified by this\n    property is used to determine the bounds of the generated hair at rendertime."]}, {"indent": 4, "type": "para", "text": ["If not specified or empty the SOP with the display flag is used."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Rendering with motion blur can invalidate the cache of the SOP being\n        cooked, causing all dependent nodes to recook when they are displayed\n        in Houdini after a render. To avoid this, create a separate SOP for\n        computing geometry to represent the bounding box of the display\n        geometry. Use this property to specify the final node of that chain."]}], "indent": 4, "role": "item", "type": "tip"}], "container": true, "role": "item_group", "type": "tip_group"}], "indent": 0, "text": ["Engine Procedural - Bounding Box SOP"], "role": "item", "attrs": {"hprop": "vm_auto_engine_boundsop"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls where the blur occurs in the image relative to the position of the object at the current frame. A value of ", {"text": ["-1"], "type": "code"}, " blurs from the position at the previous frame to the position in the current frame. A value of ", {"text": ["0"], "type": "code"}, " blurs from halfway to the previous frame to halfway to the next frame. A value of ", {"text": ["1"], "type": "code"}, " blurs from the current position to the position at the next frame. You can use fractional frame values and values greater than ", {"text": ["-1"], "type": "code"}, " or ", {"text": ["1"], "type": "code"}, " to move the blur less or more."]}, {"indent": 4, "type": "para", "text": ["To change the ", {"text": ["size"], "type": "em"}, " of the blur, change the ", {"text": ["Shutter time"], "type": "ui"}, " (", {"text": ["shutter"], "type": "code"}, " property)."]}, {"indent": 4, "type": "para", "text": ["This parameter replaces the old ", {"text": ["Motion blur style"], "type": "ui"}, " (", {"text": ["motionstyle"], "type": "code"}, ") parameter, which only allows values of \"before\" (shutter offset=-1), \"center\" (shutter offset=0), and \"after\" (shutter offset=1)."]}], "indent": 0, "text": ["Shutter offset"], "role": "item", "attrs": {"hprop": "shutteroffset"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of transformation blur motion samples. Each object (unless the parameter exists on the object) will have this many transforms output over the shutter duration. Increasing this number will result in smoother sub-frame motion, at a small memory and compute expense. Any number of segments may be specified, though the default of 2 is often adequate unless significant nonlinear motion occurs within the shutter time for a frame."]}], "indent": 0, "text": ["Xform time samples"], "role": "item", "attrs": {"ifdprop": "object:xformsamples", "hprop": "xform_motionsamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of deformation blur motion samples. Each object (unless the parameter exists on the object) will have this many copies of the geometry included in the IFD. When an object is deforming it is necessary to increase this parameter to a value of 2 to see motion blurred geometry.  Any number of segments may be specified, though a value of 2 is often adequate unless significant nonlinear motion occurs within the shutter time for a frame."]}, {"indent": 4, "type": "para", "text": ["This option has no effect on objects which use velocity blur, since velocity blur is linear by nature."]}, {"indent": 4, "type": "para", "text": ["Any number of segments may be specified; however, duplicate geometry is sent down for each sample which may significantly impact the memory footprint of mantra. "]}], "indent": 0, "text": ["Geo time samples"], "role": "item", "attrs": {"ifdprop": "object:geosamples", "hprop": "geo_motionsamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"text": ["understanding mantra rendering"], "fullpath": "/render/understanding", "scheme": null, "type": "link", "value": "/render/understanding"}, " for more information."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Each primitive is diced up into micropolygons which are shaded and sampled independently."]}], "indent": 4, "type": "dt", "text": ["Micropolygon Rendering"]}, {"body": [{"indent": 8, "type": "para", "text": ["The scene is sampled by sending rays from the camera.  Each surface hit by a ray will trigger a surface shader execution."]}], "indent": 4, "type": "dt", "text": ["Ray Tracing"]}, {"body": [{"indent": 8, "type": "para", "text": ["Sampling is performed on micropolygons; however, all shading and illumination is performed using physically based rendering. "]}, {"indent": 8, "type": "para", "text": ["The number of rays used to compute shading is determined by the maximum ray-samples."]}], "indent": 4, "type": "dt", "text": ["Micropolygon Physically Based Rendering"]}, {"body": [{"indent": 8, "type": "para", "text": ["Sampling of the scene is performed using ray-tracing and shading is computed using physically based rendering."]}, {"indent": 8, "type": "para", "text": ["In this case, the pixel samples determine the shading quality of the PBR engine."]}], "indent": 4, "type": "dt", "text": ["Physically Based Rendering"]}, {"body": [{"indent": 8, "type": "para", "text": ["Rather than rendering an image, a photon map will be generated by sending photons from light sources into the scene.  The photon map file to be generated is specified on the PBR tab."]}], "indent": 4, "type": "dt", "text": ["Photon Map Generation"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["Though this IFD token has an integer value, it\u2019s also possible to set the value through a string value."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["micropoly"], "type": "code"}, " \u2013 Micropolygon scanline rendering (default)."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["raytrace"], "type": "code"}, " \u2013 All rendering will be performed using ray-tracing."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["pbrmicropoly"], "type": "code"}, " \u2013 Physically Based Rendering using micro-polygon scanline rendering"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["pbrraytrace"], "type": "code"}, " \u2013 Physically Based Rendering using ray-tracing only."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["photon"], "type": "code"}, " \u2013 Photon map generation."]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Render engine"], "role": "item", "attrs": {"ifdprop": "renderer:renderengine", "hprop": "vm_renderengine"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enable or disable raytrace motion blur for micro-polygon rendering and photon map generation. By default, raytrace motion blur is disabled. This setting has no effect on the ray tracing rendering engines."]}], "indent": 0, "text": ["Raytrace motion blur"], "role": "item", "attrs": {"ifdprop": "object:traceblur", "hprop": "vm_traceblur"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Rendering"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The lens focal distance and distance from the camera at\n    which objects will be in focus. This is only used when rendering using depth of field. Objects outside this distance will be blurred."]}], "indent": 0, "text": ["Focus distance"], "role": "item", "attrs": {"ifdprop": "camera:focus", "hprop": "focus"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Lens fstop. This is only used when rendering using depth of field.\n    Determines blurriness of depth of field effects."]}], "indent": 0, "text": ["F-stop"], "role": "item", "attrs": {"ifdprop": "camera:fstop", "hprop": "fstop"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The portion of the frame interval that the camera shutter is\n    open. Used to determine motion blur. ", {"text": ["[0,1]"], "type": "code"}]}], "indent": 0, "text": ["Shutter time"], "role": "item", "attrs": {"hprop": "shutter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["See ", {"text": ["Shutter offset"], "type": "ui"}, " (", {"text": ["shutteroffset"], "type": "code"}, " property)."]}], "indent": 0, "text": ["Motion blur style"], "role": "item", "attrs": {"hprop": "motionstyle"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["The ramp is always evaluated across the entire range, regardless of the shutter time setting."]}], "indent": 4, "type": "dt", "text": ["Controls the opening of the shutter along shutter time through a grayscale \n    ramp. The higher the ramp value at a given time point, the more time \n    sample will be focused in that area. \n    NOTE"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Shutter shape"], "role": "item", "attrs": {"ifdprop": "camera:shuttershape", "hprop": "vm_shuttershape"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If enabled, this object\u2019s rendered motion blur will be based upon\n    the vector attribute named ", {"text": ["v"], "type": "code"}, " in the geometry. The units of the\n    attribute are in (1 unit/second)."]}, {"indent": 4, "type": "para", "text": ["Velocity motion blur should be used if it contains changing point\n    counts since it cannot be rendered correctly with deformation\n    motion blur. For example, a particle system with changing particle\n    counts should use this option."]}, {"indent": 4, "type": "para", "text": ["You can use Velocity blur on these types of objects as long as they\n    have valid ", {"text": ["v"], "type": "code"}, " attributes. Particles automatically have the \"v\"\n    attribute so if you are rendering particles, simply enable this\n    parameter."]}], "indent": 0, "text": ["Geometry velocity blur"], "role": "item", "attrs": {"ifdprop": "object:velocityblur", "hprop": "geo_velocityblur"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls anamorphic depth of field by changing the aspect ratio for the ellipse of confusion.  Values between 0 and 1 will increase the amount of blur in the Y direction.  Values larger than 1 will decrease the amount of blur in Y."]}], "indent": 0, "text": ["Depth of field aspect ratio"], "role": "item", "attrs": {"ifdprop": "renderer:dofaspect", "hprop": "vm_dofaspect"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["Controls the number of primary rays Mantra will use to sample your scene per pixel. The two numbers represent an arrangement of samples in the X and Y axis and are generally the same number. However, for non-square pixels it may be necessary to use different values in X and Y. Multiplying these two values together will give you the number of primary rays per pixel."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/sampling_tab/PixelSampling.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling_tab/PixelSampling.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["Increasing Pixel Samples will result in a cleaner, higher quality image. However, since all other sampling values are multiplied by the number of Pixel Samples, they should only be increased when necessary. For more details on when to increase Pixel Samples, see the \u201cRemoving Noise\u201d section."]}], "indent": 0, "text": ["Pixel samples"], "role": "item", "attrs": {"ifdprop": "image:samples", "hprop": "vm_samples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, this parameter will cause Mantra to use ray variance antialiasing when determining the number of Secondary Rays to send for every Primary Ray."]}, {"indent": 4, "type": "para", "text": ["This means that rather than using a specific number of rays, Mantra will first send out a small number of rays and use this sample set to evaluate the Variance. Depending on the amount of various, Mantra will continue to send more rays up to the ", {"text": ["Max Ray Samples"], "type": "ui"}, " value. Ray Variance Antialiasing is useful for optimizing your render by sending more rays only in the areas they are needed."]}, {"indent": 4, "type": "para", "text": ["In cases where the minimum number of rays to remove noise is equal to the maximum number of rays, you may save a small amount of render time by disabling Ray Variance Antialiasing."]}], "indent": 0, "text": ["Ray variance anti-aliasing"], "role": "item", "attrs": {"ifdprop": "object:dorayvariance", "hprop": "vm_dorayvariance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["Ray Variance anti-aliasing"], "type": "ui"}, " is enabled, this parameter represents the maximum number of secondary rays allowed for each BSDF type even if the ", {"text": ["Noise Level"], "type": "ui"}, " is never reached. This parameter, along with ", {"text": ["Min Ray Samples"], "type": "ui"}, ", essentially allows you to create a range of acceptable sampling for your image. Carefully controlling the total number of potential rays is the best way to optimize your renders."]}, {"indent": 4, "type": "para", "text": ["Remember, this number is multiplied by the current number of Pixel Samples ", {"text": ["and"], "type": "em"}, " the number of BSDF types on the material being evaluated. For example, if it\u2019s a purely diffuse material, and Pixel Samples are set to 3\u00d73, and the ", {"text": ["Max Ray Samples"], "type": "ui"}, " is set to 1, then it will cast up to 9 secondary rays (9 diffuse rays). If the material is both reflective ", {"text": ["and"], "type": "em"}, " refractive, then it will cast up to 18 secondary rays (9 reflection and 9 refraction rays)."]}, {"indent": 4, "type": "para", "text": ["For more details on when to increase ", {"text": ["Max Ray Samples"], "type": "ui"}, ", see ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, "."]}], "indent": 0, "text": ["Max Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:maxraysamples", "hprop": "vm_maxraysamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This value is the ", {"text": ["minimum number of secondary rays"], "type": "strong"}, " to use for each BSDF type when generating an image. When ", {"text": ["Ray Variance anti-aliasing"], "type": "ui"}, " is disabled, this number represents the number of secondary rays to send regardless of the ", {"text": ["Noise Level"], "type": "ui"}, "."]}, {"indent": 4, "type": "para", "text": ["Remember, this number is multiplied by the current number of Pixel Samples ", {"text": ["and"], "type": "em"}, " the number of BSDF types on the material being evaluated."]}], "indent": 0, "text": ["Min Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:minraysamples", "hprop": "vm_minraysamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Represents a threshold in the ", {"text": ["amount of variance allowed before mantra will send more secondary rays"], "type": "strong"}, ". Variance essentially represents how \u201cspread out\u201d the values in a set of samples are. For instance, a set of samples that were all the same would have a variance of 0. It is generally a good idea to keep this value as high as possible so that rays are sent only into those areas where an unacceptable amount of noise is present."]}, {"indent": 4, "type": "para", "text": ["Adding \u201cdirect samples\u201d and \u201cindirect samples\u201d image planes can help you track how many samples are being sent and to which parts of the image. For more information about sampling, see the \u201cSampling and Noise\u201d section."]}, {"indent": 4, "type": "para", "text": ["If you find that certain objects in your scene require substantially more samples than other parts of your image and you are unable to \u201ctarget\u201d those objects using the Noise Level parameter, it may be a better idea to add per-object sampling parameters to the problem areas. See ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, " for more details."]}], "indent": 0, "text": ["Noise Level"], "role": "item", "attrs": {"ifdprop": "object:variance", "hprop": "vm_variance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Acts as a global multiplier on all per-component quality parameters. This allows you to increase/decrease quality, keeping the relative per-component qualities the same."]}], "indent": 0, "text": ["Global Quality"], "role": "item", "attrs": {"ifdprop": "object:globalquality", "hprop": "vm_globalquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the quality of ", {"text": ["indirect diffuse"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Often, indirect sources of light (such as the surfaces of other objects, and light scattered inside of a volume) will be a significant cause of noise in your renders. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"indent": 4, "type": "para", "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Diffuse Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary diffuse ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"indent": 4, "type": "para", "text": ["To find how much noise is in your indirect diffuse component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Diffuse component."]}], "indent": 0, "text": ["Diffuse Quality"], "role": "item", "attrs": {"ifdprop": "object:diffusequality", "hprop": "vm_diffusequality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the quality of ", {"text": ["indirect sss"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Often, indirect sources of light (such as the surfaces of other objects, and light scattered inside of a volume) will be a significant cause of noise in your renders. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"indent": 4, "type": "para", "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["SSS Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary SSS ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"indent": 4, "type": "para", "text": ["To find how much noise is in your indirect SSS component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually."]}], "indent": 0, "text": ["SSS Quality"], "role": "item", "attrs": {"ifdprop": "object:sssquality", "hprop": "vm_sssquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the quality of ", {"text": ["indirect refraction"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Indirect refractions (refracted light from of other objects in the scene, such as when viewing an object through glass) can sometimes add noise to the render. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"indent": 4, "type": "para", "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Refract Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary refraction ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"indent": 4, "type": "para", "text": ["To find how much noise is in your indirect refraction component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Refraction component."]}], "indent": 0, "text": ["Refraction Quality"], "role": "item", "attrs": {"ifdprop": "object:refractionquality", "hprop": "vm_refractionquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the quality of ", {"text": ["indirect reflection"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Indirect reflections (reflections of other objects in the scene) can sometimes add noise to the render. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"indent": 4, "type": "para", "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Reflect Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary reflection ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"indent": 4, "type": "para", "text": ["To find how much noise is in your indirect reflection component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Reflection component."]}], "indent": 0, "text": ["Reflection Quality"], "role": "item", "attrs": {"ifdprop": "object:reflectionquality", "hprop": "vm_reflectionquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the quality of ", {"text": ["indirect volume"], "type": "em"}, " sampling (for information on the difference between direct and indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "). Often, indirect sources of light (such as the surfaces of other objects, and light scattered inside of a volume) will be a significant cause of noise in your renders. Turning this up should decrease this type of noise, at the cost of slowing down rendering."]}, {"indent": 4, "type": "para", "text": ["This parameter acts as a multiplier on ", {"text": ["Min Ray Samples"], "type": "ui"}, " and ", {"text": ["Max Ray Samples"], "type": "ui"}, " and also as a divisor for ", {"text": ["Noise Level"], "type": "ui"}, ". For example, if you have ", {"text": ["Min Ray Samples"], "type": "ui"}, " set to ", {"text": ["1"], "type": "code"}, ", ", {"text": ["May Ray Samples"], "type": "ui"}, " set to ", {"text": ["8"], "type": "code"}, " and your Noise Level to ", {"text": ["0.1"], "type": "code"}, ", then set ", {"text": ["Volume Quality"], "type": "ui"}, " to ", {"text": ["2"], "type": "code"}, ", Mantra will send between 2 and 16 secondary volume ray samples based on a Noise Level of 0.05. Remember these numbers apply only to the ", {"text": ["indirect samples"], "type": "em"}, ". Mantra uses the original values for all direct sampling."]}, {"indent": 4, "type": "para", "text": ["To find how much noise is in your indirect volume component, add the \"Indirect Lighting (per-component)\" image plane in the ", {"text": ["Extra Image Planes"], "type": "ui"}, " tab. This lets you check each indirect component individually. For this parameter, you should check the Indirect Volume component."]}], "indent": 0, "text": ["Volume Quality"], "role": "item", "attrs": {"ifdprop": "object:volumequality", "hprop": "vm_volumequality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sampling color space for variance antialiasing.  Setting this to Gamma 2.2 will cause darker parts of the image to receive more samples."]}], "indent": 0, "text": ["Variance color space"], "role": "item", "attrs": {"ifdprop": "renderer:colorspace", "hprop": "vm_colorspace"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Decouples the Direct from Indirect Rays, allowing for different sampling rates as well as separate noise levels. Generally speaking, it will only be necessary to enable this parameter if you find that too many samples are being sent as Direct Rays."]}, {"indent": 4, "type": "para", "text": ["Adding \u201cdirect samples\u201d and \u201cindirect samples\u201d image planes can help you track how many samples are being sent and to which parts of the image. For more information about sampling, see the \u201cSampling and Noise\u201d section."]}, {"indent": 4, "type": "para", "text": ["This parameter will enable three new parameters: ", {"text": ["Min Indirect Ray Samples"], "type": "ui"}, ", ", {"text": ["Max Indirect Ray Samples"], "type": "ui"}, ", and ", {"text": ["Indirect Noise Level"], "type": "ui"}, "."]}, {"indent": 4, "type": "para", "text": ["To understand the difference between Direct and Indirect rays, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "."]}], "indent": 0, "text": ["Enable Indirect Sample Limits"], "role": "item", "attrs": {"ifdprop": "object:decoupleindirect", "hprop": "vm_decoupleindirect"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The ", {"text": ["minimum number of indirect rays"], "type": "strong"}, " to use when generating an image. Generally speaking indirect rays are used when sampling other objects and their material properties. For more information about indirect rays see \u201cSampling and Noise\u201d."]}, {"indent": 4, "type": "para", "text": ["Remember, like the previous Ray Sample limits, this value is multiplied by the current number of Pixel Samples."]}], "indent": 0, "text": ["Min Indirect Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:minindirectraysamples", "hprop": "vm_minindirectraysamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The ", {"text": ["maximum number of indirect rays"], "type": "strong"}, " to use when generating an image, ", {"text": ["even if the Indirect Noise level is never reached"], "type": "em"}, ". This parameter, along with ", {"text": ["Min Indirect Ray Samples"], "type": "ui"}, ", essentially allows you to create a range of acceptable sampling for your image. Carefully controlling the total number of potential rays is the best way to optimize your renders."]}, {"indent": 4, "type": "para", "text": ["Remember, this number is multiplied by the current number of Pixel Samples."]}, {"indent": 4, "type": "para", "text": ["For more details on when to increase ", {"text": ["Max Indirect Ray Samples"], "type": "ui"}, ", see ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, "."]}], "indent": 0, "text": ["Max Indirect Ray Samples"], "role": "item", "attrs": {"ifdprop": "object:maxindirectraysamples", "hprop": "vm_maxindirectraysamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A threshold in the ", {"text": ["amount of variance allowed before mantra will send more indirect rays"], "type": "strong"}, ". Variance essentially represents how \u201cspread out\u201d the values in a set of samples are, a set of samples that were all the same would have a variance of 0. It is generally a good idea to keep this value as high as possible so that rays are sent only into those areas where an unacceptable amount of noise is present."]}, {"indent": 4, "type": "para", "text": ["Adding \u201cdirect samples\u201d and \u201cindirect samples\u201d image planes can help you track how many samples are being sent and to which parts of the image. For more information about sampling, see the \u201cSampling and Noise\u201d section."]}, {"indent": 4, "type": "para", "text": ["If you find that certain objects in your scene require substantially more samples than other parts of your image and you are unable to \u201ctarget\u201d those objects using the Noise Level parameter, it may be a better idea to add per-object sampling parameters to the problem areas. See ", {"text": ["removing noise"], "fullpath": "/render/noise", "scheme": null, "type": "link", "value": "/render/noise"}, " for more details."]}], "indent": 0, "text": ["Indirect Noise Level"], "role": "item", "attrs": {"ifdprop": "object:indirectvariance", "hprop": "vm_indirectvariance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The relative number of illumination samples to be used for the light source.  Sampling Quality is relative to the ray sampling parameters (", {"text": ["vm_minraysamples"], "type": "code"}, " and ", {"text": ["vm_maxraysamples"], "type": "code"}, ")."]}], "indent": 0, "text": ["Sampling quality"], "role": "item", "attrs": {"ifdprop": "light:samplingquality", "hprop": "vm_samplingquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A floating point value which adds noise to pixel sampling patterns. A value of 1 will fully randomize pixel sampling patterns, while a value of 0 turns of pixel jitter resulting in stairstep artifacts when too few pixel samples are used. Jitter only applies to pixel antialiasing and does not apply to motion blur or depth of field sampling (which are always randomized)."]}], "indent": 0, "text": ["Jitter"], "role": "item", "attrs": {"ifdprop": "image:jitter", "hprop": "vm_jitter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Adjusting this parameter will cause the pixel sampling patterns used by Mantra to be regenerated in different configurations. By default, the patterns change on every frame, so manually changing this value is not necessary."]}], "indent": 0, "text": ["Random seed"], "role": "item", "attrs": {"ifdprop": "renderer:randomseed", "hprop": "vm_randomseed"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sampling generally occurs in random patterns which change on every frame of an animation. This can cause a distracting \u201cbuzz\u201d when there is a significant amount of noise in your images which can make evaluation of other aspects of the scene difficult. Enabling this parameter will \u201clock\u201d the sampling patterns so that the noise remains the same on every frame."]}, {"indent": 4, "type": "para", "text": ["Also, in some cases where the final rendered images will be sent through a post-render de- noise process, it can be useful to have the noise remain constant frame to frame. Consistent sampling patterns can help when analyzing the noise."]}, {"indent": 4, "type": "para", "text": ["It defaults to \u201coff\u201d because it is generally unacceptable to have a locked sampling pattern for final sequences."]}], "indent": 0, "text": ["Sample lock"], "role": "item", "attrs": {"ifdprop": "image:samplelock", "hprop": "vm_samplelock"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["For scenes using both motion blur and depth of field, mantra\u2019s default\n    image sampling patterns correlate the time and depth of field samples.\n    This has the effect of reducing noise, but can lead to correlation\n    artifacts (banding) in the render in parts of the image where there is\n    both significant motion blur and depth of field.  Decorrelating depth\n    of field from motion blur by enabling this setting will eliminate these\n    banding artifacts while increasing the noise in the render."]}, {"indent": 4, "type": "para", "text": ["For micropolygon rendering, there is a performance penalty when\n    enabling this property, since mantra optimizes micropolygon rendering\n    for correlated depth of field sampling patterns.  There is no\n    performance penalty for ray tracing."]}], "indent": 0, "text": ["Decorrelate Depth of Field from Motion Blur Samples"], "role": "item", "attrs": {"ifdprop": "image:decorrelatedof", "hprop": "vm_decorrelatedof"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Filter kernel used in depth of field rendering. Use the pop-up menu to the right of the text box to choose from the available options."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Use a gaussian filter kernel (highest quality)."]}], "indent": 4, "type": "dt", "text": ["Radial bokeh (", {"text": ["radial"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Use an image file "]}], "indent": 4, "type": "dt", "text": ["Image file bokeh (", {"text": ["file"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Use a box filter kernal."]}], "indent": 4, "type": "dt", "text": ["Box filter bokeh (", {"text": ["box"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Do not filter."]}], "indent": 4, "type": "dt", "text": ["Disable bokeh (", {"text": ["null"], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Bokeh"], "role": "item", "attrs": {"ifdprop": "camera:bokeh", "hprop": "vm_bokeh"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The file to use for \"file\" shaped bokeh.  White/black cutout images that delineate the shape of the lens are good candidates, where white regions represent the areas that light passes through."]}], "indent": 0, "text": ["Bokeh image file"], "role": "item", "attrs": {"ifdprop": "camera:bokeh", "hprop": "vm_bokehfile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The rotation for \"file\" shaped bokeh."]}], "indent": 0, "text": ["Bokeh rotation"], "role": "item", "attrs": {"ifdprop": "camera:bokeh", "hprop": "vm_bokehrotation"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A scale on the native step size that determines how finely mantra will\n    subdivide the velocity blur ray tracing cage. For voxel volume\n    primitives, the default of 0.1 means to take one velocity sample every\n    10 voxels.  Smaller values will speed up renders but may introduce\n    inaccuracy in the resulting motion blur."]}], "indent": 0, "text": ["Volume velocity quality"], "role": "item", "attrs": {"ifdprop": "object:velocityquality", "hprop": "vm_velocityquality"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["How finely or coarsely a volume is sampled as a ray travels through it. Volumetric objects are made up of 3d structures called Voxels, the value of this parameter represents the number of voxels a ray will travel through before performing another sample."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/sampling_tab/VolumeQuality.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling_tab/VolumeQuality.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["The default value is ", {"text": ["0.25"], "type": "code"}, ", which means that every one of every four voxels will be sampled. A value of ", {"text": ["1"], "type": "code"}, " would mean that all voxels are sampled and a value of 2 would mean that all voxels are sampled twice. This means that the volume step rate value behaves in a similar way to pixel samples, acting as a multiplier on the total number of samples for volumetric objects."]}, {"indent": 4, "type": "para", "text": ["For volumes that aren\u2019t voxel based, like CVEX procedural volumes, Mantra will divide the bounding box of the volume into roughly 100 \u201cvirtual\u201d voxels. In these cases, setting the Volume Step Rate correctly is essential to maintaining the correct level of detail."]}, {"indent": 4, "type": "para", "text": ["Keep in mind that increasing the volume step rate can dramatically increase render times, so it should only be adjusted when necessary. Also, while increasing the default from ", {"text": ["0.25"], "type": "code"}, " can reduce volumetric noise, increasing the value beyond ", {"text": ["1"], "type": "code"}, " will rarely see similar results."]}, {"indent": 4, "type": "para", "text": ["For more information about volume sampling, see ", {"text": ["sampling and noise"], "fullpath": "/render/sampling", "scheme": null, "type": "link", "value": "/render/sampling"}, "."]}], "indent": 0, "text": ["Volume step rate"], "role": "item", "attrs": {"ifdprop": "object:volumesteprate", "hprop": "vm_volumesteprate"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to render this object as if it was a uniform-density volume. Using this property on surface geometry is more efficient than actually creating a volume object of uniform density, since the renderer can assume that the volume density is uniform and place samples more optimally. The surface normal of the surface is used to determine which side of the surface will render as a volume - the normal will point away from the interior. The surface need not be closed - if the surface is not closed, the volume will extend an infinite distance away from the surface. Non-closed surfaces may produce unexpected results near the edge of the surface, so try to keep the viewing camera away from the edges. This parameter is compatible with ray tracing and PBR but not micropolygon renders."]}], "indent": 0, "text": ["Uniform volume"], "role": "item", "attrs": {"ifdprop": "object:volumeuniform", "hprop": "vm_volumeuniform"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Determines the type of uniform volume. ", {"text": ["Continuous"], "type": "code"}, " samples along a series of points within the intersected volume object. ", {"text": ["Segment"], "type": "code"}, " samples once per-segment within the intersected volume object."]}], "indent": 0, "text": ["Uniform volume type"], "role": "item", "attrs": {"ifdprop": "object:volumeuniformtype", "hprop": "vm_volumeuniformtype"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When there are flipped normals due to reversed geometry or self intersections, mantra may misjudge volume spans and cause artifacts in render. Mantra will try to correct for such a case, provided that the distances between the intersections fall within this threshold."]}], "indent": 0, "text": ["Uniform volume flipped normal detection threshold"], "role": "item", "attrs": {"ifdprop": "object:volumeuniformflipthresh", "hprop": "vm_volumeuniformflipthresh"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When rendering a uniform volume (", {"text": ["vm_uniformvolume"], "type": "code"}, " is enabled), this setting controls whether the surface is also rendered.  If you enable this setting, the surface shader should handle both volume and surface samples by checking the value of the dPdz global - when it is 0 the shader should render a surface, otherwise a volume."]}], "indent": 0, "text": ["Volume surface"], "role": "item", "attrs": {"ifdprop": "object:volumesurface", "hprop": "vm_volumesurface"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Rather than generating samples inside a volume, this setting will configure the renderer so that it automatically finds an isosurface of the volume density field and renders this as a surface.  The ", {"text": ["vm_volumedensity"], "type": "code"}, " parameter is used as a threshold to control the isosurface density threshold. You should use an ordinary surface shader when rendering volumes with this setting enabled - not a volume rendering surface shader."]}, {"indent": 4, "type": "para", "text": ["By default, the isosurface is found by ray marching through the volume to find points where the threshold density is crossed. This means that to improve render accuracy, you can increase the ", {"text": ["vm_volumesteprate"], "type": "code"}, " parameter. Some volume types use a native accelerated isosurface search technique in which case the volume step rate is ignored and the isosurface is determined analytically for that particular type of volume. VDB volumes, for example, use this analytic isosurface rendering approach. The ", {"text": ["vm_volumeisodefault"], "type": "code"}, " parameter can be used to disable this native intersection algorithm."]}], "indent": 0, "text": ["Volume isosurface"], "role": "item", "attrs": {"ifdprop": "object:volumeiso", "hprop": "vm_volumeiso"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Disable native volume isosurface for this object when ", {"text": ["vm_volumeiso"], "type": "code"}, " is enabled. This parameter will only affect volume types that have a native isosurface algorithm - including VDB volumes."]}], "indent": 0, "text": ["Use default volume isosurface evaluator"], "role": "item", "attrs": {"ifdprop": "object:volumeisodefault", "hprop": "vm_volumeisodefault"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When ", {"text": ["vm_volumeuniform"], "type": "code"}, " is on, the uniform density of the object\u2019s volume. This value must be the same on the object as on the Volume Cloud shader.  When ", {"text": ["vm_volumeiso"], "type": "code"}, " is on, this value specifies the threshold density value for isosurface rendering."]}], "indent": 0, "text": ["Volume density"], "role": "item", "attrs": {"ifdprop": "object:volumedensity", "hprop": "vm_volumedensity"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of samples to generate when rendering a uniform volume (", {"text": ["vm_uniformvolume"], "type": "code"}, " is enabled).  The samples will be distributed so as to produce an equal image contribution if they were all equal in brightness."]}], "indent": 0, "text": ["Volume samples"], "role": "item", "attrs": {"ifdprop": "object:volumesamples", "hprop": "vm_volumesamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A factor to proportionally decrease the volume step rate only for shadows, relative to the volume step rate. Smaller values will cause mantra to use a larger ray march step size for shadow rays than other shading rays.  A value of 1 will produce equal quality for shadow rays and shading rays."]}], "indent": 0, "text": ["Volume shadow step rate"], "role": "item", "attrs": {"ifdprop": "object:volumeshadowsteprate", "hprop": "vm_volumeshadowsteprate"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the minimum density value that will be rendered.  Using a larger zero threshold can improve rendering performance by reducing the amount of shading and sampling that occurs in nearly empty parts of the volume.  Using too large a zero threshold can introduce clipping artifacts in the render."]}], "indent": 0, "text": ["Volume zero threshold"], "role": "item", "attrs": {"ifdprop": "object:volumezerothresh", "hprop": "vm_volumezerothresh"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the volume channel by name that will be used for empty space culling.  By default mantra will use the 'density' channel if it exists.  If you are rendering an emissive volume in which some parts of the volume have a 0 density but still need to be rendered, you should specify a different channel using this parameter.  If the specified channel is not found, mantra will assume that the entire volume needs to be rendered and no culling will occur.  The sampling channel should be structured such that values less than the ", {"text": ["vm_volumezerothresh"], "type": "code"}, " indicate empty space."]}], "indent": 0, "text": ["Volume sampling channel"], "role": "item", "attrs": {"ifdprop": "object:volumesamplingchannel", "hprop": "vm_volumesamplingchannel"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used for uniform volumes when doing inside/outside tests."]}], "indent": 0, "text": ["Volume Up Vector"], "role": "item", "attrs": {"ifdprop": "object:volumeupvector", "hprop": "vm_volumeupvector"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["The number of transparent samples to be shaded as a ray travels through translucent objects. Increasing this value will result in less noise in translucent objects and is generally less costly than increasing Pixel samples, Volume Step Rate, or Min and Max ray samples. Stochastic Sampling will not have any effect on noise from Indirect Sources however."]}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/images/render/mug/sampling/VolumeSamplingStochastic.jpg", "scheme": "Image", "type": "link", "value": "/images/render/mug/sampling/VolumeSamplingStochastic.jpg"}]}], "container": true, "role": "item_group", "type": "fig_group"}, {"indent": 4, "type": "para", "text": ["This may make the image noisier than without stochastic transparency, so you may need to compensate by, for example, increasing the pixel samples. You should generally leave this option on."]}, {"indent": 4, "type": "para", "text": ["The renderer ignores this option for micropolygon rendering (except for secondary ray tracing) and for renders that only generate opacity (such as deep shadow maps). In those cases it is more efficient to composite all the transparent shading results."]}, {"indent": 4, "type": "para", "text": ["Added in Houdini 12."]}], "indent": 0, "text": ["Stochastic transparency"], "role": "item", "attrs": {"ifdprop": "image:transparent", "hprop": "vm_transparent"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of transparent samples to shade when ", {"fragment": "#vm_transparent", "text": ["Stochastic Transparency"], "value": "#vm_transparent", "fullpath": "/props/mantra#vm_transparent", "scheme": null, "type": "link"}, " is on. Higher values improve shading quality for volumes and transparent surfaces, but are slower to render."]}], "indent": 0, "text": ["Stochastic samples"], "role": "item", "attrs": {"ifdprop": "image:transparentsamples", "hprop": "vm_transparentsamples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter is related to the motion blur parameters which are available only when Motion Blur is enabled. Disabling this option will cause motion blur to be removed from the final rendered image, however the blurred Position will still be calculated, allowing for custom motion vector image planes to be created. For more information, see ", {"text": ["motion blur"], "fullpath": "/render/blur", "scheme": null, "type": "link", "value": "/render/blur"}, "."]}], "indent": 0, "text": ["Allow image motion blur"], "role": "item", "attrs": {"ifdprop": "renderer:imageblur", "hprop": "vm_imageblur"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Sampling"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [], "indent": 0, "text": ["Rendering properties"], "role": "item", "attrs": {"hprop": "shop_propertiespath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Material"], "role": "item", "attrs": {"hprop": "shop_materialpath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Surface shader"], "role": "item", "attrs": {"ifdprop": "object:surface", "hprop": "shop_surfacepath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable surface shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_surface_shader"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Photon shader"], "role": "item", "attrs": {"hprop": "shop_photonpath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Displacement shader"], "role": "item", "attrs": {"ifdprop": "object:displace", "hprop": "shop_displacepath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable displace shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_displace_shader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the object has matte shading enabled, this shader is used for primary ray shading instead of the surface shader."]}], "indent": 0, "text": ["Matte shader"], "role": "item", "attrs": {"ifdprop": "object:matteshader", "hprop": "vm_matteshader"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Light shader"], "role": "item", "attrs": {"hprop": "shop_lightpath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable light shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_light_shader"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Shadow shader"], "role": "item", "attrs": {"ifdprop": "object:shadow", "hprop": "shop_shadowpath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable shadow shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_shadow_shader"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Fog shader"], "role": "item", "attrs": {"hprop": "shop_fogpath"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable fog shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_fog_shader"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Disable geometry shader rendering"], "role": "item", "attrs": {"hprop": "shop_disable_geometry_shader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["On object nodes, this parameter defines a material style sheet to be applied\n    to this object' geometry. A material style sheet determines the geometry\n    look by assigning various shaders and materials to different pieces\n    of the geometry (primitives) and by overriding shader parameters\n    for rendering just these pieces."]}, {"indent": 4, "type": "para", "text": ["The style sheet definition in this parameter is specified using a JSON \n    format, but can be edited in Data Tree pane with Material Style Sheets view."]}], "indent": 0, "text": ["Material style sheet"], "role": "item", "attrs": {"ifdprop": "object:materialstylesheet", "hprop": "shop_materialstylesheet"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Shaders"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of component types that will behave like diffuse bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Diffuse Components"], "role": "item", "attrs": {"ifdprop": "renderer:diffusecomponents", "hprop": "vm_diffusecomponents"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of component types that will behave like refract bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Refract Components"], "role": "item", "attrs": {"ifdprop": "renderer:refractcomponents", "hprop": "vm_refractcomponents"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of component types that will behave like volume bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["Volume Components"], "role": "item", "attrs": {"ifdprop": "renderer:volumecomponents", "hprop": "vm_volumecomponents"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of component types that will behave like subsurface scatter bounces.  This will affect which reflection scope is used based on the ray type and also which bounce limit to use.  Uncategorized component types are assumed to be reflections."]}], "indent": 0, "text": ["SSS Components"], "role": "item", "attrs": {"ifdprop": "renderer:ssscomponents", "hprop": "vm_ssscomponents"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["To save on computation, mantra will only compute exports on surface shaders if the variable needs to be saved to an image plane.  This means that some surface exports may not be available in fog shaders for the ", {"text": ["simport()"], "type": "code"}, " function.  This parameter specifies a list of variables which need to be computed for fog shaders."]}], "indent": 0, "text": ["Variables imported by fog shaders"], "role": "item", "attrs": {"ifdprop": "renderer:fogimports", "hprop": "vm_fogimports"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["To save on computation, mantra will only compute exports on surface shaders if the variable needs to be saved to an image plane.  This means that some surface exports may not be available in fog shaders for the ", {"text": ["simport()"], "type": "code"}, " function.  However, to properly render advanced features like absorption and nested dielectrics, additional exports from surface shaders are required.  This enables on these special exports."]}], "indent": 0, "text": ["Enable Absorption and Nested Dielectrics"], "role": "item", "attrs": {"ifdprop": "renderer:nesteddielectric", "hprop": "vm_nesteddielectric"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The type of path tracing to perform in PBR mode."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["diffuse"], "type": "code"}, " \u2013 Trace all diffuse and specular bounces, but once a diffuse bounce is encountered continue tracing only diffuse reflections."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["all"], "type": "code"}, " \u2013 All paths are traced.  This option can be used to enable rendering of caustics without the use of photon maps - however when using point or small area lights, the rendered result can turn out to be extremely noisy."]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Allowable paths"], "role": "item", "attrs": {"ifdprop": "renderer:pbrpathtype", "hprop": "vm_pbrpathtype"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Roughness parameter in GGX BSDFs are clamped by the maximum roughness value propagated down the ray chain in pathtracing. Enabling this option can cut out a lot of noise in indirect specular (in particular, cases where glossy surface is reflected by a rough specular surface) at the cost of a bit of accuracy."]}], "indent": 0, "text": ["Constrain by Maximum Roughness"], "role": "item", "attrs": {"ifdprop": "renderer:constrainmaxrough", "hprop": "vm_constrainmaxrough"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The shader used to evaluate samples for the experimental generator rendering engine."]}], "indent": 0, "text": ["Generator Shader"], "role": "item", "attrs": {"ifdprop": "renderer:generatorshader", "hprop": "vm_generatorshader"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["The absolute value is used to determine the bounds."]}], "indent": 4, "type": "dt", "text": ["The maximum bounds that the displacement shader will move geometry. This is defined in \"camera\" space. \n    NOTE"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Displacement bound"], "role": "item", "attrs": {"ifdprop": "object:displacebound", "hprop": "vm_displacebound"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The space in which you specify displacement bounds."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["\"object\""], "type": "code"}, " \u2013 Displacements occur in object space."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["\"camera\""], "type": "code"}, " \u2013 Displacements occur in camera space."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["\"world\""], "type": "code"}, " \u2013 Default, currently an alias for camera."]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Displacement space"], "role": "item", "attrs": {"ifdprop": "object:displacespace", "hprop": "vm_displacespace"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The maximum bounds for volume velocity motion blur.  It is only necessary to configure this parameter when using velocity motion blur with custom volume procedurals, since mantra already computes an accurate bound for built-in volume types."]}], "indent": 0, "text": ["Velocity bound"], "role": "item", "attrs": {"ifdprop": "object:velocitybound", "hprop": "vm_velocitybound"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["With extreme displacement, it\u2019s possible to get micro-polygons which are stretched far out of shape. Turning re-dicing on will cause the geometry to be re-measured after a trial displacement, to get a much better estimate of the actual size of the displaced geometry. This will result in micro-polygons which have a much more uniform size and will most likely provide higher quality images. This is more costly since the displacement shader may be run twice during the dicing process."]}, {"indent": 4, "type": "para", "text": ["This property has no effect for volume displacements."]}], "indent": 0, "text": ["Re-dice displacements"], "role": "item", "attrs": {"ifdprop": "object:redice", "hprop": "vm_redice"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, the object\u2019s surface shader will be replaced with a matte\n    shader for primary rays. The default matte shader causes the object to\n    render as fully opaque but with an alpha of 0 - effectively cutting a\n    hole in the image where the object would have appeared. This setting is\n    useful when manually splitting an image into passes, so that the\n    background elements can be rendered separately from a foreground\n    object.  The default matte shader is the \"Matte\" VEX shader, though it\n    is possible to set a different matte shader by adding the\n    ", {"text": ["vm_matteshader"], "type": "code"}, " render property and assigning another shader.\n    Secondary rays will still use the object\u2019s assigned surface shader,\n    allowing it to appear in reflections and indirect lighting even though\n    it will not render directly."]}, {"indent": 4, "type": "para", "text": ["For correct matte shading of volumes:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "ord", "text": ["Add the ", {"text": ["vm_matteshader"], "type": "code"}, " property to the object."]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Create a ", {"text": ["Volume Matte"], "type": "ui"}, " shader."]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Set the density on this shader to match the density on the geometry shader."]}, {"indent": 4, "blevel": 6, "type": "ord", "text": ["Assign this shader to ", {"text": ["vm_matteshader"], "type": "code"}, "."]}], "container": true, "type": "ord_group"}, {"indent": 4, "type": "para", "text": ["Then when the ", {"text": ["Matte Shading"], "type": "ui"}, " toggle is enabled, it will use your custom volume matte shader rather than the default (which just sets the density to 1). If you want fully opaque matte, you can use the matte shader rather than volume matte. "]}], "indent": 0, "text": ["Matte shading"], "role": "item", "attrs": {"ifdprop": "object:matte", "hprop": "vm_matte"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When running displacement shaders, whether the VEX variable P is actually moved (true displacement) or whether bump mapping will be performed."]}], "indent": 0, "text": ["True displace"], "role": "item", "attrs": {"ifdprop": "object:truedisplace", "hprop": "vm_truedisplace"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When true displacements is enabled, use the displacement as a bump map in addition to displacing the geometry.  Enabling this option can increase apparent detail without incurring the cost of an increase in shading quality.  Essentially, mantra is using true displacements up to the shading quality, and then adding the remaining detail by modifying the shading normal ", {"text": ["N"], "type": "code"}, "."]}], "indent": 0, "text": ["Add Bump To Ray Traced Displacements"], "role": "item", "attrs": {"ifdprop": "object:bumpraydisplace", "hprop": "vm_bumpraydisplace"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Some volume primitives (Geometry Volumes, Image3D) can use a filter during evaluation of volume channels. This specifies the filter.  The default box filter is fast to evaluate and produces sharp renders for most smooth fluid simulations.  If your voxel data contains aliasing (stairstepping along edges), you may need to use a larger filter width or smoother filter to produce acceptable results.  For aliased volume data, ", {"text": ["gauss"], "type": "code"}, " is a good filter with a filter width of 1.5."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["point"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["box"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["gauss"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["bartlett"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["blackman"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["catrom"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["hanning"], "type": "code"}]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["mitchell"], "type": "code"}]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": ["Volume filter"], "role": "item", "attrs": {"ifdprop": "object:filter", "hprop": "vm_volumefilter"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This specifies the filter width for the object:filter property. The filter width is specified in number of voxels. Larger filter widths take longer to render and produce blurrier renders, but may be necessary to combat aliasing in some kinds of voxel data."]}], "indent": 0, "text": ["Volume filter width"], "role": "item", "attrs": {"ifdprop": "object:filterwidth", "hprop": "vm_volumefilterwidth"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Shade every sample rather than shading micropolygon vertices. This setting enables the raytrace rendering on a per-object basis."]}, {"indent": 4, "type": "para", "text": ["When micro-polygon rendering, shading normally occurs at micro-polygon vertices at the beginning of the frame. To determine the color of a sample, the corner vertices are interpolated. Turning on ", {"text": ["object:rayshade"], "type": "code"}, " will cause the ray-tracing shading algorithm to be invoked. This will cause each sample to be shaded independently. This means that the shading cost may be significantly increased. However, each sample will be shaded at the correct time, and location."]}, {"indent": 4, "type": "para", "text": ["Currently not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Raytrace shading"], "role": "item", "attrs": {"ifdprop": "object:rayshade", "hprop": "vm_rayshade"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Global raytracing bias to be used for PBR rendering, specified in world space units.  Increase the raytracing bias only if doing so eliminates rendering artifacts in your render.  For really small scenes (1 unit in size), it is sometimes necessary to decrease the raytracing bias."]}], "indent": 0, "text": ["Raytracing bias"], "role": "item", "attrs": {"ifdprop": "renderer:raybias", "hprop": "vm_raybias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the distance between the shading position and the generated points used for ray tracing derivative calculations as a multiple of the pixel size.  Smaller values will produce sharper results at the expense of possible numerical stability problems.  If you are using bump mapping on geometry with inconsistent tangent vectors, decrease this value to eliminate artifacts in the render.  This value is not a scale on the derivative size, only an accuracy control."]}], "indent": 0, "text": ["Ray derivative bias"], "role": "item", "attrs": {"ifdprop": "renderer:rayderivbias", "hprop": "vm_rayderivbias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, ray tracing derivatives will use a randomly oriented s/t basis as opposed to the default geometric basis.  This property can be used to reduce shading artifacts that arise due to abrupt changes in parameter directions at surface boundaries, particularly when computing normals from high frequency patterns.  Ray tracing derivatives include all values computed using the ", {"text": ["Du()"], "type": "code"}, ", ", {"text": ["Dv()"], "type": "code"}, ", ", {"text": ["computenormal()"], "type": "code"}, ", and the ", {"text": ["dPds"], "type": "code"}, "/", {"text": ["dPdt"], "type": "code"}, " globals.  The s and t shading globals are unaffected by this property."]}], "indent": 0, "text": ["Randomize ray derivative basis"], "role": "item", "attrs": {"ifdprop": "renderer:rayderivrandom", "hprop": "vm_rayderivrandom"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When micro-polygon rendering, shading normally occurs at micro-polygon vertices at the beginning of the frame. Enabling this checkbox causes the vertex colors to be Gouraud shaded to determine the color for a sample."]}, {"indent": 4, "type": "para", "text": ["Turn this checkbox off when you are trying to match a background plate to  eliminate any filtering which might occur on the plate. The Gouraud interpolation will cause softening of the map."]}], "indent": 0, "text": ["Smooth grid colors"], "role": "item", "attrs": {"ifdprop": "object:smoothcolor", "hprop": "vm_smoothcolor"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Fix shadow terminator"], "role": "item", "attrs": {"status": "nd", "ifdprop": "object:smoothP", "hprop": "vm_smoothP"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The space or comma separated list of categories to which this object belongs."]}, {"indent": 4, "type": "para", "text": ["Currently not supported for per-primitive material assignment (material SOP)."]}], "indent": 0, "text": ["Categories"], "role": "item", "attrs": {"ifdprop": "object:categories", "hprop": "categories"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A list of patterns. Lights matching these patterns will illuminate this object. You can use wildcards (for example, ", {"text": ["key_*"], "type": "code"}, ") and\n    ", {"text": ["bundle references"], "fullpath": "/basics/bundles", "scheme": null, "type": "link", "value": "/basics/bundles"}, "  to specify lights."]}, {"indent": 4, "type": "para", "text": ["You can also use the  ", {"text": ["link editor pane"], "fullpath": "/ref/panes/linker", "scheme": null, "type": "link", "value": "/ref/panes/linker"}, "  to edit the relationships between lights and objects using a graphical\n    interface."]}, {"indent": 4, "type": "para", "text": ["The ", {"text": ["object:lightmask"], "type": "code"}, " property in Mantra is a computed property containing the results of combining light categories and light masks."]}], "indent": 0, "text": ["Light mask"], "role": "item", "attrs": {"ifdprop": "object:lightmask", "hprop": "lightmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of categories. Lights in these categories will illuminate this object."]}], "indent": 0, "text": ["Light selection"], "role": "item", "attrs": {"ifdprop": "object:lightcategories", "hprop": "lightcategories"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A list of patterns. Objects matching these patterns will reflect in this object. You can use wildcards (for example, ", {"text": ["key_*"], "type": "code"}, ") and\n    ", {"text": ["bundle references"], "fullpath": "/basics/bundles", "scheme": null, "type": "link", "value": "/basics/bundles"}, "  to specify objects."]}, {"indent": 4, "type": "para", "text": ["You can also use the  ", {"text": ["link editor pane"], "fullpath": "/ref/panes/linker", "scheme": null, "type": "link", "value": "/ref/panes/linker"}, "  to edit the relationships between lights and objects using a graphical\n    interface."]}, {"indent": 4, "type": "para", "text": ["The ", {"text": ["object:reflectmask"], "type": "code"}, " property in Mantra is a computed property containing the results of combining reflection categories and reflection masks."]}], "indent": 0, "text": ["Reflection mask"], "role": "item", "attrs": {"ifdprop": "object:reflectmask", "hprop": "reflectmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of categories. Objects in these categories will reflect in this object."]}], "indent": 0, "text": ["Reflection selection"], "role": "item", "attrs": {"ifdprop": "object:reflectcategories", "hprop": "reflectcategories"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A list of patterns. Objects matching these patterns will be visible in refraction rays. You can use wildcards (for example, ", {"text": ["key_*"], "type": "code"}, ") and ", {"text": ["bundle references"], "fullpath": "/basics/bundles", "scheme": null, "type": "link", "value": "/basics/bundles"}, "  to specify objects."]}, {"indent": 4, "type": "para", "text": ["You can also use the  ", {"text": ["link editor pane"], "fullpath": "/ref/panes/linker", "scheme": null, "type": "link", "value": "/ref/panes/linker"}, "  to edit the relationships between lights and objects using a graphical\n    interface."]}, {"indent": 4, "type": "para", "text": ["The ", {"text": ["object:refractmask"], "type": "code"}, " property in Mantra is a computed property containing the results of combining reflection categories and reflection masks."]}], "indent": 0, "text": ["Refraction mask"], "role": "item", "attrs": {"ifdprop": "object:refractmask", "hprop": "refractmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space-separated list of categories. Objects in these categories will be visible in refraction rays."]}], "indent": 0, "text": ["Refraction selection"], "role": "item", "attrs": {"ifdprop": "object:refractcategories", "hprop": "refractcategories"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When biases are used in VEX shaders, the bias can either be performed along the ray direction or along the surface normal. If this parameter is turned on, biasing will be along the surface normal - using the ", {"text": ["Ng"], "type": "code"}, " VEX variable. "]}, {"indent": 4, "type": "para", "text": ["If the ray direction and normal point in different directions, the normal will first be flipped and then biasing will be performed in the direction of the flipped normal.  This setting is particularly useful when ray traced surfaces that are seen edge-on."]}], "indent": 0, "text": ["Bias along normal"], "role": "item", "attrs": {"ifdprop": "object:biasnormal", "hprop": "vm_biasnormal"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Normally, emission (\"Ce\") will contribute to secondary rays such as reflections.  This setting disables emission for secondary rays so that it only affects primary rays or directly visible light.  This setting is useful to avoid double-counting emission when it is already handled by another object or light."]}], "indent": 0, "text": ["Emission illuminates objects"], "role": "item", "attrs": {"ifdprop": "object:emitillum", "hprop": "vm_emitillum"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["By default, when instancing is used with displacements, the displaced\n    geometry will be created uniquely for each instance, since it\u2019s\n    possible that the displacements may differ based on the world-space\n    position of each instance.  This default behavior will guarantee\n    correct results but it can be inefficient since mantra needs to keep a\n    separate copy of the displaced geometry for each instance. When this\n    setting is enabled, mantra will share a single copy of the displaced\n    geometry between all instances, and assumes that the displacement\n    shader only uses the object space position to determine the displaced\n    position and normal."]}, {"indent": 4, "type": "para", "text": ["The dicing quality used when displacements are shared will be the dicing quality for the instance that is closest to the camera. Therefore, instances that are farther from the camera may incur a greater rendering cost when this setting is enabled, but overall memory use will usually be lower."]}, {"indent": 4, "type": "para", "text": ["When sharing displacements on packed primitives, there\u2019s a very subtle issue which may cause issues with popping displacements.  The ", {"text": ["vm_procuseroottransform"], "type": "code"}, " toggle is on by default.  This means the object space for the packed geometry will not include the transform on the packed primitive itself, only the transform on the object containing the packed primitives.  This is important when doing geometry/volume lighting so that point clouds will all be in the space of the single object.  However, when there are shared displacements, the displacement should be computed in the space of the unpacked geometry (i.e. including the transform on the packed primitive).  If you want to use shared displacements on packed primitives, you should turn off the ", {"text": ["vm_procuseroottransform"], "type": "code"}, " parameter."]}], "indent": 0, "text": ["Share Displacements Between Instances"], "role": "item", "attrs": {"ifdprop": "object:sharedisplace", "hprop": "vm_sharedisplace"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Shading"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The pattern of object names which are considered for ray-traced shadows."]}], "indent": 0, "text": ["Shadow mask"], "role": "item", "attrs": {"ifdprop": "light:shadowmask", "hprop": "shadowmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The pattern of object categories which are considered for ray-traced shadows."]}], "indent": 0, "text": ["Shadow selection"], "role": "item", "attrs": {"ifdprop": "light:shadowcategories", "hprop": "shadowcategories"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Shadow"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [], "indent": 0, "text": ["Render output"], "role": "item", "attrs": {"status": "nd", "hprop": "soho_spoolrenderoutput"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["VEX profiling lets you do analyze shader performance. Turning this on will slow down shading, especially when NAN detection is turned on."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["No VEX Profiling is performed."]}], "indent": 4, "type": "dt", "text": ["No VEX Profiling (", {"text": ["0"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Mantra will print out information about shading computations at the conclusion of the render. This helps in identifying bottlenecks in the shading process."]}], "indent": 4, "type": "dt", "text": ["Execution Profiling (", {"text": ["1"], "type": "code"}, ")"]}, {"body": [{"indent": 8, "type": "para", "text": ["Prints out the shading information and will not print instructions that generate bad values (Not A Number). The output is cryptic, but can help track down errors in shaders."]}], "indent": 4, "type": "dt", "text": ["Profiling and NAN detection (", {"text": ["2"], "type": "code"}, ")"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["When NAN detection is turned on, each instruction executed in VEX will be checked for invalid arithmetic operations. This will check for division by ", {"text": ["0"], "type": "code"}, ", numeric overflow, invalid operations. Errors like this will typically result in white or black pixels in the resulting image."]}], "indent": 0, "text": ["VEX profiling"], "role": "item", "attrs": {"ifdprop": "renderer:vexprofile", "hprop": "vm_vexprofile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Increasing this value will cause more information to be printed out during rendering.  To see render time and memory information, set the verbosity level to 1.  To see more detailed information about the render, set this parameter to 3.  Larger values print out progressively more information."]}], "indent": 0, "text": ["Verbose level"], "role": "item", "attrs": {"ifdprop": "renderer:verbose", "hprop": "vm_verbose"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A percentage complete value is printed out as tiles are finished. This is in the style expected by Pixar\u2019s Alfred render queue."]}, {"indent": 4, "type": "para", "text": ["The following is an example of timing information and how to read it."]}, {"lang": null, "indent": 4, "type": "pre", "text": ["\n    Render Time: 4.52u 6.30s 4.24r Memory:  23.40 MB of 23.59 MB arena size.  VM Size: 345.11 MB\n    "]}, {"body": [{"body": [{"body": [{"body": [{"indent": 12, "type": "para", "text": ["This value might not be 100% accurate depending on the OS and other system variables.  On Linux, this value will indicate the total time for ", {"text": ["all threads"], "type": "ui"}, " to render, so rendering with more than one processor may inflate the user time."]}], "indent": 8, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 4, "blevel": 6, "type": "bullet", "text": ["The ", {"text": ["u"], "type": "code"}, " value is the user time in seconds mantra took to render the image."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["The ", {"text": ["s"], "type": "code"}, " value is the system overhead incurred in rendering the frame (disk io, swap, etc.).  A large system time may indicate a large amount of time spend reading or writing files."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["The ", {"text": ["r"], "type": "code"}, " value is the wall clock time to render.  This is the most important value as it gives a clear indication for the total amount of time spent rendering."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["Arena size is the amount of memory mantra allocated to actually render the image. It does not reflect how much memory mantra actually used."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": ["VM size is the virtual memory size for the mantra program.  This is the amount of memory reported by the operating system and may significantly exceed the amount of memory that mantra is actually using."]}], "container": true, "type": "bullet_group"}, {"indent": 4, "type": "para", "text": ["Mantra needs to grab continuous chunks of memory as it builds the data structures. Once it frees up the data, the operating system controls the arena size shrinking it where it finds continuous chunks of memory back to the free pool of available memory. This is called memory allocation and memory deallocation. You don\u2019t want the arena size much larger than the actual memory used."]}], "indent": 0, "text": ["Alfred style progress"], "role": "item", "attrs": {"ifdprop": "renderer:alfprogress", "hprop": "vm_alfprogress"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This property specifies a python callback which can be called at the completion of each tile rendered. There is a \"built-in\" \"mantra\" module which allows information to be queried. There is a single function available in the mantra module. The \"property\" function allows querying of any global rendering property as well as some other special properties. The result of the property call is always a list of values. "]}, {"indent": 4, "type": "para", "text": ["The special properties queried may be\u2026"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:ncomplete"], "type": "code"}, " \u2013 The number of tiles which have been completed."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:ntiles"], "type": "code"}, " \u2013 The total number of tiles in the image."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:laptime"], "type": "code"}, " \u2013 The number of seconds taken to render the last tile."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:totaltime"], "type": "code"}, " \u2013 The total number of seconds to render since the render began.  This does ", {"text": ["not"], "type": "strong"}, " include time to load the scene, but rather is defined as the time since the first tile began rendering."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:coords"], "type": "code"}, " \u2013 The tile bounding box (in pixels)."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["tile:memory"], "type": "code"}, " \u2013 The amount of RAM in use by mantra."]}], "container": true, "type": "bullet_group"}, {"lang": "python", "indent": 4, "type": "pre", "text": ["\n    import mantra\n    import sys\n\n    tile = mantra.property(\"tile:ncomplete\")(0)\n    if tile == 1\n        print mantra.property(\"renderer:name\")\n        print mantra.property(\"renderer:version\")\n    "]}], "indent": 0, "text": ["Python tile callback"], "role": "item", "attrs": {"ifdprop": "renderer:tilecallback", "hprop": "vm_tilecallback"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Colorize output"], "role": "item", "attrs": {"status": "nd", "ifdprop": "global:logcolors", "hprop": "vm_logcolors"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Log timestamp"], "role": "item", "attrs": {"status": "nd", "ifdprop": "global:logtimestamps", "hprop": "vm_logtimestamps"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Statistics"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Specifies a list of cameras to be used for rendering. The native operator type for the stereo camera has this property and by default specifies two regular cameras for the left and right points of view."]}], "indent": 0, "text": ["Render cameras"], "role": "item", "attrs": {"hprop": "vm_cameralist"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Is a string appended to the file name. This string is usually specified by the cameras included in the ", {"text": ["vm_cameralist"], "type": "code"}, " property of another camera, and is appended to the ", {"text": ["vm_picture"], "type": "code"}, " file name string of the render node before saving the rendered image to a file. It is used for disambiguating left and right images for a given frame. This suffix is added to the base filename and will come before the filename extension."]}], "indent": 0, "text": ["Image file suffix"], "role": "item", "attrs": {"hprop": "vm_filenamesuffix"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Is non-zero if the camera represents the left view point in a stereoscopic setup."]}], "indent": 0, "text": ["Is left camera"], "role": "item", "attrs": {"hprop": "vm_s3dleftcamera"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Is non-zero if the camera represents the right view point in a stereoscopic setup."]}], "indent": 0, "text": ["Is right camera"], "role": "item", "attrs": {"hprop": "vm_s3drightcamera"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Sub camera tag"], "role": "item", "attrs": {"status": "nd", "hprop": "subcamtag"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Include in viewport menu"], "role": "item", "attrs": {"status": "nd", "hprop": "viewmenu"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["View xform node"], "role": "item", "attrs": {"status": "nd", "hprop": "viewxformpath"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Stereo"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Selects the method used to unwrap from the 'UV Object'."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Maps the UVs to their locations on the surface of the object."]}], "indent": 4, "type": "dt", "text": ["UV To Surface"]}, {"body": [{"indent": 8, "type": "para", "text": ["Uses raytracing to find the surface closest to the ", {"text": ["UV Object"], "type": "ui"}, "."]}], "indent": 4, "type": "dt", "text": ["Trace Closest Surface"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Unwrap Method"], "role": "item", "attrs": {"hprop": "vm_uv_unwrap_method"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The texture baking output format:"]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["Bake texture into one or more UDIM texture images."]}], "indent": 4, "type": "dt", "text": ["UDIM"]}, {"body": [{"indent": 8, "type": "para", "text": ["Bake texture into a single Ptex image."]}], "indent": 4, "type": "dt", "text": ["Ptex"]}], "container": true, "type": "dt_group"}], "indent": 0, "text": ["Texture Format"], "role": "item", "attrs": {"ifdprop": "renderer:uvtype", "hprop": "vm_uvtype"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When texture baking to UDIM images, this is the name of the texture\n    coordinate attribute used for unwrapping."]}], "indent": 0, "text": ["UV Attribute"], "role": "item", "attrs": {"ifdprop": "renderer:uvattribute", "hprop": "vm_uvattribute"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When texture baking to UDIM images, this specifies the resolution of the\n    UDIM images."]}], "indent": 0, "text": ["UV Unwrap Resolution"], "role": "item", "attrs": {"ifdprop": "image:resolution", "hprop": "vm_uvunwrapres"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the sharpness of baked textures. Higher values produce sharper results."]}], "indent": 0, "text": ["UV Shading Quality"], "role": "item", "attrs": {"ifdprop": "renderer:uvshadingquality", "hprop": "vm_uvshadingquality"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When performing texture baking, this parameter will create any intermediate directories before creating the baked texture images."]}], "indent": 0, "text": ["Create Intermediate Directories"], "role": "item", "attrs": {"ifdprop": "renderer:uvmkpath", "hprop": "vm_uvmkpath"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When UV baking from a high-res object to a low-res cage, normally you want to turn off rendering of the low-res cage.  Turning off this option will disable that feature."]}], "indent": 0, "text": ["Hide UV cage objects"], "role": "item", "attrs": {"hprop": "vm_uvhidecage"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This parameter controls the light components excluded during bake renders. When baking it is common to render only view-independent components such as \"diffuse\". The default value of ", {"text": ["-diffuse & -volume"], "type": "code"}, " will only render diffuse and volume light paths."]}], "indent": 0, "text": ["Exclude Light Paths"], "role": "item", "attrs": {"hprop": "vm_uvlightpaths"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a Ptex image, this specifies the tile resolution for the\n    smallest faces in the model."]}], "indent": 0, "text": ["Minimum Ptex Map Resolution"], "role": "item", "attrs": {"ifdprop": "renderer:ptexmapminres", "hprop": "vm_ptexmapminres"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a Ptex image, this specifies the largest resolution for any\n    individual face in the model."]}], "indent": 0, "text": ["Maximum Ptex Map Resolution"], "role": "item", "attrs": {"ifdprop": "renderer:ptexmapmaxres", "hprop": "vm_ptexmapmaxres"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a Ptex image, mantra will measure the world-space size of all the faces in the image.  Each face\u2019s tile resolution will be determined by the relative size of the face compared with the smallest faces in the model (unless ", {"text": ["Ptex Use Relative Scale"], "type": "ui"}, " is disabled).  The tile resolution of a given face is given by ", {"text": ["clamp(curr_size/min_size * ptexmapminres * ptexmapscale, ptexmapminres, ptexmapmaxres)"], "type": "code"}, "."]}], "indent": 0, "text": ["Ptex Resolution Scale"], "role": "item", "attrs": {"ifdprop": "renderer:ptexmapscale", "hprop": "vm_ptexmapscale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a Ptex image, mantra will look for primitive-level scalar attribute of this name to scale tile resolution of current face. Note that the scaled resolution is still clamped by Minimum and Maximum resolutions."]}], "indent": 0, "text": ["Ptex Scale Prim Attribute"], "role": "item", "attrs": {"ifdprop": "renderer:ptexscaleattr", "hprop": "vm_ptexscaleattr"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If this is disabled, mantra will no longer measure relative size of faces compared with smallest faces in the model when baking to a Ptex image. The tile resolution of each face will simply be ", {"text": ["Minimum Ptex Map Resolution"], "type": "ui"}, " multiplied by ", {"text": ["Ptex Resolution Scale"], "type": "ui"}, " and primitive-level Ptex scale attribute (if one exists)."]}], "indent": 0, "text": ["Ptex Use Relative Scale"], "role": "item", "attrs": {"ifdprop": "renderer:ptexrelativescale", "hprop": "vm_ptexrelativescale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a Ptex image, this option determines the orientation of face ids for subfaces when splitting non-quad faces.  The default is to order the sub-faces counterclockwise.  However, some software expects to have the faces ordered clockwise."]}], "indent": 0, "text": ["Orient Ptex Subfaces Clockwise"], "role": "item", "attrs": {"ifdprop": "renderer:ptexwraporient", "hprop": "vm_ptexwraporient"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a UDIM image, this option determines what type of post-processing is applied to the final image.  The choices are  ", {"text": ["No Post Processing"], "type": "ui"}, ", ", {"text": ["Border Expansion"], "type": "ui"}, ", ", {"text": ["Fill Background With Average Color"], "type": "ui"}, ", and ", {"text": ["Diffuse Fill"], "type": "ui"}, "."]}, {"body": [{"body": [{"indent": 12, "type": "para", "text": ["Currently, this is only supported when rendering to disk (not to flipbooks)"]}], "indent": 4, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 0, "text": ["UDIM Post Process"], "role": "item", "attrs": {"ifdprop": "renderer:uvpostprocess", "hprop": "vm_uvpostprocess"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When baking to a UDIM image and performing island border expansion, this\n    parameter indicates by how many pixels each island should be enlarged."]}], "indent": 0, "text": ["UV Additional Pixels at Border"], "role": "item", "attrs": {"ifdprop": "renderer:uvborderpixels", "hprop": "vm_uvborderpixels"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When texture baking, this will reverse normals on the geometry.  This\n    determines the orientation of the surface for the baking lens shader (i.e.\n    shade the inside or outside of the surface)."]}], "indent": 0, "text": ["Reverse Normals"], "role": "item", "attrs": {"hprop": "vm_uv_flip_normal"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Determines how much to offset the position of the ray from the surface of the object along the normal vector. This value should be increased proportional to the displacement in a displacement shader (if there is one) in order to ensure that the ray hits the surface. The\n    bias is used solely for camera rays."]}], "indent": 0, "text": ["Ray Bias"], "role": "item", "attrs": {"hprop": "vm_uv_ray_bias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["If ", {"text": ["vm_uv_unwrap_method"], "type": "code"}, " is set to ", {"text": ["Trace Closest Surface"], "type": "code"}, " this parameter controls the maximum distance to trace for nearby surfaces. Useful for limiting the areas of the scene that will be baked onto the low-res object."]}], "indent": 0, "text": ["Ray Max Distance"], "role": "item", "attrs": {"hprop": "vm_uv_ray_maxdist"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Unwrapping"], "container": true, "type": "h", "id": null}, {"body": [], "indent": 0, "level": 2, "text": ["User"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The output resolution in pixels. Standard presets are available via the pull down menu to the right of the parameter."]}], "indent": 0, "text": ["Resolution"], "role": "item", "attrs": {"hprop": "res"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Choose resolution"], "role": "item", "attrs": {"status": "nd", "hprop": "resMenu"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The pixel aspect ratio of the output image."]}], "indent": 0, "text": ["Pixel aspect ratio"], "role": "item", "attrs": {"ifdprop": "image:pixelaspect", "hprop": "aspect"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Type of camera projection used for rendering (for example, perspective or orthographic)."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["This simulates the classic pinhole camera where camera rays emanate\n        from a common camera origin through a flat camera plane."]}], "indent": 4, "type": "dt", "text": ["Perspective"]}, {"body": [{"indent": 8, "type": "para", "text": ["This uses parallel camera rays that are orthogonal to the (flat)\n        camera plane. The width of the view volume is determined by the\n        Ortho Width parameter below."]}], "indent": 4, "type": "dt", "text": ["Orthographic"]}, {"body": [{"indent": 8, "type": "para", "text": ["This projection uses a spherical camera plane for rendering."]}], "indent": 4, "type": "dt", "text": ["Polar (panoramic)"]}, {"body": [{"indent": 8, "type": "para", "text": ["This projection uses a cylindrical camera plane for rendering."]}], "indent": 4, "type": "dt", "text": ["Cylindrical (panoramic)"]}], "container": true, "type": "dt_group"}, {"indent": 4, "type": "para", "text": ["Lens Shader:\n    Use a lens shader to initialize rays for ray tracing."]}, {"indent": 4, "type": "para", "text": ["Selecting ", {"text": ["Polar"], "type": "ui"}, ", ", {"text": ["Cylindrical"], "type": "ui"}, " or ", {"text": ["Lens Shader"], "type": "ui"}, " will automatically switch the ", {"text": ["Rendering Engine"], "type": "ui"}, " (on the output driver) to ", {"text": ["Ray Tracing"], "type": "ui"}, ", as it is impossible to render these projections with micropolygon rendering."]}], "indent": 0, "text": ["Projection"], "role": "item", "attrs": {"hprop": "projection"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Width of orthographic view volume when using Projection is set to\n    Orthographic."]}], "indent": 0, "text": ["Otho width"], "role": "item", "attrs": {"ifdprop": "camera:orthowidth", "hprop": "orthowidth"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Camera focal length (zoom)."]}], "indent": 0, "text": ["Focal length"], "role": "item", "attrs": {"hprop": "focal"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The units used for the focal length."]}], "indent": 0, "text": ["Focal units"], "role": "item", "attrs": {"hprop": "focalunits"}, "type": "properties_item"}, {"body": [{"body": [{"body": [{"indent": 8, "type": "para", "text": ["Width of the visible field."]}, {"body": [{"body": [{"indent": 12, "type": "para", "text": ["The correct aperture width for Super 35mm format motion picture film is 24.89."]}], "indent": 8, "role": "item", "type": "note"}], "container": true, "role": "item_group", "type": "note_group"}], "indent": 4, "role": "item", "type": "fig", "text": [{"text": "", "fullpath": "/nodes/images/fov.png", "scheme": "Image", "type": "link", "value": "/nodes/images/fov.png"}]}], "container": true, "role": "item_group", "type": "fig_group"}], "indent": 0, "text": ["Aperture"], "role": "item", "attrs": {"hprop": "aperture"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Position of near clipping plane."]}], "indent": 0, "text": ["Near clipping"], "role": "item", "attrs": {"hprop": "near"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Position of far clipping plane."]}], "indent": 0, "text": ["Far clipping"], "role": "item", "attrs": {"hprop": "far"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Define the center of the window during the rendering process."]}], "indent": 0, "text": ["Screen window X/Y"], "role": "item", "attrs": {"hprop": "win"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Scale for expanding the cropped area specified by the ", {"text": ["Crop"], "type": "ui"}, " parameters."]}], "indent": 0, "text": ["Screen window size"], "role": "item", "attrs": {"hprop": "winsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sets the screen window mask to cover the bounding box of the selected object(s)."]}], "indent": 0, "text": ["Screen window mask"], "role": "item", "attrs": {"hprop": "winmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Left cropping margin for camera\u2019s view area."]}], "indent": 0, "text": ["Left crop"], "role": "item", "attrs": {"hprop": "cropl"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Right cropping margin for camera\u2019s view area."]}], "indent": 0, "text": ["Right crop"], "role": "item", "attrs": {"hprop": "cropr"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Bottom cropping margin for camera\u2019s view area."]}], "indent": 0, "text": ["Bottom crop"], "role": "item", "attrs": {"hprop": "cropb"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Top cropping margin for camera\u2019s view area."]}], "indent": 0, "text": ["Top crop"], "role": "item", "attrs": {"hprop": "cropt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Sets the pixel crop region to cover the bounding box of the selected object(s)."]}], "indent": 0, "text": ["Crop Mask"], "role": "item", "attrs": {"hprop": "cropmask"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enlarges the crop region by this many pixels (horizontal and vertical amounts).  If the crop region is the full image, additional pixels outside the image will be rendered."]}, {"indent": 4, "type": "para", "text": ["For images that support arbitrary data windows (OpenEXR, Houdini) pixels outside the image resolution will be saved.  For other image formats, the pixels will be computed but the results discarded."]}], "indent": 0, "text": ["Image Overscan"], "role": "item", "attrs": {"hprop": "vm_overscan"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Scales the viewport geometry. This parameter is only for display\n    purposes."]}], "indent": 0, "text": ["Icon scale"], "role": "item", "attrs": {"hprop": "iconscale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Mantra is able to render using a non-flat projection plane. When the curvature is non-zero, ray-tracing will be used for primary rays. The curvature may either be greater or less than zero to mimic a wide angle or fish-eye lens."]}, {"indent": 4, "type": "para", "text": ["The ", {"text": ["vm_curvature"], "type": "code"}, " has the following effect on an existing perspective direction vector D:"]}, {"lang": null, "indent": 4, "type": "pre", "text": ["\n    tx = [-0.5:0.5] x screen offset\n    ty = [-0.5:0.5] y screen offset\n\n    cmult = camera:curvature / camera:zoom\n    D.z = 1 + (1 - 2*(tx*tx + ty*ty)) * cmult\n    "]}], "indent": 0, "text": ["Lens curvature"], "role": "item", "attrs": {"ifdprop": "camera:curvature", "hprop": "vm_curvature"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Remove camera scaling when calculating the view transform. This is on by default."]}], "indent": 0, "text": ["Remove Camera Scale"], "role": "item", "attrs": {"hprop": "vm_removecamerascale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables background image rendering."]}], "indent": 0, "text": ["Enable background image"], "role": "item", "attrs": {"ifdprop": "image:bgenable", "hprop": "vm_bgenable"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies a ", {"text": ["deep camera"], "fullpath": "/render/dcm", "scheme": null, "type": "link", "value": "/render/dcm"}, "/", {"text": ["shadow"], "fullpath": "/render/shadows", "scheme": null, "type": "link", "value": "/render/shadows"}, " image to use to fill in the background color for primary rays (and only primary rays)."]}, {"indent": 4, "type": "para", "text": ["Because the deep camera/shadow image stores the color/opacity values for all depths, the deep image can be mixed with other objects in the scene with perfect occlusion/transparency."]}, {"indent": 4, "type": "para", "text": ["Add this property to a camera (not the output driver). If you add it to the output driver, the background image will be picked up for shadow map generation, which is probably not what you want."]}, {"indent": 4, "type": "para", "text": ["If you add this property to a light, the image will be merged with shadow maps generated shadow maps from the light."]}], "indent": 0, "text": ["Background Image"], "role": "item", "attrs": {"ifdprop": "image:background", "hprop": "vm_background"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Render the ", {"fragment": "#vm_background", "text": ["background deep camera map"], "value": "#vm_background", "fullpath": "/props/mantra#vm_background", "scheme": null, "type": "link"}, " as a matte object. When this property is on, mantra throws away the color of the deep camera map, and the alpha from the deep camera map is not put into the final image. This is the default behavior for deep shadow map files."]}, {"indent": 4, "type": "para", "text": ["Only meaningful for deep camera images.  Deep shadow images have this behavior by default."]}], "indent": 0, "text": ["Background Image as Matte"], "role": "item", "attrs": {"default": "('false')", "ifdprop": "image:backgroundmatte", "hprop": "vm_backgroundmatte"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A space/comma-separated list of patterns matching the channels to use from the ", {"fragment": "#vm_background", "text": ["background image"], "value": "#vm_background", "fullpath": "/props/mantra#vm_background", "scheme": null, "type": "link"}, ". This For example, ", {"text": ["*,^C"], "type": "code"}, " uses all channels except the ", {"text": ["C"], "type": "code"}, " channel. This lets you for example use only the alpha channel from a deep camera map, and prevent the color from the DCM from affecting the rendered image."]}, {"indent": 4, "type": "para", "text": ["This is applicable to both deep camera map backgrounds and flat image backgrounds."]}], "indent": 0, "text": ["Background Image Channels"], "role": "item", "attrs": {"default": "(\"*\")", "ifdprop": "image:backgroundchannels", "hprop": "vm_backgroundchannels"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, if the background image does not match the render resolution the background will be scaled to fill the render resolution."]}], "indent": 0, "text": ["Scale background to fill image"], "role": "item", "attrs": {"ifdprop": "image:bgscale", "hprop": "vm_bgscale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This setting allows you to apply a scale to the z-values in the background image, which may simplify merging deep images that have a different scale."]}], "indent": 0, "text": ["Background Z-Scale"], "role": "item", "attrs": {"ifdprop": "image:bgzscale", "hprop": "vm_bgzscale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specifies the CVEX lens shader to use for the ", {"text": ["Lens Shader"], "type": "code"}, " projection\n    type.  A lens shader is responsible for computing primary rays from\n    screen coordinates, and is a flexible way to define new kinds of camera\n    projections that can\u2019t be modeled as perspective or orthographic\n    projections.  Lens shaders can have the following parameters and\n    exports:"]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float x"], "type": "code"}, " \u2013 X screen coordinate in the range -1 to 1"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float y"], "type": "code"}, " \u2013 Y screen coordinate in the range -1 to 1"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float Time"], "type": "code"}, " \u2013 Sample time"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float dofx"], "type": "code"}, " \u2013 X depth of field sample value"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float dofy"], "type": "code"}, " \u2013 Y depth of field sample value"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["float aspect"], "type": "code"}, " \u2013 Image aspect ratio (x/y)"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["export vector P"], "type": "code"}, " \u2013 Ray origin in camera space"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["export vector I"], "type": "code"}, " \u2013 Ray direction in camera space"]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["export int valid"], "type": "code"}, " \u2013 Whether the sample is valid for measuring"]}], "container": true, "type": "bullet_group"}, {"indent": 4, "type": "para", "text": ["The lens shader should be able to handle x and y values outside the -1\n    to 1 range, in case samples outside the image need to be generated. The\n    P and I exports should be created in camera space, ignoring the camera\n    transform."]}, {"indent": 4, "type": "para", "text": ["Before rendering begins, mantra measures the lens shader before\n    rendering.  During the measuring process, the ", {"text": ["valid"], "type": "code"}, " variable can be used\n    to flag invalid rays.  In the future, the ", {"text": ["valid"], "type": "code"}, " flag may be used during\n    rendering."]}, {"indent": 4, "type": "para", "text": ["Mantra\u2019s camera space is defined with positive\n    z-values in front of the camera, so for a default camera the z-axis\n    is flipped relative to Houdini\u2019s world space."]}, {"indent": 4, "type": "para", "text": ["An example lens shader is the ", {"text": ["Ray Lens"], "fullpath": "/nodes/shop/v_asadlens", "scheme": null, "type": "link", "value": "/nodes/shop/v_asadlens"}, " shader."]}], "indent": 0, "text": ["Lens Shader"], "role": "item", "attrs": {"ifdprop": "renderer:lensshader", "hprop": "vm_lensshader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specify the cropping region in pixel coordinates.  This is typically automatically done in IFD generation."]}], "indent": 0, "text": ["Pixel Crop"], "role": "item", "attrs": {"ifdprop": "image:pixelcrop"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["View"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The shader assigned to the automatically added background fog object (see ", {"fragment": "#vm_fogbackground", "text": "", "value": "/props/mantra#vm_fogbackground", "fallback_text": "vm_fogbackground", "fullpath": "/props/mantra#vm_fogbackground", "scheme": "Mantra", "type": "link"}, "). You must add this as a spare parameter if you want to change it, it doesn\u2019t exist in the render properties interface."]}], "indent": 0, "text": ["Fog Background Shader"], "role": "item", "attrs": {"ifdprop": "renderer:fogbackgroundshader", "hprop": "vm_fogbackgroundshader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The number of tiles queued for network rendering. You must add this as a spare parameter if you want to change it, it doesn\u2019t exist in the render properties interface."]}], "indent": 0, "text": ["Network Queue Size"], "role": "item", "attrs": {"ifdprop": "renderer:networkqsize", "hprop": "vm_networkqsize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Typically handled automatically during IFD generation."]}, {"indent": 4, "type": "para", "text": ["In the material overrides, the names specified for the overrides may not\n    match the internal mantra property names (i.e. ", {"text": ["vm_rendersubd"], "type": "code"}, " as opposed\n    to ", {"text": ["rendersubd"], "type": "code"}, ").  The property map provides a name map (represented as a\n    Python dictionary) mapping the parameter name specified in the override to\n    the actual Mantra property name."]}, {"indent": 4, "type": "para", "text": ["You must add this as a spare parameter if you want to change it, it doesn\u2019t exist in the render properties interface."]}], "indent": 0, "text": ["Override Property Map"], "role": "item", "attrs": {"ifdprop": "geometry:overridepropmap", "hprop": "vm_overridepropmap"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Enables independent sampling for different light sources when rendering with PBR.  When disabled, mantra will attempt to reduce the expense of lighting computation by randomly selecting a light source to compute illumination rather than performing lighting from all lights.  Normally leaving multi-light sampling enabled will produce a better performance/quality tradeoff, in combination with active radius control in scenes with many lights."]}, {"indent": 4, "type": "para", "text": ["This is passed as an argument to the ", {"fragment": "#vm_pbrshader", "text": "", "value": "/props/mantra#vm_pbrshader", "fallback_text": "vm_pbrshader", "fullpath": "/props/mantra#vm_pbrshader", "scheme": "Mantra", "type": "link"}, "."]}, {"indent": 4, "type": "para", "text": ["You must add this as a spare parameter if you want to change it, it doesn\u2019t exist in the render properties interface."]}], "indent": 0, "text": ["Sample all lights"], "role": "item", "attrs": {"hprop": "vm_pbrmultilight"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Other Houdini properties"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["These properties exist in IFD scene description files, but do not have equivalents in the Houdini property UI."]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["This is typically handled automatically using the camera shutter information."]}], "indent": 0, "text": ["Geometry velocity scale"], "role": "item", "attrs": {"ifdprop": "object:velocityscale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Specify the rendering task.  This setting is passed to the IPR viewer and is typically done automatically during IFD generation."]}], "indent": 0, "text": ["Progress Action"], "role": "item", "attrs": {"ifdprop": "renderer:progressaction"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["The name of the image file to write the plane to (if undefined, inherited from ", {"text": ["image:filename"], "type": "code"}, ")."]}], "indent": 0, "text": [{"text": ["plane:planefile"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:planefile"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The image device to write the plane (if undefined, inherited from ", {"text": ["image:device"], "type": "code"}, ")."]}], "indent": 0, "text": [{"text": ["plane:planedevice"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:planedevice"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The channel name for the image plane in the output file."]}], "indent": 0, "text": [{"text": ["plane:planechannel"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:channel"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The VEX variable to use as the image plane data."]}], "indent": 0, "text": [{"text": ["plane:planevariable"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:variable"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The VEX type of the variable named in the ", {"text": ["plane:planevariable"], "type": "code"}, " property."]}], "indent": 0, "text": [{"text": ["plane:vextype"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:vextype"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Name of a light object associated with the VEX variable. If this is set, the variable is exported at the conclusion of the illuminance loops run for the light."]}], "indent": 0, "text": [{"text": ["plane:lightexport"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:lightexport"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether per-component export is enabled."]}], "indent": 0, "text": [{"text": ["plane:component"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:component"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Gamma correction value for the image plane."]}], "indent": 0, "text": [{"text": ["plane:gamma"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:gamma"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to exclude the plane from deep camera map rendering."]}], "indent": 0, "text": [{"text": ["plane:excludedcm"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:excludedcm"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Whether to include the plane in the relighting buffer"]}], "indent": 0, "text": [{"text": ["plane:showrelightingbuffer"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:showrelightingbuffer"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Gain value for the image plane."]}], "indent": 0, "text": [{"text": ["plane:gain"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:gain"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The storage type for the plane image.  The type of quantization used will affect image quality and size.  If you need to adjust the image\u2019s dynamic range in compositing, you should normally leave this value at the default of 16-bit floating point."]}, {"indent": 4, "type": "para", "text": ["The default is ", {"text": ["\"float16\""], "type": "code"}, " for the first plane, and ", {"text": ["\"float\""], "type": "code"}, " for secondary planes. You can override the first plane\u2019s value with the ", {"text": ["-b"], "type": "code"}, " command line argument to mantra."]}], "indent": 0, "text": [{"text": ["plane:quantize"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:quantize"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Disables the output of the image plane."]}], "indent": 0, "text": [{"text": ["plane:disable"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "plane:disable"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 3, "text": ["Image and plane properties"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["These properties are only meaningful in IFD:"]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["Read only variable holding the renderer\u2019s name."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["renderer:name"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Example: (9, 0, 614)"]}, {"indent": 4, "type": "para", "text": ["Read only triple of the major version, minor version, and build number of the renderer."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["renderer:version"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Example: (0)"]}, {"indent": 4, "type": "para", "text": ["An integer value which can be queried from within shaders. Not supported for per-primitive material assignment (in the ", {"text": ["Material surface node"], "fullpath": "/nodes/sop/material", "scheme": "Node", "type": "link", "value": "/nodes/sop/material"}, ")."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["object:id"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Example: (1.0)"]}, {"indent": 4, "type": "para", "text": ["Read only floating point value that provides the surface area of the object currently being shaded."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["object:area"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Example: (1)"]}, {"indent": 4, "type": "para", "text": ["Read only integer value that indicates whether the current light (for example in an illuminance loop) is an area light."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["light:arealight"], "type": "code"}]}, {"body": [{"indent": 4, "type": "para", "text": ["Example: (1)"]}, {"indent": 4, "type": "para", "text": ["Read only integer value that indicates whether the current light (for example in an illuminance loop) is a distant light source (an environment light or directional light)."]}], "indent": 0, "role": "item", "type": "properties_item", "text": [{"text": ["light:distantlight"], "type": "code"}]}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 3, "text": ["Implicit properties"], "container": true, "type": "h", "id": null}, {"body": [{"indent": 0, "type": "para", "text": ["The following properties are computed in scripts  during the mapping process. They do not have directly equivalent Houdini properties."]}, {"body": [{"body": [{"indent": 4, "type": "para", "text": ["The output image resolution."]}], "indent": 0, "text": [{"text": ["image:resolution"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "image:resolution"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The video field to render."]}, {"body": [{"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["0"], "type": "code"}, " \u2013 Both even & odd fields."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["1"], "type": "code"}, " \u2013 Odd field."]}, {"indent": 4, "blevel": 6, "type": "bullet", "text": [{"text": ["2"], "type": "code"}, " \u2013 Even field."]}], "container": true, "type": "bullet_group"}], "indent": 0, "text": [{"text": ["image:field"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "image:field"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["A rectangle in screen space as (", {"text": ["xmin"], "type": "code"}, ", ", {"text": ["xmax"], "type": "code"}, ", ", {"text": ["ymin"], "type": "code"}, ", ", {"text": ["ymax"], "type": "code"}, "), where the values are between 0 and 1. Only pixels within this region will be rendered."]}], "indent": 0, "text": [{"text": ["image:crop"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "image:crop"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is used in determining the camera projection. Like the crop window, this specifies a rectangle in the screen. Unlike the crop window, the window is expanded to fill the full image."]}], "indent": 0, "text": [{"text": ["image:window"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "image:window"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This property is used when computing the projection matrix for light sources in shadow mapping.  If the projection from the texture is used (default behavior), this property is ignored."]}], "indent": 0, "text": [{"text": ["light:window"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:window"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The camera\u2019s projection model. This may be one of ", {"text": ["perspective"], "type": "code"}, ", ", {"text": ["orthographic"], "type": "code"}, ", ", {"text": ["polar"], "type": "code"}, ", or ", {"text": ["cylindrical"], "type": "code"}, "."]}], "indent": 0, "text": [{"text": ["camera:projection"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "camera:projection"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Near and far clipping planes for the projection."]}], "indent": 0, "text": [{"text": ["camera:clip"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "camera:clip"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Ratio of the focal length to the aperture of the camera. It is used to determine the field of view of the camera. "]}], "indent": 0, "text": [{"text": ["camera:zoom"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "camera:zoom"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": [{"text": ["camera:focal"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "camera:focal"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Not an intrinsic mantra property, but added by SOHO when rendering stereo\n    pairs."]}, {"indent": 4, "type": "para", "text": ["This is used to determine whether a camera represents the left eye or the\n    right eye in a stereo projection. If stereo is not enabled for the camera,\n    this property is undefined."]}, {"indent": 4, "type": "para", "text": ["If defined, the value may be one of ", {"text": ["left"], "type": "code"}, ", ", {"text": ["right"], "type": "code"}, ", or ", {"text": ["both"], "type": "code"}, "."]}], "indent": 0, "text": [{"text": ["camera:stereoeye"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "camera:stereoeye"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The name associated with the geometry. This is the name which instance objects use to access the geometry."]}], "indent": 0, "text": [{"text": ["geometry:name"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "geometry:name"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Materials may be specified on a per-primitive basis. However, since materials refer to SHOP paths, it\u2019s sometimes important to be able to resolve relative paths."]}], "indent": 0, "text": [{"text": ["geometry:basepath"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "geometry:basepath"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The surface shader attached to the object."]}], "indent": 0, "text": [{"text": ["object:surface"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "object:surface"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The displacement shader attached to the object."]}], "indent": 0, "text": [{"text": ["object:displace"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "object:displace"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The VEX shader used to shade a fog object."]}], "indent": 0, "text": [{"text": ["fog:shader"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "fog:shader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The shader used to compute the illumination of the light source."]}], "indent": 0, "text": [{"text": ["light:shader"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:shader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The shader used to compute occlusion of light from the light source."]}], "indent": 0, "text": [{"text": ["light:shadow"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:shadow"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is a light shader used to handle geometry light intersections.  This is used to implement the ", {"text": ["sample_light()"], "type": "code"}, " function for area lights.  This light shader cannot reference any global variables or light-specific functionality."]}], "indent": 0, "text": [{"text": ["light:samplershader"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:samplershader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is a light shader used to handle geometry light intersections.  This is used to implement the ", {"text": ["intersect_lights()"], "type": "code"}, " function for area lights.  This light shader cannot reference any global variables or light-specific functionality."]}], "indent": 0, "text": [{"text": ["light:tracershader"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:tracershader"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when computing NDC (Normalized Device Coordinates) from within VEX shaders."]}], "indent": 0, "text": [{"text": ["light:projection"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:projection"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when computing NDC (Normalized Device Coordinates) from within VEX shaders."]}], "indent": 0, "text": [{"text": ["light:zoom"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:zoom"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when computing NDC (Normalized Device Coordinates) from within VEX shaders."]}], "indent": 0, "text": [{"text": ["light:orthowidth"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "light:orthowidth"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 3, "text": ["Computed properties"], "container": true, "type": "h", "id": null}], "indent": 0, "level": 2, "text": ["IFD-only properties"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["A literal string to use as the \"descriptive text\" displayed with the\n    render node in the network editor. Usually, you will want to set\n    ", {"text": ["soho_descriptiveparmname"], "type": "code"}, " instead, since it\u2019s more useful to show the\n    value of a parameter instead of a static string."]}], "indent": 0, "text": ["Descriptive Name"], "role": "item", "attrs": {"hprop": "soho_descriptivename"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["The internal name of a paremeter to use as the content of the \"descriptive\n    text\" displayed with the render node in the network editor. For example, if\n    you set this ", {"text": ["camera"], "type": "code"}, ", the network editor will display the value of the\n    render node\u2019s Camera parameter beside the node in the network editor."]}], "indent": 0, "text": ["Descriptive Parm Name"], "role": "item", "attrs": {"hprop": "soho_descriptiveparmname"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When the ", {"text": ["-v"], "type": "code"}, " option is specified on the ", {"text": ["ray_detail"], "type": "code"}, " line, this determines the time scale for velocity based motion blur."]}, {"indent": 4, "type": "para", "text": ["You must add this as a float spare parameter if you want to change it, since it doesn\u2019t exist in the render properties interface."]}], "indent": 0, "text": [{"text": ["vm_motiontimescale"], "type": "code"}, " / ", {"text": ["geometry:timescale"], "type": "code"}], "role": "item", "attrs": {"ifdprop": "geometry:timescale", "hprop": "vm_motiontimescale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Is a spare parameter on the camera that will influence which objects are captured by the camera. This parameter is also recognized in the viewport, so if the camera has this parameter defined, when viewing through the camera the viewport will use it as a mask to filter which options should be visible."]}], "indent": 0, "text": [{"text": ["vobject"], "type": "code"}], "role": "item", "attrs": {"hprop": "vobject"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the shading position (", {"text": ["P"], "type": "code"}, ") using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Shading position (P)"], "role": "item", "attrs": {"hprop": "vm_quickplane_P"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the shading depth (", {"text": ["Pz"], "type": "code"}, ") using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Shading depth (Pz)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Pz"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the shading normal (", {"text": ["N"], "type": "code"}, ") using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Shading normal (N)"], "role": "item", "attrs": {"hprop": "vm_quickplane_N"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the shading tangent-space normal (", {"text": ["Nt"], "type": "code"}, ") using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}, {"indent": 4, "type": "para", "text": ["This is specific to texture baking and exists by default on the baking output driver."]}], "indent": 0, "text": ["Shading tangent-space normal (Nt)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Nt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the combined lighting (all components) using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Combined lighting (per-component)"], "role": "item", "attrs": {"hprop": "vm_quickplane_all_comp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the direct lighting (all components) using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Direct lighting (per-component)"], "role": "item", "attrs": {"hprop": "vm_quickplane_direct_comp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the indirect lighting (all components) using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Indirect lighting (per-component)"], "role": "item", "attrs": {"hprop": "vm_quickplane_indirect_comp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for all types of light emission using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Combined emission"], "role": "item", "attrs": {"hprop": "vm_quickplane_all_emission"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the direct, un-shadowed lighting using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Direct unshadowed"], "role": "item", "attrs": {"hprop": "vm_quickplane_direct_noshadow"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the number of direct shading samples using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Direct ray samples"], "role": "item", "attrs": {"hprop": "vm_quickplane_direct_samples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add an extra image plane for the number of indirect shading samples using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["Indirect ray samples"], "role": "item", "attrs": {"hprop": "vm_quickplane_indirect_samples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add two extra image planes for single and multiple subsurface scattering using pre-defined settings.  For finer control, add the image channel using the generic image plane interface."]}], "indent": 0, "text": ["SSS Single/Multi"], "role": "item", "attrs": {"hprop": "vm_quickplane_sss"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The high-res object\u2019s normal projected into the low-res object\u2019s tangent-space."]}], "indent": 0, "text": ["Tangent Space Normal (Nt)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Nt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. Stores the magnitude between the high-res and low-res objects."]}], "indent": 0, "text": ["Displacement (Ds)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Ds"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. Stores the deltas between the high-res and low-res objects."]}], "indent": 0, "text": ["Vector Displacement (Vd)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Vd"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. Stores the deltas between the high-res and low-res objects in the low-res object\u2019s tangent-space."]}], "indent": 0, "text": ["Tangent-Space Vector Displacement (Vdt)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Vdt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The occlusion at the shading position."]}], "indent": 0, "text": ["Occlusion (Oc)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Oc"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The occlusion along the inverted normal at the shading position.  This produces \"relief\" shading."]}], "indent": 0, "text": ["Cavity (Cv)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Cv"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The thickness at the shading position."]}], "indent": 0, "text": ["Thickness (Th)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Th"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The curvature at the shading position."]}], "indent": 0, "text": ["Curvature (Cu)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Cu"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Used when baking textures. The Alpha channel with white in areas where\n    rays hit the high-res object."]}], "indent": 0, "text": ["Alpha (Ab)"], "role": "item", "attrs": {"hprop": "vm_quickplane_Ab"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Misc. properties"], "container": true, "type": "h", "id": null}, {"body": [{"body": [{"body": [{"indent": 4, "type": "para", "text": ["Disables all lighting on primary image plane in order to make baking faster."]}], "indent": 0, "text": ["Disable Lighting/Emission"], "role": "item", "attrs": {"hprop": "vm_bake_skipcf"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Add baking related shader exports to layers structs, so they can be mixed by layer compositing operations and finally exported."]}], "indent": 0, "text": ["Add Baking Exports to Shader Layers"], "role": "item", "attrs": {"hprop": "vm_bake_layerexport"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Number of samples to use for raytraced shading (eg. Occlusion, Cavity, Thickness). Increasing the number of samples will reduce noise in the shading."]}], "indent": 0, "text": ["Baking samples"], "role": "item", "attrs": {"hprop": "vm_bake_samples"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Use Mikkelsen\u2019s Tangent Space for baking tangent space normals (", {"text": ["Nt"], "type": "code"}, "). The basis is computed per-fragment (Unreal Engine compatible). Use a ", {"text": ["Divide SOP"], "fullpath": "/nodes/sop/divide", "scheme": "Node", "type": "link", "value": "/nodes/sop/divide"}, " to convert the UV Object into triangle mesh before baking because other applications may interpolate tangents across quads differently."]}], "indent": 0, "text": ["Use MikkT Tangent Space"], "role": "item", "attrs": {"ifdprop": "renderer:bake_usemikkt", "hprop": "vm_bake_usemikkt"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["When enabled, backfacing normals in tangent space (i.e. its Z axis in tangent basis is negative) will be flipped to always face forward."]}], "indent": 0, "text": ["Tangent Normal Face Forward"], "role": "item", "attrs": {"ifdprop": "renderer:bake_normalsfaceforward", "hprop": "vm_bake_normalsfaceforward"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Toggles flipping of the normal\u2019s X axis. Various packages may expect normal maps in different spaces. The flip parameters allow you to match these various spaces."]}], "indent": 0, "text": ["Tangent Normal Flip X"], "role": "item", "attrs": {"hprop": "vm_bake_tangentnormalflipx"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Toggles flipping of the normal\u2019s Y axis. Various packages may expect normal maps in different spaces. The flip parameters allow you to match these various spaces."]}], "indent": 0, "text": ["Tangent Normal Flip Y"], "role": "item", "attrs": {"hprop": "vm_bake_tangentnormalflipy"}, "type": "properties_item"}, {"body": [], "indent": 0, "text": ["Include Displacement in Tangent Normal"], "role": "item", "attrs": {"hprop": "vm_bake_tangentnormalincludedisp"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This acts as a contrast control over the occlusion shading, with values higher and lower than ", {"text": ["0.5"], "type": "code"}, " resulting in more and less contrast."]}], "indent": 0, "text": ["Occlusion Bias"], "role": "item", "attrs": {"hprop": "vm_bake_occlusionbias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Controls the distance within which features will influence the shading."]}], "indent": 0, "text": ["Cavity Distance"], "role": "item", "attrs": {"hprop": "vm_bake_cavitydistance"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This acts as a contrast control over the cavity occlusion shading, with values higher and lower than ", {"text": ["0.5"], "type": "code"}, " resulting in more and less contrast."]}], "indent": 0, "text": ["Cavity Bias"], "role": "item", "attrs": {"hprop": "vm_bake_cavitybias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This is a course but fast approximation for measuring curvature. When off (the default), the renderer measures curvature using local topology. Turning this on measures curvature by casting occlusion rays. The number of occlusion rays is controlled by ", {"text": ["Baking Samples"], "type": "ui"}, " parameter."]}], "indent": 0, "text": ["Occlusion-based Curvature"], "role": "item", "attrs": {"hprop": "vm_bake_curvatureocc"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Maximum occlusion ray distance to use when ", {"text": ["Occlusion-based Curvature"], "type": "ui"}, " is on."]}], "indent": 0, "text": ["Curvature Ray Distance"], "role": "item", "attrs": {"hprop": "vm_bake_curvaturesdist"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["Multiplies the output curvature value. If you are seeing any curvature shading you should increase this value until the gradient is visible."]}], "indent": 0, "text": ["Curvature Scale"], "role": "item", "attrs": {"hprop": "vm_bake_curvaturescale"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["This acts as a contrast control over the curvature\u2019s shading, with values higher and lower than ", {"text": ["0.5"], "type": "code"}, " resulting in more and less contrast."]}], "indent": 0, "text": ["Curvature Bias"], "role": "item", "attrs": {"hprop": "vm_bake_curvaturebias"}, "type": "properties_item"}, {"body": [{"indent": 4, "type": "para", "text": ["These controls let you output VEX variables as auxiliary image planes, either as extra planes in the output file or extra files."]}, {"body": [{"body": [{"indent": 8, "type": "para", "text": ["As of Houdini 9.1, each channel can now be written out to a different file. This lets you work with OpenEXR programs that don\u2019t support multiple channels in a single ", {"text": [".exr"], "type": "code"}, " image."]}, {"indent": 8, "type": "para", "text": ["You can also do fancy stuff like send one channel to the ", {"text": ["md"], "type": "code"}, " device (a non-interactive MPlay window), or split your image into multiple ", {"text": [".pic"], "type": "code"}, " files with a handful of ", {"text": [".tif"], "type": "code"}, " files thrown in. But if the primary image is ", {"text": ["ip"], "type": "code"}, ", all planes go to ", {"text": ["ip"], "type": "code"}, "."]}], "indent": 4, "role": "item", "type": "tip"}], "container": true, "role": "item_group", "type": "tip_group"}, {"indent": 4, "type": "para", "text": ["The Channel Name parameter lets you give the channel in the output file a different name than the default (the name of the VEX variable). For example, you want to send out the Of variable. If the Channel Name is left blank, the plane name in the ", {"text": [".pic"], "type": "code"}, " file will be ", {"text": ["Of"], "type": "code"}, ". If you set Channel Name to ", {"text": ["Opacity"], "type": "code"}, ", the plane in the ", {"text": [".pic"], "type": "code"}, " file will be called ", {"text": ["Opacity"], "type": "code"}, "."]}], "indent": 0, "text": ["Extra image planes"], "role": "item", "attrs": {"hprop": "vm_numaux"}, "type": "properties_item"}], "container": true, "role": "item_group", "type": "properties_item_group"}], "indent": 0, "level": 2, "text": ["Baking Properties"], "container": true, "type": "h", "id": null}], "indent": 0, "level": 1, "text": "Properties", "role": "section", "container": true, "type": "properties_section", "id": "properties"}], "included": ["/props/_minmax_styles"], "type": "root", "attrs": {"type": "properties"}, "title": ["Mantra rendering properties"]}